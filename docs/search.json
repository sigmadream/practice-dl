[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PNU 2024, 통계학과 딥러닝 특강",
    "section": "",
    "text": "강의노트"
  },
  {
    "objectID": "index.html#ref.",
    "href": "index.html#ref.",
    "title": "PNU 2024, 통계학과 딥러닝 특강",
    "section": "",
    "text": "강의노트"
  },
  {
    "objectID": "DL03.html",
    "href": "DL03.html",
    "title": "Day3. 머신러닝과 딥러닝",
    "section": "",
    "text": "import numpy as np\n\n\ndef AND(x1, x2):\n    x = np.array([x1, x2]) # 입력\n    w = np.array([0.5, 0.5]) # 가중치\n    b = -0.7 # 편향\n    tmp = np.sum(w*x) + b\n    if tmp &lt;= 0:\n        return 0\n    else:\n        return 1\n\n\nprint(AND(0,0))\nprint(AND(0,1))\nprint(AND(1,0))\nprint(AND(1,1))\n\n0\n0\n0\n1\n\n\n\ndef NAND(x1, x2):\n    x = np.array([x1, x2]) # 입력\n    w = np.array([-0.5, -0.5]) # 가중치\n    b = 0.7 # 편향\n    tmp = np.sum(w*x) + b\n    if tmp &lt;= 0:\n        return 0\n    else:\n        return 1\n\n\nprint(NAND(0,0))\nprint(NAND(0,1))\nprint(NAND(1,0))\nprint(NAND(1,1))\n\n1\n1\n1\n0\n\n\n\ndef OR(x1, x2):\n    x = np.array([x1, x2]) # 입력\n    w = np.array([0.5, 0.5]) # 가중치\n    b = -0.2 # 편향\n    tmp = np.sum(w*x) + b\n    if tmp &lt;= 0:\n        return 0\n    else:\n        return 1\n\n\nprint(OR(0,0))\nprint(OR(0,1))\nprint(OR(1,0))\nprint(OR(1,1))\n\n0\n1\n1\n1"
  },
  {
    "objectID": "DL03.html#퍼셉트론을-활용한-머신러닝",
    "href": "DL03.html#퍼셉트론을-활용한-머신러닝",
    "title": "Day3. 머신러닝과 딥러닝",
    "section": "",
    "text": "import numpy as np\n\n\ndef AND(x1, x2):\n    x = np.array([x1, x2]) # 입력\n    w = np.array([0.5, 0.5]) # 가중치\n    b = -0.7 # 편향\n    tmp = np.sum(w*x) + b\n    if tmp &lt;= 0:\n        return 0\n    else:\n        return 1\n\n\nprint(AND(0,0))\nprint(AND(0,1))\nprint(AND(1,0))\nprint(AND(1,1))\n\n0\n0\n0\n1\n\n\n\ndef NAND(x1, x2):\n    x = np.array([x1, x2]) # 입력\n    w = np.array([-0.5, -0.5]) # 가중치\n    b = 0.7 # 편향\n    tmp = np.sum(w*x) + b\n    if tmp &lt;= 0:\n        return 0\n    else:\n        return 1\n\n\nprint(NAND(0,0))\nprint(NAND(0,1))\nprint(NAND(1,0))\nprint(NAND(1,1))\n\n1\n1\n1\n0\n\n\n\ndef OR(x1, x2):\n    x = np.array([x1, x2]) # 입력\n    w = np.array([0.5, 0.5]) # 가중치\n    b = -0.2 # 편향\n    tmp = np.sum(w*x) + b\n    if tmp &lt;= 0:\n        return 0\n    else:\n        return 1\n\n\nprint(OR(0,0))\nprint(OR(0,1))\nprint(OR(1,0))\nprint(OR(1,1))\n\n0\n1\n1\n1"
  },
  {
    "objectID": "DL03.html#딥러닝을-활용한-xor-문제-해결",
    "href": "DL03.html#딥러닝을-활용한-xor-문제-해결",
    "title": "Day3. 머신러닝과 딥러닝",
    "section": "딥러닝을 활용한 XOR 문제 해결",
    "text": "딥러닝을 활용한 XOR 문제 해결\n\ndef XOR(x1, x2):\n    s1 = NAND(x1, x2)\n    s2 = OR(x1, x2)\n    return AND(s1, s2)\n\n\nprint(XOR(0,0)) # 0\nprint(XOR(0,1)) # 1\nprint(XOR(1,0)) # 1\nprint(XOR(1,1)) # 0\n\n0\n1\n1\n0"
  },
  {
    "objectID": "DL03.html#sin-값-예측하기",
    "href": "DL03.html#sin-값-예측하기",
    "title": "Day3. 머신러닝과 딥러닝",
    "section": "Sin 값 예측하기",
    "text": "Sin 값 예측하기\n\nimport math\nimport torch\nimport matplotlib.pyplot as plt\n\nx = torch.linspace(-math.pi, math.pi, 1000)\ny = torch.sin(x)\n\na = torch.randn(())\nb = torch.randn(())\nc = torch.randn(())\nd = torch.randn(())\n\ny_random = a * x**3 + b * x**2 + c * x + d\n\nplt.subplot(2, 1, 1)\nplt.title(\"y true\")\nplt.plot(x, y)\n\nplt.subplot(2, 1, 2)\nplt.title(\"y radnom\")\nplt.plot(x, y_random)\nplt.show()\n\nlearning_rate = 1e-6\n\nfor epoch in range(2000):\n   y_pred = a * x**3 + b * x**2 + c * x + d\n\n   loss = (y_pred - y).pow(2).sum().item()\n   if epoch % 100 == 0:\n       print(f\"epoch{epoch+1} loss:{loss}\")\n\n   grad_y_pred = 2.0 * (y_pred - y)\n   grad_a = (grad_y_pred * x ** 3).sum()\n   grad_b = (grad_y_pred * x ** 2).sum()\n   grad_c = (grad_y_pred * x).sum()\n   grad_d = grad_y_pred.sum()\n\n   a -= learning_rate * grad_a\n   b -= learning_rate * grad_b\n   c -= learning_rate * grad_c\n   d -= learning_rate * grad_d\n\nplt.subplot(3, 1, 1)\nplt.title(\"y true\")\nplt.plot(x, y)\n\nplt.subplot(3, 1, 2)\nplt.title(\"y pred\")\nplt.plot(x, y_pred)\n\nplt.subplot(3, 1, 3)\nplt.plot(y_random)\nplt.title(\"y random\")\nplt.show()\n\n\n\n\nepoch1 loss:1018073.25\nepoch101 loss:259.82220458984375\nepoch201 loss:211.42466735839844\nepoch301 loss:172.73411560058594\nepoch401 loss:141.27572631835938\nepoch501 loss:115.69705963134766\nepoch601 loss:94.89965057373047\nepoch701 loss:77.98924255371094\nepoch801 loss:64.23966979980469\nepoch901 loss:53.059940338134766\nepoch1001 loss:43.96979522705078\nepoch1101 loss:36.57878875732422\nepoch1201 loss:30.56935691833496\nepoch1301 loss:25.683107376098633\nepoch1401 loss:21.7100830078125\nepoch1501 loss:18.479732513427734\nepoch1601 loss:15.853113174438477\nepoch1701 loss:13.717451095581055\nepoch1801 loss:11.98098373413086\nepoch1901 loss:10.569087028503418"
  },
  {
    "objectID": "DL03.html#using-pytorch",
    "href": "DL03.html#using-pytorch",
    "title": "Day3. 머신러닝과 딥러닝",
    "section": "Using PyTorch",
    "text": "Using PyTorch\n\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nimport copy\n\n\nLoading the data, EDA and data preparation\n\ndf = pd.read_csv(\"./data/housing.csv\")\ndf = df.dropna().reset_index(drop=True)\ndf.head(5)\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\nNEAR BAY\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\nNEAR BAY\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\nNEAR BAY\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\nNEAR BAY\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\nNEAR BAY\n\n\n\n\n\n\n\n\nxDf = df[\n    [\n    \"longitude\",\n     \"latitude\",\n     \"housing_median_age\",\n     \"total_rooms\",\n     \"total_bedrooms\",\n     \"population\",\n     \"households\",\n     \"median_income\"\n    ]\n]\n\ndf[\"median_house_value\"] = df.apply(lambda row: float(row[\"median_house_value\"] / float(100000)), axis=1)\n\nyDf = df[\"median_house_value\"]\n\nX = xDf.values\ny = yDf.values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, shuffle = True)\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n\n\n\nArchitecture of the Neural Network\n이 연습에서는 신경망의 고전적인 구조인 피라미드 구조를 사용하겠습니다. 이 유형의 신경망에서 각 숨겨진 레이어는 다음 레이어에 연결되며 각 레이어는 이전 레이어보다 작습니다. 입력 계층의 크기는 특징의 수와 같으며, 이 경우 8입니다. 이 예제에서는 하나의 목표(연속적인 값인 집 가격)를 예측하려고 하므로 마지막 계층에 뉴런 하나만 있습니다.\n회귀 문제에서는 대상을 완벽하게 정확하게 예측할 수 없으므로 손실 함수로 MSE를 사용하는 것이 좋습니다.\n\n\nDefining the Model\n이제 PyTorch를 사용해 모델을 피라미드 구조의 선형 레이어 시퀀스로 정의하겠습니다. 입력 레이어에는 8개의 뉴런(이것이 우리가 가진 특징의 수)과 단 하나의 출력 뉴런(이것이 우리의 목표인 집값)이 있다는 점에 유의하세요.\n\nmodel = nn.Sequential(\n    nn.Linear(8, 24),\n    nn.ReLU(),\n    nn.Linear(24, 12),\n    nn.ReLU(),\n    nn.Linear(12, 6),\n    nn.ReLU(),\n    nn.Linear(6, 1)\n)\n\nAs a loss function we will use MSE and for the optimizer we will use Adam\n\nloss_function = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.001)\n\n\n\nDefining the training loop\n\nepochs = 400\nbatchSize = 20\n\nbest_mse = np.inf\nbest_weights = None\nhistory = []\n\nsize = X.shape[0]\n\nfor epoch in range(epochs):\n    model.train()\n\n    index = 0\n\n    while index * batchSize &lt;= size:\n        X_batch = X_train[index:index + batchSize]\n        y_batch = y_train[index:index + batchSize]\n\n        y_pred = model(X_batch)\n\n        loss = loss_function(y_pred, y_batch)\n\n        optimizer.zero_grad()\n        loss.backward()\n\n        optimizer.step()\n\n        index += batchSize\n\n    model.eval()\n    y_pred = model(X_test)\n    mse = loss_function(y_pred, y_test)\n    mse = float(mse)\n    history.append(mse)\n    if mse &lt; best_mse:\n        print(f\"best mse is {mse} on epoch {epoch}\")\n        best_mse = mse\n        best_weights = copy.deepcopy(model.state_dict())\n\nmodel.load_state_dict(best_weights)\n\nbest mse is 6.128345966339111 on epoch 0\nbest mse is 4.747837066650391 on epoch 1\nbest mse is 4.726436138153076 on epoch 2\nbest mse is 4.378176212310791 on epoch 3\nbest mse is 4.287140369415283 on epoch 5\nbest mse is 4.082657337188721 on epoch 6\nbest mse is 3.8813700675964355 on epoch 7\nbest mse is 3.604973316192627 on epoch 8\nbest mse is 2.6447768211364746 on epoch 9\nbest mse is 2.5121638774871826 on epoch 10\nbest mse is 1.7982743978500366 on epoch 11\nbest mse is 1.647772192955017 on epoch 12\nbest mse is 1.5655877590179443 on epoch 13\nbest mse is 1.4794301986694336 on epoch 14\nbest mse is 1.4520149230957031 on epoch 15\nbest mse is 1.4172937870025635 on epoch 16\nbest mse is 1.3881410360336304 on epoch 17\nbest mse is 1.3622167110443115 on epoch 18\nbest mse is 1.2826541662216187 on epoch 19\nbest mse is 1.2210208177566528 on epoch 20\nbest mse is 1.1112759113311768 on epoch 21\nbest mse is 1.1039745807647705 on epoch 22\nbest mse is 1.0982367992401123 on epoch 23\nbest mse is 1.0963279008865356 on epoch 24\nbest mse is 1.089799404144287 on epoch 25\nbest mse is 1.0830093622207642 on epoch 30\nbest mse is 1.0713061094284058 on epoch 31\nbest mse is 1.0708402395248413 on epoch 32\nbest mse is 1.068825125694275 on epoch 33\nbest mse is 1.05531907081604 on epoch 34\nbest mse is 1.0497716665267944 on epoch 35\nbest mse is 1.0382816791534424 on epoch 36\nbest mse is 1.0312730073928833 on epoch 37\nbest mse is 1.0244638919830322 on epoch 38\nbest mse is 1.019054889678955 on epoch 39\nbest mse is 1.0077873468399048 on epoch 41\nbest mse is 1.007314920425415 on epoch 42\nbest mse is 0.9989040493965149 on epoch 43\nbest mse is 0.9963122606277466 on epoch 44\nbest mse is 0.9906237125396729 on epoch 46\nbest mse is 0.9681081175804138 on epoch 47\nbest mse is 0.9679588675498962 on epoch 48\nbest mse is 0.9636338949203491 on epoch 49\nbest mse is 0.9365105628967285 on epoch 51\nbest mse is 0.9349256753921509 on epoch 59\nbest mse is 0.9318903684616089 on epoch 60\nbest mse is 0.9142102003097534 on epoch 63\nbest mse is 0.9138439297676086 on epoch 65\nbest mse is 0.9086882472038269 on epoch 66\nbest mse is 0.9014654755592346 on epoch 67\nbest mse is 0.8996442556381226 on epoch 68\nbest mse is 0.8988744616508484 on epoch 72\nbest mse is 0.8975339531898499 on epoch 73\nbest mse is 0.8964466452598572 on epoch 74\nbest mse is 0.8934708833694458 on epoch 75\nbest mse is 0.8881350755691528 on epoch 77\nbest mse is 0.8869858980178833 on epoch 79\nbest mse is 0.8848766088485718 on epoch 80\nbest mse is 0.8816877603530884 on epoch 81\nbest mse is 0.8811050057411194 on epoch 83\nbest mse is 0.8774977326393127 on epoch 85\nbest mse is 0.8737624883651733 on epoch 86\nbest mse is 0.8732728362083435 on epoch 88\nbest mse is 0.8731635808944702 on epoch 93\nbest mse is 0.8614754676818848 on epoch 98\nbest mse is 0.8488722443580627 on epoch 159\nbest mse is 0.8383627533912659 on epoch 160\nbest mse is 0.8242272138595581 on epoch 161\nbest mse is 0.8041302561759949 on epoch 162\nbest mse is 0.799055278301239 on epoch 166\nbest mse is 0.7923058867454529 on epoch 168\nbest mse is 0.7869041562080383 on epoch 170\nbest mse is 0.7707822918891907 on epoch 171\nbest mse is 0.7557774186134338 on epoch 172\nbest mse is 0.7529003024101257 on epoch 174\nbest mse is 0.7306028008460999 on epoch 176\nbest mse is 0.7285521626472473 on epoch 177\nbest mse is 0.7085898518562317 on epoch 180\nbest mse is 0.7069340944290161 on epoch 183\nbest mse is 0.6941869854927063 on epoch 184\nbest mse is 0.6871175169944763 on epoch 187\nbest mse is 0.6768085360527039 on epoch 188\nbest mse is 0.674870491027832 on epoch 192\nbest mse is 0.6707104444503784 on epoch 193\nbest mse is 0.6658936142921448 on epoch 196\nbest mse is 0.6569523811340332 on epoch 198\nbest mse is 0.6482753753662109 on epoch 199\nbest mse is 0.6455034017562866 on epoch 203\nbest mse is 0.637505292892456 on epoch 205\nbest mse is 0.6342315077781677 on epoch 206\nbest mse is 0.6324762105941772 on epoch 207\nbest mse is 0.6312294602394104 on epoch 208\nbest mse is 0.6305112838745117 on epoch 209\nbest mse is 0.6167631149291992 on epoch 212\nbest mse is 0.6097006797790527 on epoch 216\nbest mse is 0.6043913960456848 on epoch 217\nbest mse is 0.6026005148887634 on epoch 218\nbest mse is 0.5929579734802246 on epoch 219\nbest mse is 0.589219331741333 on epoch 221\nbest mse is 0.5780711770057678 on epoch 224\nbest mse is 0.5773553848266602 on epoch 226\nbest mse is 0.5717324018478394 on epoch 227\nbest mse is 0.5657535791397095 on epoch 230\nbest mse is 0.5491172075271606 on epoch 236\nbest mse is 0.5466038584709167 on epoch 238\nbest mse is 0.5438665151596069 on epoch 239\nbest mse is 0.5391550064086914 on epoch 243\nbest mse is 0.5359430313110352 on epoch 251\nbest mse is 0.5355218648910522 on epoch 268\n\n\n&lt;All keys matched successfully&gt;\n\n\n\nprint(\"MSE: %.4f\" % best_mse)\n\nMSE: 0.5355\n\n\nMSE의 경우, 값이 100000으로 나뉘어져 있으므로 실제 가치는 약 50000 달러이다.\n\n\nPlotting the learning curve\n\nplt.plot(history)\nplt.title(\"MSE evolution by Epoch\")\nplt.xlabel(\"MSE\")\nplt.ylabel(\"Epoch\")\n\nText(0, 0.5, 'Epoch')"
  },
  {
    "objectID": "DL01.html",
    "href": "DL01.html",
    "title": "Day1. 전처리",
    "section": "",
    "text": "관련기사 : “우리 결혼 안 합니다” 생애 모델을 거부하는 사람들 [2023 연애·결혼 리포트]\n통계청에서 “데이터”를 다운로드\n\n\nimport pandas as pd\n\n\ndf_kosis = pd.read_csv(\"data/kosis-20240117021412.csv\")\ndf_kosis.shape\n\n(19, 937)\n\n\n\ndf_kosis.head()\n\n\n\n\n\n\n\n\n시군구별\n1997.01\n1997.01.1\n1997.01.2\n1997.02\n1997.02.1\n1997.02.2\n1997.03\n1997.03.1\n1997.03.2\n...\n2022.09.2\n2022.10\n2022.10.1\n2022.10.2\n2022.11\n2022.11.1\n2022.11.2\n2022.12\n2022.12.1\n2022.12.2\n\n\n\n\n0\n시군구별\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n...\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n\n\n1\n전국\n63268\n33266\n30002\n58144\n30086\n28058\n62160\n32333\n29827\n...\n10715\n20646\n10530\n10116\n18981\n9737\n9244\n16896\n8684\n8212\n\n\n2\n서울특별시\n13205\n6886\n6319\n12239\n6224\n6015\n13358\n6947\n6411\n...\n1831\n3612\n1794\n1818\n3230\n1678\n1552\n2901\n1472\n1429\n\n\n3\n부산광역시\n4201\n2260\n1941\n3910\n2104\n1806\n4304\n2234\n2070\n...\n575\n1166\n602\n564\n977\n479\n498\n957\n528\n429\n\n\n4\n대구광역시\n3345\n1764\n1581\n2994\n1608\n1386\n3337\n1815\n1522\n...\n416\n848\n428\n420\n802\n406\n396\n663\n334\n329\n\n\n\n\n5 rows × 937 columns\n\n\n\n 이미지 출처 : https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n\ndf_kosis.head(1)\n\n\n\n\n\n\n\n\n시군구별\n1997.01\n1997.01.1\n1997.01.2\n1997.02\n1997.02.1\n1997.02.2\n1997.03\n1997.03.1\n1997.03.2\n...\n2022.09.2\n2022.10\n2022.10.1\n2022.10.2\n2022.11\n2022.11.1\n2022.11.2\n2022.12\n2022.12.1\n2022.12.2\n\n\n\n\n0\n시군구별\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n...\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n\n\n\n\n1 rows × 937 columns\n\n\n\n\ndf = df_kosis.melt(id_vars=\"시군구별\")\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n\n\n\n\n0\n시군구별\n1997.01\n계 (명)\n\n\n1\n전국\n1997.01\n63268\n\n\n2\n서울특별시\n1997.01\n13205\n\n\n3\n부산광역시\n1997.01\n4201\n\n\n4\n대구광역시\n1997.01\n3345\n\n\n\n\n\n\n\n\ndf[\"시군구별\"].unique()\n\narray(['시군구별', '전국', '서울특별시', '부산광역시', '대구광역시', '인천광역시', '광주광역시', '대전광역시',\n       '울산광역시', '세종특별자치시', '경기도', '강원도', '충청북도', '충청남도', '전라북도', '전라남도',\n       '경상북도', '경상남도', '제주특별자치도'], dtype=object)\n\n\n\ndf = df[df[\"시군구별\"] != \"시군구별\"].copy()\ndf.shape\n\n(16848, 3)\n\n\n\ndf[\"시군구별\"].unique()\n\narray(['전국', '서울특별시', '부산광역시', '대구광역시', '인천광역시', '광주광역시', '대전광역시',\n       '울산광역시', '세종특별자치시', '경기도', '강원도', '충청북도', '충청남도', '전라북도', '전라남도',\n       '경상북도', '경상남도', '제주특별자치도'], dtype=object)\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n\n\n\n\n1\n전국\n1997.01\n63268\n\n\n2\n서울특별시\n1997.01\n13205\n\n\n3\n부산광역시\n1997.01\n4201\n\n\n4\n대구광역시\n1997.01\n3345\n\n\n5\n인천광역시\n1997.01\n3646\n\n\n\n\n\n\n\n\ndf[\"연도\"] = df[\"variable\"].str.split(\".\", expand=True)[0]\ndf[\"월\"] = df[\"variable\"].str.split(\".\", expand=True)[1]\ndf[\"성별\"] = df[\"variable\"].str.split(\".\", expand=True)[2]\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268\n1997\n01\nNone\n\n\n2\n서울특별시\n1997.01\n13205\n1997\n01\nNone\n\n\n3\n부산광역시\n1997.01\n4201\n1997\n01\nNone\n\n\n4\n대구광역시\n1997.01\n3345\n1997\n01\nNone\n\n\n5\n인천광역시\n1997.01\n3646\n1997\n01\nNone\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n연도\n월\n성별\n\n\n\n\n17779\n전라북도\n2022.12.2\n229\n2022\n12\n2\n\n\n17780\n전라남도\n2022.12.2\n250\n2022\n12\n2\n\n\n17781\n경상북도\n2022.12.2\n366\n2022\n12\n2\n\n\n17782\n경상남도\n2022.12.2\n503\n2022\n12\n2\n\n\n17783\n제주특별자치도\n2022.12.2\n121\n2022\n12\n2\n\n\n\n\n\n\n\n\ndf[\"성별\"].unique()\n\narray([None, '1', '2'], dtype=object)\n\n\n\ndf[\"성별\"].nunique()\n\n2\n\n\n\ndf[\"성별\"] = df[\"성별\"].fillna(\"전체\")\ndf[\"성별\"].unique()\n\narray(['전체', '1', '2'], dtype=object)\n\n\n\ndf[\"성별\"] = df[\"성별\"].replace(\"1\", \"남자\").replace(\"2\", \"여자\")\ndf[\"성별\"].unique()\n\narray(['전체', '남자', '여자'], dtype=object)\n\n\n\ndf[\"성별\"].value_counts()\n\n성별\n전체    5616\n남자    5616\n여자    5616\nName: count, dtype: int64\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268\n1997\n01\n전체\n\n\n2\n서울특별시\n1997.01\n13205\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646\n1997\n01\n전체\n\n\n\n\n\n\n\n\ndf = df.rename(columns={\"variable\": \"기간\", \"value\": \"출생아수\"})\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268\n1997\n01\n전체\n\n\n2\n서울특별시\n1997.01\n13205\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646\n1997\n01\n전체\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 16848 entries, 1 to 17783\nData columns (total 6 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   시군구별    16848 non-null  object\n 1   기간      16848 non-null  object\n 2   출생아수    16848 non-null  object\n 3   연도      16848 non-null  object\n 4   월       16848 non-null  object\n 5   성별      16848 non-null  object\ndtypes: object(6)\nmemory usage: 921.4+ KB\n\n\n\nimport numpy as np\ndf[\"출생아수\"] = df[\"출생아수\"].replace(\"-\", np.nan)\ndf[\"출생아수\"] = df[\"출생아수\"].astype(float)\ndf[\"출생아수\"].describe()\n\ncount    16308.000000\nmean      2898.333579\nstd       6406.925280\nmin         30.000000\n25%        589.000000\n50%        980.000000\n75%       1833.250000\nmax      63268.000000\nName: 출생아수, dtype: float64\n\n\n\ndf_all = df[(df[\"시군구별\"] == \"전국\") & (df[\"성별\"] == \"전체\")]\ndf_all.head(2)\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268.0\n1997\n01\n전체\n\n\n58\n전국\n1997.02\n58144.0\n1997\n02\n전체\n\n\n\n\n\n\n\n\ndf_all = df_all[[\"연도\", \"월\", \"출생아수\"]].copy()\ndf_all.head()\n\n\n\n\n\n\n\n\n연도\n월\n출생아수\n\n\n\n\n1\n1997\n01\n63268.0\n\n\n58\n1997\n02\n58144.0\n\n\n115\n1997\n03\n62160.0\n\n\n172\n1997\n04\n56949.0\n\n\n229\n1997\n05\n55270.0\n\n\n\n\n\n\n\n\n# !pip install koreanize_matplotlib\n\n\nimport matplotlib.pyplot as plt\nimport koreanize_matplotlib\n%config InlineBackend.figure_format = 'retina'\n\n\ndf_all.set_index([\"연도\", \"월\"]).plot(figsize=(15, 4))\n\n&lt;Axes: xlabel='연도,월'&gt;\n\n\n\n\n\n\ndf_all[-48:].set_index([\"연도\", \"월\"]).plot.bar(figsize=(15, 4))\n\n&lt;Axes: xlabel='연도,월'&gt;\n\n\n\n\n\n\nimport seaborn as sns\n\n\nplt.figure(figsize=(15, 4))\nsns.lineplot(data=df_all, x=\"연도\", y=\"출생아수\", errorbar=None)\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.lineplot(data=df_all, x=\"연도\", y=\"출생아수\", errorbar=None, hue=\"월\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.barplot(data=df_all, x=\"연도\", y=\"출생아수\", errorbar=None, hue=\"월\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_local = df[df[\"시군구별\"] != \"전국\"].copy()\ndf_local.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201.0\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345.0\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646.0\n1997\n01\n전체\n\n\n6\n광주광역시\n1997.01\n2166.0\n1997\n01\n전체\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.pointplot(data=df_local, x=\"연도\", y=\"출생아수\", hue=\"성별\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_local_all = df_local[df_local[\"성별\"] == \"전체\"]\ndf_local_all.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201.0\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345.0\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646.0\n1997\n01\n전체\n\n\n6\n광주광역시\n1997.01\n2166.0\n1997\n01\n전체\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.pointplot(data=df_local_all, x=\"연도\", y=\"출생아수\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_local_all.columns\n\nIndex(['시군구별', '기간', '출생아수', '연도', '월', '성별'], dtype='object')\n\n\n\nplt.figure(figsize=(12, 4))\nsns.pointplot(data=df_local_all, x=\"연도\", y=\"출생아수\", hue=\"시군구별\", errorbar=None)\nplt.legend(loc='center right', bbox_to_anchor=(1.17, 0.5), ncol=1)\n\n&lt;matplotlib.legend.Legend at 0x21ca6e613d0&gt;\n\n\n\n\n\n\ndf_local_2 = df_local_all[df_local_all[\"시군구별\"].isin([\"서울특별시\", \"경기도\", \"세종특별자치시\"])]\ndf_local_2.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n9\n세종특별자치시\n1997.01\nNaN\n1997\n01\n전체\n\n\n10\n경기도\n1997.01\n13440.0\n1997\n01\n전체\n\n\n59\n서울특별시\n1997.02\n12239.0\n1997\n02\n전체\n\n\n66\n세종특별자치시\n1997.02\nNaN\n1997\n02\n전체\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.pointplot(data=df_local_2, x=\"연도\", y=\"출생아수\", errorbar=None, hue=\"시군구별\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_sj = df[df[\"시군구별\"] == \"세종특별자치시\"].dropna(how=\"any\")\ndf_sj.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n10269\n세종특별자치시\n2012.01\n73.0\n2012\n01\n전체\n\n\n10288\n세종특별자치시\n2012.01.1\n38.0\n2012\n01\n남자\n\n\n10307\n세종특별자치시\n2012.01.2\n35.0\n2012\n01\n여자\n\n\n10326\n세종특별자치시\n2012.02\n74.0\n2012\n02\n전체\n\n\n10345\n세종특별자치시\n2012.02.1\n43.0\n2012\n02\n남자\n\n\n\n\n\n\n\n\nimport numpy as np\nsns.pointplot(data=df_sj, x=\"연도\", y=\"출생아수\", errorbar=None, estimator=np.sum)\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_local_all\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201.0\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345.0\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646.0\n1997\n01\n전체\n\n\n6\n광주광역시\n1997.01\n2166.0\n1997\n01\n전체\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n17741\n전라북도\n2022.12\n483.0\n2022\n12\n전체\n\n\n17742\n전라남도\n2022.12\n500.0\n2022\n12\n전체\n\n\n17743\n경상북도\n2022.12\n770.0\n2022\n12\n전체\n\n\n17744\n경상남도\n2022.12\n993.0\n2022\n12\n전체\n\n\n17745\n제주특별자치도\n2022.12\n233.0\n2022\n12\n전체\n\n\n\n\n5304 rows × 6 columns\n\n\n\n\nsns.relplot(data=df_local_all.sort_values(by=[\"연도\", \"월\"]), x=\"연도\", y=\"출생아수\", kind=\"line\", col=\"시군구별\", col_wrap=4, hue=\"시군구별\")\n\n\n\n\n\ndf_local_gender = df[(df[\"시군구별\"] != \"전국\") & (df[\"성별\"] !=  \"전체\")]\n\n\nsns.relplot(data=df_local_gender, x=\"연도\", y=\"출생아수\", kind=\"line\", col=\"시군구별\", col_wrap=4, hue=\"성별\")"
  },
  {
    "objectID": "DL01.html#통계청-출생아수시도시군구-재현",
    "href": "DL01.html#통계청-출생아수시도시군구-재현",
    "title": "Day1. 전처리",
    "section": "",
    "text": "관련기사 : “우리 결혼 안 합니다” 생애 모델을 거부하는 사람들 [2023 연애·결혼 리포트]\n통계청에서 “데이터”를 다운로드\n\n\nimport pandas as pd\n\n\ndf_kosis = pd.read_csv(\"data/kosis-20240117021412.csv\")\ndf_kosis.shape\n\n(19, 937)\n\n\n\ndf_kosis.head()\n\n\n\n\n\n\n\n\n시군구별\n1997.01\n1997.01.1\n1997.01.2\n1997.02\n1997.02.1\n1997.02.2\n1997.03\n1997.03.1\n1997.03.2\n...\n2022.09.2\n2022.10\n2022.10.1\n2022.10.2\n2022.11\n2022.11.1\n2022.11.2\n2022.12\n2022.12.1\n2022.12.2\n\n\n\n\n0\n시군구별\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n...\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n\n\n1\n전국\n63268\n33266\n30002\n58144\n30086\n28058\n62160\n32333\n29827\n...\n10715\n20646\n10530\n10116\n18981\n9737\n9244\n16896\n8684\n8212\n\n\n2\n서울특별시\n13205\n6886\n6319\n12239\n6224\n6015\n13358\n6947\n6411\n...\n1831\n3612\n1794\n1818\n3230\n1678\n1552\n2901\n1472\n1429\n\n\n3\n부산광역시\n4201\n2260\n1941\n3910\n2104\n1806\n4304\n2234\n2070\n...\n575\n1166\n602\n564\n977\n479\n498\n957\n528\n429\n\n\n4\n대구광역시\n3345\n1764\n1581\n2994\n1608\n1386\n3337\n1815\n1522\n...\n416\n848\n428\n420\n802\n406\n396\n663\n334\n329\n\n\n\n\n5 rows × 937 columns\n\n\n\n 이미지 출처 : https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n\ndf_kosis.head(1)\n\n\n\n\n\n\n\n\n시군구별\n1997.01\n1997.01.1\n1997.01.2\n1997.02\n1997.02.1\n1997.02.2\n1997.03\n1997.03.1\n1997.03.2\n...\n2022.09.2\n2022.10\n2022.10.1\n2022.10.2\n2022.11\n2022.11.1\n2022.11.2\n2022.12\n2022.12.1\n2022.12.2\n\n\n\n\n0\n시군구별\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n...\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n\n\n\n\n1 rows × 937 columns\n\n\n\n\ndf = df_kosis.melt(id_vars=\"시군구별\")\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n\n\n\n\n0\n시군구별\n1997.01\n계 (명)\n\n\n1\n전국\n1997.01\n63268\n\n\n2\n서울특별시\n1997.01\n13205\n\n\n3\n부산광역시\n1997.01\n4201\n\n\n4\n대구광역시\n1997.01\n3345\n\n\n\n\n\n\n\n\ndf[\"시군구별\"].unique()\n\narray(['시군구별', '전국', '서울특별시', '부산광역시', '대구광역시', '인천광역시', '광주광역시', '대전광역시',\n       '울산광역시', '세종특별자치시', '경기도', '강원도', '충청북도', '충청남도', '전라북도', '전라남도',\n       '경상북도', '경상남도', '제주특별자치도'], dtype=object)\n\n\n\ndf = df[df[\"시군구별\"] != \"시군구별\"].copy()\ndf.shape\n\n(16848, 3)\n\n\n\ndf[\"시군구별\"].unique()\n\narray(['전국', '서울특별시', '부산광역시', '대구광역시', '인천광역시', '광주광역시', '대전광역시',\n       '울산광역시', '세종특별자치시', '경기도', '강원도', '충청북도', '충청남도', '전라북도', '전라남도',\n       '경상북도', '경상남도', '제주특별자치도'], dtype=object)\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n\n\n\n\n1\n전국\n1997.01\n63268\n\n\n2\n서울특별시\n1997.01\n13205\n\n\n3\n부산광역시\n1997.01\n4201\n\n\n4\n대구광역시\n1997.01\n3345\n\n\n5\n인천광역시\n1997.01\n3646\n\n\n\n\n\n\n\n\ndf[\"연도\"] = df[\"variable\"].str.split(\".\", expand=True)[0]\ndf[\"월\"] = df[\"variable\"].str.split(\".\", expand=True)[1]\ndf[\"성별\"] = df[\"variable\"].str.split(\".\", expand=True)[2]\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268\n1997\n01\nNone\n\n\n2\n서울특별시\n1997.01\n13205\n1997\n01\nNone\n\n\n3\n부산광역시\n1997.01\n4201\n1997\n01\nNone\n\n\n4\n대구광역시\n1997.01\n3345\n1997\n01\nNone\n\n\n5\n인천광역시\n1997.01\n3646\n1997\n01\nNone\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n연도\n월\n성별\n\n\n\n\n17779\n전라북도\n2022.12.2\n229\n2022\n12\n2\n\n\n17780\n전라남도\n2022.12.2\n250\n2022\n12\n2\n\n\n17781\n경상북도\n2022.12.2\n366\n2022\n12\n2\n\n\n17782\n경상남도\n2022.12.2\n503\n2022\n12\n2\n\n\n17783\n제주특별자치도\n2022.12.2\n121\n2022\n12\n2\n\n\n\n\n\n\n\n\ndf[\"성별\"].unique()\n\narray([None, '1', '2'], dtype=object)\n\n\n\ndf[\"성별\"].nunique()\n\n2\n\n\n\ndf[\"성별\"] = df[\"성별\"].fillna(\"전체\")\ndf[\"성별\"].unique()\n\narray(['전체', '1', '2'], dtype=object)\n\n\n\ndf[\"성별\"] = df[\"성별\"].replace(\"1\", \"남자\").replace(\"2\", \"여자\")\ndf[\"성별\"].unique()\n\narray(['전체', '남자', '여자'], dtype=object)\n\n\n\ndf[\"성별\"].value_counts()\n\n성별\n전체    5616\n남자    5616\n여자    5616\nName: count, dtype: int64\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268\n1997\n01\n전체\n\n\n2\n서울특별시\n1997.01\n13205\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646\n1997\n01\n전체\n\n\n\n\n\n\n\n\ndf = df.rename(columns={\"variable\": \"기간\", \"value\": \"출생아수\"})\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268\n1997\n01\n전체\n\n\n2\n서울특별시\n1997.01\n13205\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646\n1997\n01\n전체\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 16848 entries, 1 to 17783\nData columns (total 6 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   시군구별    16848 non-null  object\n 1   기간      16848 non-null  object\n 2   출생아수    16848 non-null  object\n 3   연도      16848 non-null  object\n 4   월       16848 non-null  object\n 5   성별      16848 non-null  object\ndtypes: object(6)\nmemory usage: 921.4+ KB\n\n\n\nimport numpy as np\ndf[\"출생아수\"] = df[\"출생아수\"].replace(\"-\", np.nan)\ndf[\"출생아수\"] = df[\"출생아수\"].astype(float)\ndf[\"출생아수\"].describe()\n\ncount    16308.000000\nmean      2898.333579\nstd       6406.925280\nmin         30.000000\n25%        589.000000\n50%        980.000000\n75%       1833.250000\nmax      63268.000000\nName: 출생아수, dtype: float64\n\n\n\ndf_all = df[(df[\"시군구별\"] == \"전국\") & (df[\"성별\"] == \"전체\")]\ndf_all.head(2)\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268.0\n1997\n01\n전체\n\n\n58\n전국\n1997.02\n58144.0\n1997\n02\n전체\n\n\n\n\n\n\n\n\ndf_all = df_all[[\"연도\", \"월\", \"출생아수\"]].copy()\ndf_all.head()\n\n\n\n\n\n\n\n\n연도\n월\n출생아수\n\n\n\n\n1\n1997\n01\n63268.0\n\n\n58\n1997\n02\n58144.0\n\n\n115\n1997\n03\n62160.0\n\n\n172\n1997\n04\n56949.0\n\n\n229\n1997\n05\n55270.0\n\n\n\n\n\n\n\n\n# !pip install koreanize_matplotlib\n\n\nimport matplotlib.pyplot as plt\nimport koreanize_matplotlib\n%config InlineBackend.figure_format = 'retina'\n\n\ndf_all.set_index([\"연도\", \"월\"]).plot(figsize=(15, 4))\n\n&lt;Axes: xlabel='연도,월'&gt;\n\n\n\n\n\n\ndf_all[-48:].set_index([\"연도\", \"월\"]).plot.bar(figsize=(15, 4))\n\n&lt;Axes: xlabel='연도,월'&gt;\n\n\n\n\n\n\nimport seaborn as sns\n\n\nplt.figure(figsize=(15, 4))\nsns.lineplot(data=df_all, x=\"연도\", y=\"출생아수\", errorbar=None)\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.lineplot(data=df_all, x=\"연도\", y=\"출생아수\", errorbar=None, hue=\"월\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.barplot(data=df_all, x=\"연도\", y=\"출생아수\", errorbar=None, hue=\"월\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_local = df[df[\"시군구별\"] != \"전국\"].copy()\ndf_local.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201.0\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345.0\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646.0\n1997\n01\n전체\n\n\n6\n광주광역시\n1997.01\n2166.0\n1997\n01\n전체\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.pointplot(data=df_local, x=\"연도\", y=\"출생아수\", hue=\"성별\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_local_all = df_local[df_local[\"성별\"] == \"전체\"]\ndf_local_all.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201.0\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345.0\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646.0\n1997\n01\n전체\n\n\n6\n광주광역시\n1997.01\n2166.0\n1997\n01\n전체\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.pointplot(data=df_local_all, x=\"연도\", y=\"출생아수\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_local_all.columns\n\nIndex(['시군구별', '기간', '출생아수', '연도', '월', '성별'], dtype='object')\n\n\n\nplt.figure(figsize=(12, 4))\nsns.pointplot(data=df_local_all, x=\"연도\", y=\"출생아수\", hue=\"시군구별\", errorbar=None)\nplt.legend(loc='center right', bbox_to_anchor=(1.17, 0.5), ncol=1)\n\n&lt;matplotlib.legend.Legend at 0x21ca6e613d0&gt;\n\n\n\n\n\n\ndf_local_2 = df_local_all[df_local_all[\"시군구별\"].isin([\"서울특별시\", \"경기도\", \"세종특별자치시\"])]\ndf_local_2.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n9\n세종특별자치시\n1997.01\nNaN\n1997\n01\n전체\n\n\n10\n경기도\n1997.01\n13440.0\n1997\n01\n전체\n\n\n59\n서울특별시\n1997.02\n12239.0\n1997\n02\n전체\n\n\n66\n세종특별자치시\n1997.02\nNaN\n1997\n02\n전체\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.pointplot(data=df_local_2, x=\"연도\", y=\"출생아수\", errorbar=None, hue=\"시군구별\")\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_sj = df[df[\"시군구별\"] == \"세종특별자치시\"].dropna(how=\"any\")\ndf_sj.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n10269\n세종특별자치시\n2012.01\n73.0\n2012\n01\n전체\n\n\n10288\n세종특별자치시\n2012.01.1\n38.0\n2012\n01\n남자\n\n\n10307\n세종특별자치시\n2012.01.2\n35.0\n2012\n01\n여자\n\n\n10326\n세종특별자치시\n2012.02\n74.0\n2012\n02\n전체\n\n\n10345\n세종특별자치시\n2012.02.1\n43.0\n2012\n02\n남자\n\n\n\n\n\n\n\n\nimport numpy as np\nsns.pointplot(data=df_sj, x=\"연도\", y=\"출생아수\", errorbar=None, estimator=np.sum)\n\n&lt;Axes: xlabel='연도', ylabel='출생아수'&gt;\n\n\n\n\n\n\ndf_local_all\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201.0\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345.0\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646.0\n1997\n01\n전체\n\n\n6\n광주광역시\n1997.01\n2166.0\n1997\n01\n전체\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n17741\n전라북도\n2022.12\n483.0\n2022\n12\n전체\n\n\n17742\n전라남도\n2022.12\n500.0\n2022\n12\n전체\n\n\n17743\n경상북도\n2022.12\n770.0\n2022\n12\n전체\n\n\n17744\n경상남도\n2022.12\n993.0\n2022\n12\n전체\n\n\n17745\n제주특별자치도\n2022.12\n233.0\n2022\n12\n전체\n\n\n\n\n5304 rows × 6 columns\n\n\n\n\nsns.relplot(data=df_local_all.sort_values(by=[\"연도\", \"월\"]), x=\"연도\", y=\"출생아수\", kind=\"line\", col=\"시군구별\", col_wrap=4, hue=\"시군구별\")\n\n\n\n\n\ndf_local_gender = df[(df[\"시군구별\"] != \"전국\") & (df[\"성별\"] !=  \"전체\")]\n\n\nsns.relplot(data=df_local_gender, x=\"연도\", y=\"출생아수\", kind=\"line\", col=\"시군구별\", col_wrap=4, hue=\"성별\")"
  },
  {
    "objectID": "DL02.html",
    "href": "DL02.html",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "",
    "text": "일반적인 예측 모델링 프로젝트(predictive modeling)는 다음과 같은 프로세스를 따른다.\n\n\n\nWorkflow\n\n\n\n\n시각화와 기술 통계(Descriptive statistics)를 통해서 데이터를 이해하는 단계이다.\n\n\n\n데이터를 정제하고 가공해서 머신 러닝 모델의 입력에 적합한 형태로 바꿔주는 단계이다.\n\nData Cleaning\n\nDeduplication\nOutlier detection\nOther cleaning techniques\n\nFor model\n\nFeature extraction\nFeature scaling\nDummification\nDimensionality reduction\n\n\n탐색적 자료 분석과 전처리는 순차적이라기 보다 반복적인 관계이다. EDA를 통해 어떤 전처리가 필요한지 알 수 있고 전처리를 통해 EDA를 수월하게 할 수 있다.\n\n\n\n적절한 머신 러닝 모델을 선택하는 단계이다.\n\n무엇을 선택할 것인가\n\nModel\nFeatures\nHyperparameters\n\n어떻게 선택할 것인가\n\nMetrics\nValidation\nCross Validation (CV)\n\n\n\n\n\n만들어진 머신 러닝 모델의 성능을 평가하고 모델을 활용하여 새로운 데이터에 대한 예측을 하는 단계이다.\n\n만들어진 모델이 얼마나 새로운 데이터에 대해 얼마나 일반화 (generalization) 가능한지 측정할 수 있다.\n평가용 데이터셋은 모델 선택과 학습 과정에서 쓰이지 않아야 한다.\n평가용 데이터셋은 학습용 데이터셋과 동일한 전처리 과정을 거쳐야 한다.\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom scipy.stats import skew\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n\ndata = pd.read_csv('data/housing.csv')\ndata.head()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\nNEAR BAY\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\nNEAR BAY\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\nNEAR BAY\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\nNEAR BAY\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\nNEAR BAY\n\n\n\n\n\n\n\n\ndata.columns.values\n\narray(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n       'total_bedrooms', 'population', 'households', 'median_income',\n       'median_house_value', 'ocean_proximity'], dtype=object)\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 20640 entries, 0 to 20639\nData columns (total 10 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   longitude           20640 non-null  float64\n 1   latitude            20640 non-null  float64\n 2   housing_median_age  20640 non-null  float64\n 3   total_rooms         20640 non-null  float64\n 4   total_bedrooms      20433 non-null  float64\n 5   population          20640 non-null  float64\n 6   households          20640 non-null  float64\n 7   median_income       20640 non-null  float64\n 8   median_house_value  20640 non-null  float64\n 9   ocean_proximity     20640 non-null  object \ndtypes: float64(9), object(1)\nmemory usage: 1.6+ MB"
  },
  {
    "objectID": "DL02.html#다양한-모델로-살펴보는-캘리포니아-집값-예측회귀",
    "href": "DL02.html#다양한-모델로-살펴보는-캘리포니아-집값-예측회귀",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "",
    "text": "일반적인 예측 모델링 프로젝트(predictive modeling)는 다음과 같은 프로세스를 따른다.\n\n\n\nWorkflow\n\n\n\n\n시각화와 기술 통계(Descriptive statistics)를 통해서 데이터를 이해하는 단계이다.\n\n\n\n데이터를 정제하고 가공해서 머신 러닝 모델의 입력에 적합한 형태로 바꿔주는 단계이다.\n\nData Cleaning\n\nDeduplication\nOutlier detection\nOther cleaning techniques\n\nFor model\n\nFeature extraction\nFeature scaling\nDummification\nDimensionality reduction\n\n\n탐색적 자료 분석과 전처리는 순차적이라기 보다 반복적인 관계이다. EDA를 통해 어떤 전처리가 필요한지 알 수 있고 전처리를 통해 EDA를 수월하게 할 수 있다.\n\n\n\n적절한 머신 러닝 모델을 선택하는 단계이다.\n\n무엇을 선택할 것인가\n\nModel\nFeatures\nHyperparameters\n\n어떻게 선택할 것인가\n\nMetrics\nValidation\nCross Validation (CV)\n\n\n\n\n\n만들어진 머신 러닝 모델의 성능을 평가하고 모델을 활용하여 새로운 데이터에 대한 예측을 하는 단계이다.\n\n만들어진 모델이 얼마나 새로운 데이터에 대해 얼마나 일반화 (generalization) 가능한지 측정할 수 있다.\n평가용 데이터셋은 모델 선택과 학습 과정에서 쓰이지 않아야 한다.\n평가용 데이터셋은 학습용 데이터셋과 동일한 전처리 과정을 거쳐야 한다.\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom scipy.stats import skew\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n\ndata = pd.read_csv('data/housing.csv')\ndata.head()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\nNEAR BAY\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\nNEAR BAY\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\nNEAR BAY\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\nNEAR BAY\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\nNEAR BAY\n\n\n\n\n\n\n\n\ndata.columns.values\n\narray(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n       'total_bedrooms', 'population', 'households', 'median_income',\n       'median_house_value', 'ocean_proximity'], dtype=object)\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 20640 entries, 0 to 20639\nData columns (total 10 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   longitude           20640 non-null  float64\n 1   latitude            20640 non-null  float64\n 2   housing_median_age  20640 non-null  float64\n 3   total_rooms         20640 non-null  float64\n 4   total_bedrooms      20433 non-null  float64\n 5   population          20640 non-null  float64\n 6   households          20640 non-null  float64\n 7   median_income       20640 non-null  float64\n 8   median_house_value  20640 non-null  float64\n 9   ocean_proximity     20640 non-null  object \ndtypes: float64(9), object(1)\nmemory usage: 1.6+ MB"
  },
  {
    "objectID": "DL02.html#전처리-preprocessing-1",
    "href": "DL02.html#전처리-preprocessing-1",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "전처리 (Preprocessing)",
    "text": "전처리 (Preprocessing)\n이 데이터셋은 잘 정제된 데이터셋이기 때문에 중복된 값이나 불량 데이터가 없다. 따라서 여기서는 Feature scaling 정도의 간단한 전처리만을 수행해보자.\n\nFeature scaling\n\n0~1 사이에 맞추기\n\n최솟값을 빼고 (최댓값 - 최솟값)으로 나눈다.\n최댓값은 1이 되고, 최솟값은 0이 된다.\n\n표준화(Standardization)하기\n\n평균을 빼고 표준편차로 나눈다.\n원래 분포가 정규분포인 경우 평균이 0이고 표준편차가 1인 표준정규분포로 바뀐다.\n대부분의 값이 -2 ~ 2 사이에 위치한다.\n\n\n이 예시에서는 표준화(Standardization)를 쓴다.\n학습 데이터셋의 전처리 과정에서 사용한 매개변수(parameter)는 테스트에서 동일하게 사용해야 한다. 이 예시에서는 학습 데이터셋에서 구한 변수의 평균과 표준편차를 저장해놓고 테스트에서 동일하게 사용할 것이다."
  },
  {
    "objectID": "DL02.html#전처리nan-missing-value",
    "href": "DL02.html#전처리nan-missing-value",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "전처리(NaN, Missing Value)",
    "text": "전처리(NaN, Missing Value)\n\ndata.isnull().sum()\n\nlongitude               0\nlatitude                0\nhousing_median_age      0\ntotal_rooms             0\ntotal_bedrooms        207\npopulation              0\nhouseholds              0\nmedian_income           0\nmedian_house_value      0\nocean_proximity         0\ndtype: int64\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n\n\n\n\ncount\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20433.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n\n\nmean\n-119.569704\n35.631861\n28.639486\n2635.763081\n537.870553\n1425.476744\n499.539680\n3.870671\n206855.816909\n\n\nstd\n2.003532\n2.135952\n12.585558\n2181.615252\n421.385070\n1132.462122\n382.329753\n1.899822\n115395.615874\n\n\nmin\n-124.350000\n32.540000\n1.000000\n2.000000\n1.000000\n3.000000\n1.000000\n0.499900\n14999.000000\n\n\n25%\n-121.800000\n33.930000\n18.000000\n1447.750000\n296.000000\n787.000000\n280.000000\n2.563400\n119600.000000\n\n\n50%\n-118.490000\n34.260000\n29.000000\n2127.000000\n435.000000\n1166.000000\n409.000000\n3.534800\n179700.000000\n\n\n75%\n-118.010000\n37.710000\n37.000000\n3148.000000\n647.000000\n1725.000000\n605.000000\n4.743250\n264725.000000\n\n\nmax\n-114.310000\n41.950000\n52.000000\n39320.000000\n6445.000000\n35682.000000\n6082.000000\n15.000100\n500001.000000\n\n\n\n\n\n\n\n\n한 블록 내의 최대 침실 수는 6445개이고 평균 침실 수는 537개임을 알 수 있습니다. 데이터가 왜곡된 것 같으므로 히스토그램을 통해 이를 확인하겠습니다.\n\n\nplt.figure(figsize= (10, 6))\nsns.histplot(data['total_bedrooms'], color = '#005b96', kde= True);\n\n\n\n\n\n확실히 왜곡되어 있으므로 누락된 값은 블록 내 객실 수 중앙값으로 채웁니다.\n\n\ndata['total_bedrooms'].fillna(data['total_bedrooms'].median(), inplace= True)"
  },
  {
    "objectID": "DL02.html#eda",
    "href": "DL02.html#eda",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "EDA",
    "text": "EDA\n\nplt.figure(figsize= (20, 8))\nsns.heatmap(data.corr(numeric_only=True), annot= True, cmap='YlGnBu')\nplt.show()\n\n\n\n\n\n중위소득은 분명 가장 중요한 특징입니다.\n\n\nsns.histplot(data['median_house_value'], color = '#005b96', kde= True);\n\n\n\n\n\ndata['median_house_value'].skew()\n\n0.9777632739098341\n\n\n\n우리의 목표 변수는 분명히 왜곡되어 있습니다. 따라서 로그 변환을 늦게 적용할 것입니다.\n\n\ndata.hist(bins = 30, figsize=(20, 15), color = '#005b96');\n\n\n\n\n많은 기능이 왜곡되어 있다는 것을 분명히 알 수 있습니다. 따라서 나중에 기능 변환을 수행할 때 이 문제를 해결해야 할 것입니다.\n어떻게 들여다봐도 문제가 많은 데이터..?, 범주형 변수도 같이 확인해보죠\n\nsns.countplot(x = data['ocean_proximity']);\n\n\n\n\n\ndata.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n        s=data[\"population\"]/100, label=\"population\", figsize=(15,8),\n        c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),colorbar=True,\n    )\nplt.legend()\nplt.show()\n\n\n\n\n\n특성공학\n\ndata['bed_per_room'] = data['total_bedrooms'] / data['total_rooms']\n\n\nX = data.drop(['median_house_value'], axis=1)\ny = np.log(data.median_house_value) # 로그 변환"
  },
  {
    "objectID": "DL02.html#특성-변환",
    "href": "DL02.html#특성-변환",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "특성 변환",
    "text": "특성 변환\n\nskew_df = pd.DataFrame(X.select_dtypes(np.number).columns, columns= ['Feature'])\nskew_df['Skew'] = skew_df['Feature'].apply(lambda feature: skew(X[feature]))\nskew_df['Abs_Skew'] = skew_df['Skew'].apply(abs)\nskew_df['Skewed'] = skew_df['Abs_Skew'].apply(lambda x: True if x &gt; 0.5 else False)\nskew_df\n\n\n\n\n\n\n\n\nFeature\nSkew\nAbs_Skew\nSkewed\n\n\n\n\n0\nlongitude\n-0.297780\n0.297780\nFalse\n\n\n1\nlatitude\n0.465919\n0.465919\nFalse\n\n\n2\nhousing_median_age\n0.060326\n0.060326\nFalse\n\n\n3\ntotal_rooms\n4.147042\n4.147042\nTrue\n\n\n4\ntotal_bedrooms\n3.480888\n3.480888\nTrue\n\n\n5\npopulation\n4.935500\n4.935500\nTrue\n\n\n6\nhouseholds\n3.410190\n3.410190\nTrue\n\n\n7\nmedian_income\n1.646537\n1.646537\nTrue\n\n\n8\nbed_per_room\n6.316445\n6.316445\nTrue\n\n\n\n\n\n\n\n\nskewed_columns = skew_df[skew_df['Abs_Skew'] &gt; 0.5]['Feature'].values\nskewed_columns\n\narray(['total_rooms', 'total_bedrooms', 'population', 'households',\n       'median_income', 'bed_per_room'], dtype=object)\n\n\n\nfor column in skewed_columns:\n    X[column] = np.log(X[column])\n\n\nEncoding\n\nencoder=LabelEncoder()\nX['ocean_proximity']=encoder.fit_transform(X['ocean_proximity'])\n\n\n\nScaling\n\nX.head()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nocean_proximity\nbed_per_room\n\n\n\n\n0\n-122.23\n37.88\n41.0\n6.779922\n4.859812\n5.774552\n4.836282\n2.119287\n3\n-1.920110\n\n\n1\n-122.22\n37.86\n21.0\n8.867709\n7.008505\n7.783641\n7.037028\n2.116424\n3\n-1.859204\n\n\n2\n-122.24\n37.85\n52.0\n7.290975\n5.247024\n6.206576\n5.176150\n1.982022\n3\n-2.043951\n\n\n3\n-122.25\n37.85\n52.0\n7.149917\n5.459586\n6.324359\n5.389072\n1.730434\n3\n-1.690331\n\n\n4\n-122.25\n37.85\n52.0\n7.394493\n5.634790\n6.336826\n5.556828\n1.347086\n3\n-1.759704\n\n\n\n\n\n\n\n\nscaler = StandardScaler()\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X), index= X.index, columns= X.columns)"
  },
  {
    "objectID": "DL02.html#데이터-나누기",
    "href": "DL02.html#데이터-나누기",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "데이터 나누기",
    "text": "데이터 나누기\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)"
  },
  {
    "objectID": "DL02.html#모델-생성",
    "href": "DL02.html#모델-생성",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "모델 생성",
    "text": "모델 생성\n\nLinear Regression\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\npredictions_lr = lr.predict(X_test)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, predictions_lr))\nr2 = r2_score(y_test, predictions_lr)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.3452750790518536\nR-square: 0.632694341236971\n\n\n\n\nKNN\n\nknn = KNeighborsRegressor()\nknn.fit(X_train, y_train)\npredictions_knn = knn.predict(X_test)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, predictions_knn))\nr2 = r2_score(y_test, predictions_knn)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.29601285396707333\nR-square: 0.7300282680211424\n\n\n\n\nRandom Forest\n\nrf = RandomForestRegressor(n_estimators= 100)\nrf.fit(X_train, y_train)\npredictions_rf = rf.predict(X_test)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, predictions_rf))\nr2 = r2_score(y_test, predictions_rf)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.2334248940765084\nR-square: 0.8321228865094886\n\n\n\n\nGradient Boosting\n\ngbr = GradientBoostingRegressor()\ngbr.fit(X_train, y_train)\npredictions_gbr = gbr.predict(X_test)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, predictions_gbr))\nr2 = r2_score(y_test, predictions_gbr)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.2682228192264499\nR-square: 0.7783393520634304"
  },
  {
    "objectID": "DL02.html#모델-결정",
    "href": "DL02.html#모델-결정",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "모델 결정",
    "text": "모델 결정\n\nfinal_predictions = (\n    0.25 * predictions_gbr +\n    0.25 * predictions_rf +\n    0.25 * predictions_knn +\n    0.25 * predictions_lr\n)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, final_predictions))\nr2 = r2_score(y_test, final_predictions)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.25736758988393904\nR-square: 0.795917923876904\n\n\n\nfinal_predictions\n\narray([10.96891851, 11.39631435, 12.7116723 , ..., 13.03870577,\n       11.33646148, 12.10731279])\n\n\n최종 예측을 원래 규모로 되돌리려면 최종 예측의 지수를 취해야 합니다.\n\nfinal_predictions = np.exp(final_predictions)\ny_test = np.exp(y_test)\n\n\npd.DataFrame({'Actual': y_test, 'Predicted': final_predictions.round(2)})\n\n\n\n\n\n\n\n\nActual\nPredicted\n\n\n\n\n20046\n47700.0\n58041.79\n\n\n3024\n45800.0\n88993.12\n\n\n15663\n500001.0\n331595.89\n\n\n20484\n218600.0\n270425.62\n\n\n9814\n278000.0\n250113.99\n\n\n...\n...\n...\n\n\n15362\n263300.0\n209092.77\n\n\n16623\n266800.0\n211218.81\n\n\n18086\n500001.0\n459873.06\n\n\n2144\n72300.0\n83822.90\n\n\n3665\n151500.0\n181192.05\n\n\n\n\n4128 rows × 2 columns"
  },
  {
    "objectID": "DL02.html#결과-확인",
    "href": "DL02.html#결과-확인",
    "title": "Day2. 기울기와 절편, 그리고 회귀",
    "section": "결과 확인",
    "text": "결과 확인\n\nplt.figure(figsize= (10, 6))\nsns.scatterplot(x= y_test, y= final_predictions, color= '#005b96')\nplt.xlabel('Actual House value')\nplt.ylabel('Predicted House Value')\nplt.show()\n\n\n\n\n\nplt.figure(figsize= (10, 6))\nsns.residplot(x= y_test, y = final_predictions, color= '#005b96')\nplt.show()\n\n\n\n\n\nresid = y_test - final_predictions\nplt.figure(figsize= (10, 6))\nsns.histplot(resid)\nplt.xlabel('Error');"
  },
  {
    "objectID": "DL04.html",
    "href": "DL04.html",
    "title": "Day4. CNN을 사용한 특징 기반 분류",
    "section": "",
    "text": "CNN을 학습하고, VGG에 대해서 알아보자"
  },
  {
    "objectID": "DL04.html#lenet-5-구현",
    "href": "DL04.html#lenet-5-구현",
    "title": "Day4. CNN을 사용한 특징 기반 분류",
    "section": "LeNet-5 구현",
    "text": "LeNet-5 구현\n\n\n\nimage.png\n\n\n\nBaseline Model with Multilayer Perceptrons\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport matplotlib.pyplot as plt\n\ntrain = torchvision.datasets.MNIST('data', train=True, download=True)\ntest = torchvision.datasets.MNIST('data', train=True, download=True)\nprint(train.data.shape, train.targets.shape)\nprint(test.data.shape, test.targets.shape)\n\ntorch.Size([60000, 28, 28]) torch.Size([60000])\ntorch.Size([60000, 28, 28]) torch.Size([60000])\n\n\n\nfor i in range(9):\n   plt.subplot(3, 3, i+1)\n   plt.imshow(train.data[i], cmap='gray')\nplt.show()\n\n\n\n\n\n# each sample becomes a vector of values 0-1\nX_train = train.data.reshape(-1, 784).float() / 255.0\ny_train = train.targets\nX_test = test.data.reshape(-1, 784).float() / 255.0\ny_test = test.targets\n\n\nfor i in range(9):\n   plt.subplot(3, 3, i+1)\n   plt.imshow(X_train[i].reshape(28,28), cmap='gray')\nplt.show()\n\n\n\n\n\nclass Baseline(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Linear(784, 784)\n        self.act1 = nn.ReLU()\n        self.layer2 = nn.Linear(784, 10)\n        \n    def forward(self, x):\n        x = self.act1(self.layer1(x))\n        x = self.layer2(x)\n        return x\n\n\nmodel = Baseline()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\nloss_fn = nn.CrossEntropyLoss()\nloader = torch.utils.data.DataLoader(list(zip(X_train, y_train)), shuffle=True, batch_size=100)\n\nn_epochs = 10\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # Validation\n    model.eval()\n    y_pred = model(X_test)\n    acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n\nEpoch 0: model accuracy 84.24%\nEpoch 1: model accuracy 87.51%\nEpoch 2: model accuracy 88.83%\nEpoch 3: model accuracy 89.66%\nEpoch 4: model accuracy 90.27%\nEpoch 5: model accuracy 90.67%\nEpoch 6: model accuracy 91.13%\nEpoch 7: model accuracy 91.45%\nEpoch 8: model accuracy 91.68%\nEpoch 9: model accuracy 92.01%\n\n\n\n\nSimple Convolutional Neural Network for MNIST\n\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize((0,), (128,)),\n])\ntrain = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform)\ntest = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(train, shuffle=True, batch_size=100)\ntestloader = torch.utils.data.DataLoader(test, shuffle=True, batch_size=100)\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Conv2d(1, 10, kernel_size=5, stride=1, padding=2)\n        self.relu1 = nn.ReLU()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n        self.dropout = nn.Dropout(0.2)\n        self.flat = nn.Flatten()\n        self.fc = nn.Linear(27*27*10, 128)\n        self.relu2 = nn.ReLU()\n        self.output = nn.Linear(128, 10)\n        \n    def forward(self, x):\n        x = self.relu1(self.conv(x))\n        x = self.pool(x)\n        x = self.dropout(x)\n        x = self.relu2(self.fc(self.flat(x)))\n        x = self.output(x)\n        return x\n\n\nmodel = CNN()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\nloss_fn = nn.CrossEntropyLoss()\n\nn_epochs = 10\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in trainloader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # Validation\n    model.eval()\n    acc = 0\n    count = 0\n    for X_batch, y_batch in testloader:\n        y_pred = model(X_batch)\n        acc += (torch.argmax(y_pred, 1) == y_batch).float().sum()\n        count += len(y_batch)\n    acc = acc / count\n    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n\nEpoch 0: model accuracy 71.64%\nEpoch 1: model accuracy 79.48%\nEpoch 2: model accuracy 81.65%\nEpoch 3: model accuracy 86.09%\nEpoch 4: model accuracy 87.39%\nEpoch 5: model accuracy 88.19%\nEpoch 6: model accuracy 88.75%\nEpoch 7: model accuracy 89.58%\nEpoch 8: model accuracy 89.31%\nEpoch 9: model accuracy 89.65%\n\n\n\n\nLeNet-5 for MNIST\n\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n        self.act1 = nn.Tanh()\n        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)\n        self.act2 = nn.Tanh()\n        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n\n        self.conv3 = nn.Conv2d(16, 120, kernel_size=5, stride=1, padding=0)\n        self.act3 = nn.Tanh()\n\n        self.flat = nn.Flatten()\n        self.fc1 = nn.Linear(1*1*120, 84)\n        self.act4 = nn.Tanh()\n        self.fc2 = nn.Linear(84, 10)\n        \n    def forward(self, x):\n        x = self.act1(self.conv1(x))\n        x = self.pool1(x)\n        x = self.act2(self.conv2(x))\n        x = self.pool2(x)\n        x = self.act3(self.conv3(x))\n        x = self.act4(self.fc1(self.flat(x)))\n        x = self.fc2(x)\n        return x\n\n\nmodel = LeNet5()\n\noptimizer = optim.Adam(model.parameters())\nloss_fn = nn.CrossEntropyLoss()\n\nn_epochs = 10\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in trainloader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # Validation\n    model.eval()\n    acc = 0\n    count = 0\n    for X_batch, y_batch in testloader:\n        y_pred = model(X_batch)\n        acc += (torch.argmax(y_pred, 1) == y_batch).float().sum()\n        count += len(y_batch)\n    acc = acc / count\n    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n\nEpoch 0: model accuracy 89.49%\nEpoch 1: model accuracy 92.64%\nEpoch 2: model accuracy 94.01%\nEpoch 3: model accuracy 95.69%\nEpoch 4: model accuracy 96.38%\nEpoch 5: model accuracy 96.84%\nEpoch 6: model accuracy 97.21%\nEpoch 7: model accuracy 97.77%\nEpoch 8: model accuracy 97.98%\nEpoch 9: model accuracy 98.29%"
  }
]