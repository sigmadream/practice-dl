[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "머신러닝/딥러닝 입문",
    "section": "",
    "text": "0.1 소개\nPNU의 2024년 겨울방학에 진행된 딥러닝 특강에 사용된 실습 코드 입니다. 통계학 학생분들에게 딥러닝을 활용한 간단한 응용 소프트웨어 개발 및 토이 프로젝트를 진행할 수 있도록 진행된 Hands-On 및 이론 강좌입니다.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PNU 2024, 통계학과 딥러닝 특강</span>"
    ]
  },
  {
    "objectID": "index.html#강의자료",
    "href": "index.html#강의자료",
    "title": "머신러닝/딥러닝 입문",
    "section": "0.2 강의자료",
    "text": "0.2 강의자료\n\n강의노트",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PNU 2024, 통계학과 딥러닝 특강</span>"
    ]
  },
  {
    "objectID": "index.html#changelog",
    "href": "index.html#changelog",
    "title": "머신러닝/딥러닝 입문",
    "section": "0.3 changelog",
    "text": "0.3 changelog\n\n2024.01.29 - CNN 관련 코드를 모두 PyTorch 형식으로 수정\n\nPyTorch를 사용해서 CNN의 주요 알고리즘을 모두 실습할 수 있도록 수정\n가능하면 VGG와 같이 전이학습을 활용할 수 있도록 수정\nStreamlit을 활용해서 모델의 활용법에 대해서 간략하게 소개",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PNU 2024, 통계학과 딥러닝 특강</span>"
    ]
  },
  {
    "objectID": "index.html#ref.",
    "href": "index.html#ref.",
    "title": "머신러닝/딥러닝 입문",
    "section": "0.4 Ref.",
    "text": "0.4 Ref.\n\nWELCOME TO PYTORCH TUTORIALS\nStreamlit\n머신 러닝 교과서: 파이토치 편\n파이토치와 구글 코랩으로 배우는 BERT 입문\n파이토치 라이트닝으로 시작하는 딥러닝\n파이토치 딥러닝 모델 AI앱 개발 입문\n101가지 문제로 배우는 딥러닝 허깅페이스 트랜스포머 with 파이토치",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PNU 2024, 통계학과 딥러닝 특강</span>"
    ]
  },
  {
    "objectID": "DL01.html",
    "href": "DL01.html",
    "title": "2  Day1. 전처리 실습(Hands-On)",
    "section": "",
    "text": "통계청 데이터를 활용한 전처리 실습\n\niris 등과 같은 전처리가 완려된 형태가 아닌 데이터를 활용해서 실습을 진행\n데이터에 대한 신뢰도를 높이기 위해서 OECD,IMF 등과 같은 공신력이 있는 기관의 데이터를 활용\n실습에선 통계청 데이터를 활용\n\n\n판다스를 사용해서 데이터의 형태를 확인하고 변경하는 과정을 진행할 예정입니다. 딥러닝을 전문적으로 다루는 수업이기 때문에 딥러닝에 필요한 최소한의 전처리 형태를 학습해보도록 하겠습니다.\n\nimport pandas as pd\n# CSV 파일을 읽어서 데이터프레임(DataFrame) 형태로 변경하고 구조를 확인\ndf_kosis = pd.read_csv(\"data/kosis-20240117021412.csv\")\ndf_kosis.shape\n\n(19, 937)\n\n\nhead를 통해서 확인할 수 있듯이, 현재 데이터는 옆으로 길게 형성되어 있습니다. 머신러닝/딥러닝의 경우 옆으로 긴 데이터를 사용하는 것은 불편하기 때문에 melt 등을 확인해서 형태를 변경해보겠습니다.\n\ndf_kosis.head()\n\n\n\n\n\n\n\n\n시군구별\n1997.01\n1997.01.1\n1997.01.2\n1997.02\n1997.02.1\n1997.02.2\n1997.03\n1997.03.1\n1997.03.2\n...\n2022.09.2\n2022.10\n2022.10.1\n2022.10.2\n2022.11\n2022.11.1\n2022.11.2\n2022.12\n2022.12.1\n2022.12.2\n\n\n\n\n0\n시군구별\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n...\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n\n\n1\n전국\n63268\n33266\n30002\n58144\n30086\n28058\n62160\n32333\n29827\n...\n10715\n20646\n10530\n10116\n18981\n9737\n9244\n16896\n8684\n8212\n\n\n2\n서울특별시\n13205\n6886\n6319\n12239\n6224\n6015\n13358\n6947\n6411\n...\n1831\n3612\n1794\n1818\n3230\n1678\n1552\n2901\n1472\n1429\n\n\n3\n부산광역시\n4201\n2260\n1941\n3910\n2104\n1806\n4304\n2234\n2070\n...\n575\n1166\n602\n564\n977\n479\n498\n957\n528\n429\n\n\n4\n대구광역시\n3345\n1764\n1581\n2994\n1608\n1386\n3337\n1815\n1522\n...\n416\n848\n428\n420\n802\n406\n396\n663\n334\n329\n\n\n\n\n5 rows × 937 columns\n\n\n\nmelt를 위해서 데이터프레임의 ’컬럼’을 확인합니다.\n\ndf_kosis.head(1)\n\n\n\n\n\n\n\n\n시군구별\n1997.01\n1997.01.1\n1997.01.2\n1997.02\n1997.02.1\n1997.02.2\n1997.03\n1997.03.1\n1997.03.2\n...\n2022.09.2\n2022.10\n2022.10.1\n2022.10.2\n2022.11\n2022.11.1\n2022.11.2\n2022.12\n2022.12.1\n2022.12.2\n\n\n\n\n0\n시군구별\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n...\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n계 (명)\n남자 (명)\n여자 (명)\n\n\n\n\n1 rows × 937 columns\n\n\n\nmelt를 사용해서 데이터를 변경하는 과정에서 해당 절차에 대한 필요성과 데이터 형태에 대해서 좀 더 다양한 자료를 찾으신다면 아래 링크를 확인하세요. - Tidy 논문 - tidy 함수\n\ndf = df_kosis.melt(id_vars=\"시군구별\")\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n\n\n\n\n0\n시군구별\n1997.01\n계 (명)\n\n\n1\n전국\n1997.01\n63268\n\n\n2\n서울특별시\n1997.01\n13205\n\n\n3\n부산광역시\n1997.01\n4201\n\n\n4\n대구광역시\n1997.01\n3345\n\n\n\n\n\n\n\n\ndf[\"시군구별\"].unique()\n\narray(['시군구별', '전국', '서울특별시', '부산광역시', '대구광역시', '인천광역시', '광주광역시', '대전광역시',\n       '울산광역시', '세종특별자치시', '경기도', '강원도', '충청북도', '충청남도', '전라북도', '전라남도',\n       '경상북도', '경상남도', '제주특별자치도'], dtype=object)\n\n\n필요한 데이터만 추출하기 위해서 데이터프레임에서 해당 데이터만 필터링을 진행합니다.\n\ndf = df[df[\"시군구별\"] != \"시군구별\"].copy()\ndf.shape\n\n(16848, 3)\n\n\n\ndf[\"시군구별\"].unique()\n\narray(['전국', '서울특별시', '부산광역시', '대구광역시', '인천광역시', '광주광역시', '대전광역시',\n       '울산광역시', '세종특별자치시', '경기도', '강원도', '충청북도', '충청남도', '전라북도', '전라남도',\n       '경상북도', '경상남도', '제주특별자치도'], dtype=object)\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n\n\n\n\n1\n전국\n1997.01\n63268\n\n\n2\n서울특별시\n1997.01\n13205\n\n\n3\n부산광역시\n1997.01\n4201\n\n\n4\n대구광역시\n1997.01\n3345\n\n\n5\n인천광역시\n1997.01\n3646\n\n\n\n\n\n\n\n\ndf[\"연도\"] = df[\"variable\"].str.split(\".\", expand=True)[0]\ndf[\"월\"] = df[\"variable\"].str.split(\".\", expand=True)[1]\ndf[\"성별\"] = df[\"variable\"].str.split(\".\", expand=True)[2]\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268\n1997\n01\nNone\n\n\n2\n서울특별시\n1997.01\n13205\n1997\n01\nNone\n\n\n3\n부산광역시\n1997.01\n4201\n1997\n01\nNone\n\n\n4\n대구광역시\n1997.01\n3345\n1997\n01\nNone\n\n\n5\n인천광역시\n1997.01\n3646\n1997\n01\nNone\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n연도\n월\n성별\n\n\n\n\n17779\n전라북도\n2022.12.2\n229\n2022\n12\n2\n\n\n17780\n전라남도\n2022.12.2\n250\n2022\n12\n2\n\n\n17781\n경상북도\n2022.12.2\n366\n2022\n12\n2\n\n\n17782\n경상남도\n2022.12.2\n503\n2022\n12\n2\n\n\n17783\n제주특별자치도\n2022.12.2\n121\n2022\n12\n2\n\n\n\n\n\n\n\n성별이 숫자(None, 1,2)로 되어있어서 데이터의 가독성을 위해서 문자열로 변경합니다.\n\ndf[\"성별\"].unique()\n\narray([None, '1', '2'], dtype=object)\n\n\n\ndf[\"성별\"].nunique()\n\n2\n\n\n\ndf[\"성별\"] = df[\"성별\"].fillna(\"전체\")\ndf[\"성별\"].unique()\n\narray(['전체', '1', '2'], dtype=object)\n\n\n\ndf[\"성별\"] = df[\"성별\"].replace(\"1\", \"남자\").replace(\"2\", \"여자\")\ndf[\"성별\"].unique()\n\narray(['전체', '남자', '여자'], dtype=object)\n\n\n\ndf[\"성별\"].value_counts()\n\n성별\n전체    5616\n남자    5616\n여자    5616\nName: count, dtype: int64\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\nvariable\nvalue\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268\n1997\n01\n전체\n\n\n2\n서울특별시\n1997.01\n13205\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646\n1997\n01\n전체\n\n\n\n\n\n\n\n불필요한 컬럼 및 컬럼을 변경하세요.\n\ndf = df.rename(columns={\"variable\": \"기간\", \"value\": \"출생아수\"})\ndf.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268\n1997\n01\n전체\n\n\n2\n서울특별시\n1997.01\n13205\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646\n1997\n01\n전체\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 16848 entries, 1 to 17783\nData columns (total 6 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   시군구별    16848 non-null  object\n 1   기간      16848 non-null  object\n 2   출생아수    16848 non-null  object\n 3   연도      16848 non-null  object\n 4   월       16848 non-null  object\n 5   성별      16848 non-null  object\ndtypes: object(6)\nmemory usage: 921.4+ KB\n\n\n-로 되어있는 데이터를 np.nan으로 변경합니다. 이때, np.nan으로 변경하는 경우 float 형태로 변경해야 합니다. 출생아수가 실수형으로 변경되는 것은 기술적인 이유가 있으니 주의하세요.\n\nimport numpy as np\ndf[\"출생아수\"] = df[\"출생아수\"].replace(\"-\", np.nan)\ndf[\"출생아수\"] = df[\"출생아수\"].astype(float)\ndf[\"출생아수\"].describe()\n\ncount    16308.000000\nmean      2898.333579\nstd       6406.925280\nmin         30.000000\n25%        589.000000\n50%        980.000000\n75%       1833.250000\nmax      63268.000000\nName: 출생아수, dtype: float64\n\n\n\ndf_all = df[(df[\"시군구별\"] == \"전국\") & (df[\"성별\"] == \"전체\")]\ndf_all.head(2)\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n1\n전국\n1997.01\n63268.0\n1997\n01\n전체\n\n\n58\n전국\n1997.02\n58144.0\n1997\n02\n전체\n\n\n\n\n\n\n\n\ndf_all = df_all[[\"연도\", \"월\", \"출생아수\"]].copy()\ndf_all.head()\n\n\n\n\n\n\n\n\n연도\n월\n출생아수\n\n\n\n\n1\n1997\n01\n63268.0\n\n\n58\n1997\n02\n58144.0\n\n\n115\n1997\n03\n62160.0\n\n\n172\n1997\n04\n56949.0\n\n\n229\n1997\n05\n55270.0\n\n\n\n\n\n\n\n\n# 한국어 처리를 위해서 아래 패키지를 설치하세요.\n# !pip install koreanize_matplotlib\n\n\n# 한국어 설정과 깔끔한 그래픽을 위해서 아래 설정을 진행합니다.\nimport matplotlib.pyplot as plt\nimport koreanize_matplotlib\n%config InlineBackend.figure_format = 'retina'\n\n\ndf_all.set_index([\"연도\", \"월\"]).plot(figsize=(15, 4))\n\n\n\n\n\n\n\n\n\ndf_all[-48:].set_index([\"연도\", \"월\"]).plot.bar(figsize=(15, 4))\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\n\n\nplt.figure(figsize=(15, 4))\nsns.lineplot(data=df_all, x=\"연도\", y=\"출생아수\", errorbar=None)\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.lineplot(data=df_all, x=\"연도\", y=\"출생아수\", errorbar=None, hue=\"월\")\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.barplot(data=df_all, x=\"연도\", y=\"출생아수\", errorbar=None, hue=\"월\")\n\n\n\n\n\n\n\n\n\ndf_local = df[df[\"시군구별\"] != \"전국\"].copy()\ndf_local.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201.0\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345.0\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646.0\n1997\n01\n전체\n\n\n6\n광주광역시\n1997.01\n2166.0\n1997\n01\n전체\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.pointplot(data=df_local, x=\"연도\", y=\"출생아수\", hue=\"성별\")\n\n\n\n\n\n\n\n\n\ndf_local_all = df_local[df_local[\"성별\"] == \"전체\"]\ndf_local_all.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201.0\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345.0\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646.0\n1997\n01\n전체\n\n\n6\n광주광역시\n1997.01\n2166.0\n1997\n01\n전체\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.pointplot(data=df_local_all, x=\"연도\", y=\"출생아수\")\n\n\n\n\n\n\n\n\n\ndf_local_all.columns\n\nIndex(['시군구별', '기간', '출생아수', '연도', '월', '성별'], dtype='object')\n\n\n\nplt.figure(figsize=(12, 4))\nsns.pointplot(data=df_local_all, x=\"연도\", y=\"출생아수\", hue=\"시군구별\", errorbar=None)\nplt.legend(loc='center right', bbox_to_anchor=(1.17, 0.5), ncol=1)\n\n\n\n\n\n\n\n\n\ndf_local_2 = df_local_all[df_local_all[\"시군구별\"].isin([\"서울특별시\", \"경기도\", \"세종특별자치시\"])]\ndf_local_2.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n9\n세종특별자치시\n1997.01\nNaN\n1997\n01\n전체\n\n\n10\n경기도\n1997.01\n13440.0\n1997\n01\n전체\n\n\n59\n서울특별시\n1997.02\n12239.0\n1997\n02\n전체\n\n\n66\n세종특별자치시\n1997.02\nNaN\n1997\n02\n전체\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15, 4))\nsns.pointplot(data=df_local_2, x=\"연도\", y=\"출생아수\", errorbar=None, hue=\"시군구별\")\n\n\n\n\n\n\n\n\n\ndf_sj = df[df[\"시군구별\"] == \"세종특별자치시\"].dropna(how=\"any\")\ndf_sj.head()\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n10269\n세종특별자치시\n2012.01\n73.0\n2012\n01\n전체\n\n\n10288\n세종특별자치시\n2012.01.1\n38.0\n2012\n01\n남자\n\n\n10307\n세종특별자치시\n2012.01.2\n35.0\n2012\n01\n여자\n\n\n10326\n세종특별자치시\n2012.02\n74.0\n2012\n02\n전체\n\n\n10345\n세종특별자치시\n2012.02.1\n43.0\n2012\n02\n남자\n\n\n\n\n\n\n\n\nimport numpy as np\nsns.pointplot(data=df_sj, x=\"연도\", y=\"출생아수\", errorbar=None, estimator=np.sum)\n\n\n\n\n\n\n\n\n\ndf_local_all\n\n\n\n\n\n\n\n\n시군구별\n기간\n출생아수\n연도\n월\n성별\n\n\n\n\n2\n서울특별시\n1997.01\n13205.0\n1997\n01\n전체\n\n\n3\n부산광역시\n1997.01\n4201.0\n1997\n01\n전체\n\n\n4\n대구광역시\n1997.01\n3345.0\n1997\n01\n전체\n\n\n5\n인천광역시\n1997.01\n3646.0\n1997\n01\n전체\n\n\n6\n광주광역시\n1997.01\n2166.0\n1997\n01\n전체\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n17741\n전라북도\n2022.12\n483.0\n2022\n12\n전체\n\n\n17742\n전라남도\n2022.12\n500.0\n2022\n12\n전체\n\n\n17743\n경상북도\n2022.12\n770.0\n2022\n12\n전체\n\n\n17744\n경상남도\n2022.12\n993.0\n2022\n12\n전체\n\n\n17745\n제주특별자치도\n2022.12\n233.0\n2022\n12\n전체\n\n\n\n\n5304 rows × 6 columns\n\n\n\n\nsns.relplot(data=df_local_all.sort_values(by=[\"연도\", \"월\"]), x=\"연도\", y=\"출생아수\", kind=\"line\", col=\"시군구별\", col_wrap=4, hue=\"시군구별\")\n\n\n\n\n\n\n\n\n\ndf_local_gender = df[(df[\"시군구별\"] != \"전국\") & (df[\"성별\"] !=  \"전체\")]\n\n\nsns.relplot(data=df_local_gender, x=\"연도\", y=\"출생아수\", kind=\"line\", col=\"시군구별\", col_wrap=4, hue=\"성별\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Day1. 전처리 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL02.html",
    "href": "DL02.html",
    "title": "3  Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)",
    "section": "",
    "text": "3.1 전처리 (Preprocessing)\n이 데이터셋은 잘 정제된 데이터셋이기 때문에 중복된 값이나 불량 데이터가 없다. 따라서 여기서는 Feature scaling 정도의 간단한 전처리만을 수행해보자.\n이 예시에서는 표준화(Standardization)를 쓴다.\n학습 데이터셋의 전처리 과정에서 사용한 매개변수(parameter)는 테스트에서 동일하게 사용해야 한다. 이 예시에서는 학습 데이터셋에서 구한 변수의 평균과 표준편차를 저장해놓고 테스트에서 동일하게 사용할 것이다.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL02.html#전처리-preprocessing",
    "href": "DL02.html#전처리-preprocessing",
    "title": "3  Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)",
    "section": "",
    "text": "Feature scaling\n\n0~1 사이에 맞추기\n\n최솟값을 빼고 (최댓값 - 최솟값)으로 나눈다.\n최댓값은 1이 되고, 최솟값은 0이 된다.\n\n표준화(Standardization)하기\n\n평균을 빼고 표준편차로 나눈다.\n원래 분포가 정규분포인 경우 평균이 0이고 표준편차가 1인 표준정규분포로 바뀐다.\n대부분의 값이 -2 ~ 2 사이에 위치한다.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL02.html#전처리nan-missing-value",
    "href": "DL02.html#전처리nan-missing-value",
    "title": "3  Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)",
    "section": "3.2 전처리(NaN, Missing Value)",
    "text": "3.2 전처리(NaN, Missing Value)\n\ndata.isnull().sum()\n\nlongitude               0\nlatitude                0\nhousing_median_age      0\ntotal_rooms             0\ntotal_bedrooms        207\npopulation              0\nhouseholds              0\nmedian_income           0\nmedian_house_value      0\nocean_proximity         0\ndtype: int64\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n\n\n\n\ncount\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20433.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n\n\nmean\n-119.569704\n35.631861\n28.639486\n2635.763081\n537.870553\n1425.476744\n499.539680\n3.870671\n206855.816909\n\n\nstd\n2.003532\n2.135952\n12.585558\n2181.615252\n421.385070\n1132.462122\n382.329753\n1.899822\n115395.615874\n\n\nmin\n-124.350000\n32.540000\n1.000000\n2.000000\n1.000000\n3.000000\n1.000000\n0.499900\n14999.000000\n\n\n25%\n-121.800000\n33.930000\n18.000000\n1447.750000\n296.000000\n787.000000\n280.000000\n2.563400\n119600.000000\n\n\n50%\n-118.490000\n34.260000\n29.000000\n2127.000000\n435.000000\n1166.000000\n409.000000\n3.534800\n179700.000000\n\n\n75%\n-118.010000\n37.710000\n37.000000\n3148.000000\n647.000000\n1725.000000\n605.000000\n4.743250\n264725.000000\n\n\nmax\n-114.310000\n41.950000\n52.000000\n39320.000000\n6445.000000\n35682.000000\n6082.000000\n15.000100\n500001.000000\n\n\n\n\n\n\n\n\n한 블록 내의 최대 침실 수는 6445개이고 평균 침실 수는 537개임을 알 수 있습니다. 데이터가 왜곡된 것 같으므로 히스토그램을 통해 이를 확인하겠습니다.\n\n\nplt.figure(figsize= (10, 6))\nsns.histplot(data['total_bedrooms'], color = '#005b96', kde= True);\n\n\n\n\n\n\n\n\n\n확실히 왜곡되어 있으므로 누락된 값은 블록 내 객실 수 중앙값으로 채웁니다.\n\n\ndata['total_bedrooms'].fillna(data['total_bedrooms'].median(), inplace= True)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL02.html#eda",
    "href": "DL02.html#eda",
    "title": "3  Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)",
    "section": "3.3 EDA",
    "text": "3.3 EDA\n\nplt.figure(figsize= (20, 8))\nsns.heatmap(data.corr(numeric_only=True), annot= True, cmap='YlGnBu')\nplt.show()\n\n\n\n\n\n\n\n\n\n중위소득은 분명 가장 중요한 특징입니다.\n\n\nsns.histplot(data['median_house_value'], color = '#005b96', kde= True);\n\n\n\n\n\n\n\n\n\ndata['median_house_value'].skew()\n\n0.9777632739098341\n\n\n\n우리의 목표 변수는 분명히 왜곡되어 있습니다. 따라서 로그 변환을 늦게 적용할 것입니다.\n\n\ndata.hist(bins = 30, figsize=(20, 15), color = '#005b96');\n\n\n\n\n\n\n\n\n많은 기능이 왜곡되어 있다는 것을 분명히 알 수 있습니다. 따라서 나중에 기능 변환을 수행할 때 이 문제를 해결해야 할 것입니다.\n어떻게 들여다봐도 문제가 많은 데이터..?, 범주형 변수도 같이 확인해보죠\n\nsns.countplot(x = data['ocean_proximity']);\n\n\n\n\n\n\n\n\n\ndata.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n        s=data[\"population\"]/100, label=\"population\", figsize=(15,8),\n        c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),colorbar=True,\n    )\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n3.3.1 특성공학\n\ndata['bed_per_room'] = data['total_bedrooms'] / data['total_rooms']\n\n\nX = data.drop(['median_house_value'], axis=1)\ny = np.log(data.median_house_value) # 로그 변환",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL02.html#특성-변환",
    "href": "DL02.html#특성-변환",
    "title": "3  Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)",
    "section": "3.4 특성 변환",
    "text": "3.4 특성 변환\n\nskew_df = pd.DataFrame(X.select_dtypes(np.number).columns, columns= ['Feature'])\nskew_df['Skew'] = skew_df['Feature'].apply(lambda feature: skew(X[feature]))\nskew_df['Abs_Skew'] = skew_df['Skew'].apply(abs)\nskew_df['Skewed'] = skew_df['Abs_Skew'].apply(lambda x: True if x &gt; 0.5 else False)\nskew_df\n\n\n\n\n\n\n\n\nFeature\nSkew\nAbs_Skew\nSkewed\n\n\n\n\n0\nlongitude\n-0.297780\n0.297780\nFalse\n\n\n1\nlatitude\n0.465919\n0.465919\nFalse\n\n\n2\nhousing_median_age\n0.060326\n0.060326\nFalse\n\n\n3\ntotal_rooms\n4.147042\n4.147042\nTrue\n\n\n4\ntotal_bedrooms\n3.480888\n3.480888\nTrue\n\n\n5\npopulation\n4.935500\n4.935500\nTrue\n\n\n6\nhouseholds\n3.410190\n3.410190\nTrue\n\n\n7\nmedian_income\n1.646537\n1.646537\nTrue\n\n\n8\nbed_per_room\n6.316445\n6.316445\nTrue\n\n\n\n\n\n\n\n\nskewed_columns = skew_df[skew_df['Abs_Skew'] &gt; 0.5]['Feature'].values\nskewed_columns\n\narray(['total_rooms', 'total_bedrooms', 'population', 'households',\n       'median_income', 'bed_per_room'], dtype=object)\n\n\n\nfor column in skewed_columns:\n    X[column] = np.log(X[column])\n\n\n3.4.1 Encoding\n\nencoder=LabelEncoder()\nX['ocean_proximity']=encoder.fit_transform(X['ocean_proximity'])\n\n\n\n3.4.2 Scaling\n\nX.head()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nocean_proximity\nbed_per_room\n\n\n\n\n0\n-122.23\n37.88\n41.0\n6.779922\n4.859812\n5.774552\n4.836282\n2.119287\n3\n-1.920110\n\n\n1\n-122.22\n37.86\n21.0\n8.867709\n7.008505\n7.783641\n7.037028\n2.116424\n3\n-1.859204\n\n\n2\n-122.24\n37.85\n52.0\n7.290975\n5.247024\n6.206576\n5.176150\n1.982022\n3\n-2.043951\n\n\n3\n-122.25\n37.85\n52.0\n7.149917\n5.459586\n6.324359\n5.389072\n1.730434\n3\n-1.690331\n\n\n4\n-122.25\n37.85\n52.0\n7.394493\n5.634790\n6.336826\n5.556828\n1.347086\n3\n-1.759704\n\n\n\n\n\n\n\n\nscaler = StandardScaler()\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X), index= X.index, columns= X.columns)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL02.html#데이터-나누기",
    "href": "DL02.html#데이터-나누기",
    "title": "3  Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)",
    "section": "3.5 데이터 나누기",
    "text": "3.5 데이터 나누기\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL02.html#모델-생성",
    "href": "DL02.html#모델-생성",
    "title": "3  Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)",
    "section": "3.6 모델 생성",
    "text": "3.6 모델 생성\n\n3.6.1 Linear Regression\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\npredictions_lr = lr.predict(X_test)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, predictions_lr))\nr2 = r2_score(y_test, predictions_lr)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.3452750790518536\nR-square: 0.632694341236971\n\n\n\n\n3.6.2 KNN\n\nknn = KNeighborsRegressor()\nknn.fit(X_train, y_train)\npredictions_knn = knn.predict(X_test)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, predictions_knn))\nr2 = r2_score(y_test, predictions_knn)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.29601285396707333\nR-square: 0.7300282680211424\n\n\n\n\n3.6.3 Random Forest\n\nrf = RandomForestRegressor(n_estimators= 100)\nrf.fit(X_train, y_train)\npredictions_rf = rf.predict(X_test)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, predictions_rf))\nr2 = r2_score(y_test, predictions_rf)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.23443947916794478\nR-square: 0.8306603537428374\n\n\n\n\n3.6.4 Gradient Boosting\n\ngbr = GradientBoostingRegressor()\ngbr.fit(X_train, y_train)\npredictions_gbr = gbr.predict(X_test)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, predictions_gbr))\nr2 = r2_score(y_test, predictions_gbr)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.26832719243746866\nR-square: 0.7781668094365237",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL02.html#모델-결정",
    "href": "DL02.html#모델-결정",
    "title": "3  Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)",
    "section": "3.7 모델 결정",
    "text": "3.7 모델 결정\n\nfinal_predictions = (\n    0.25 * predictions_gbr +\n    0.25 * predictions_rf +\n    0.25 * predictions_knn +\n    0.25 * predictions_lr\n)\n\n\nrmse = np.sqrt(mean_squared_error(y_test, final_predictions))\nr2 = r2_score(y_test, final_predictions)\n\nprint('RMSE:', rmse)\nprint('R-square:', r2)\n\nRMSE: 0.257662802570265\nR-square: 0.7954494719527825\n\n\n\nfinal_predictions\n\narray([10.97419641, 11.37878658, 12.7062257 , ..., 13.03923565,\n       11.33747207, 12.09494704])\n\n\n최종 예측을 원래 규모로 되돌리려면 최종 예측의 지수를 취해야 합니다.\n\nfinal_predictions = np.exp(final_predictions)\ny_test = np.exp(y_test)\n\n\npd.DataFrame({'Actual': y_test, 'Predicted': final_predictions.round(2)})\n\n\n\n\n\n\n\n\nActual\nPredicted\n\n\n\n\n20046\n47700.0\n58348.94\n\n\n3024\n45800.0\n87446.86\n\n\n15663\n500001.0\n329794.73\n\n\n20484\n218600.0\n269034.24\n\n\n9814\n278000.0\n252162.21\n\n\n...\n...\n...\n\n\n15362\n263300.0\n209975.79\n\n\n16623\n266800.0\n210500.56\n\n\n18086\n500001.0\n460116.80\n\n\n2144\n72300.0\n83907.65\n\n\n3665\n151500.0\n178965.27\n\n\n\n\n4128 rows × 2 columns",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL02.html#결과-확인",
    "href": "DL02.html#결과-확인",
    "title": "3  Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)",
    "section": "3.8 결과 확인",
    "text": "3.8 결과 확인\n\nplt.figure(figsize= (10, 6))\nsns.scatterplot(x= y_test, y= final_predictions, color= '#005b96')\nplt.xlabel('Actual House value')\nplt.ylabel('Predicted House Value')\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure(figsize= (10, 6))\nsns.residplot(x= y_test, y = final_predictions, color= '#005b96')\nplt.show()\n\n\n\n\n\n\n\n\n\nresid = y_test - final_predictions\nplt.figure(figsize= (10, 6))\nsns.histplot(resid)\nplt.xlabel('Error');",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day2. 기울기와 절편, 그리고 회귀 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL03.html",
    "href": "DL03.html",
    "title": "4  Day3. 머신러닝과 딥러닝 실습(Hands-On)",
    "section": "",
    "text": "4.1 딥러닝을 활용한 XOR 문제 해결\ndef XOR(x1, x2):\n    s1 = NAND(x1, x2)\n    s2 = OR(x1, x2)\n    return AND(s1, s2)\nprint(XOR(0,0)) # 0\nprint(XOR(0,1)) # 1\nprint(XOR(1,0)) # 1\nprint(XOR(1,1)) # 0\n\n0\n1\n1\n0",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Day3. 머신러닝과 딥러닝 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL03.html#sin-값-예측하기",
    "href": "DL03.html#sin-값-예측하기",
    "title": "4  Day3. 머신러닝과 딥러닝 실습(Hands-On)",
    "section": "4.2 Sin 값 예측하기",
    "text": "4.2 Sin 값 예측하기\n\nimport math\nimport torch\nimport matplotlib.pyplot as plt\n\nx = torch.linspace(-math.pi, math.pi, 1000)\ny = torch.sin(x)\n\na = torch.randn(())\nb = torch.randn(())\nc = torch.randn(())\nd = torch.randn(())\n\ny_random = a * x**3 + b * x**2 + c * x + d\n\nplt.subplot(2, 1, 1)\nplt.title(\"y true\")\nplt.plot(x, y)\n\nplt.subplot(2, 1, 2)\nplt.title(\"y radnom\")\nplt.plot(x, y_random)\nplt.show()\n\nlearning_rate = 1e-6\n\nfor epoch in range(2000):\n   y_pred = a * x**3 + b * x**2 + c * x + d\n\n   loss = (y_pred - y).pow(2).sum().item()\n   if epoch % 100 == 0:\n       print(f\"epoch{epoch+1} loss:{loss}\")\n\n   grad_y_pred = 2.0 * (y_pred - y)\n   grad_a = (grad_y_pred * x ** 3).sum()\n   grad_b = (grad_y_pred * x ** 2).sum()\n   grad_c = (grad_y_pred * x).sum()\n   grad_d = grad_y_pred.sum()\n\n   a -= learning_rate * grad_a\n   b -= learning_rate * grad_b\n   c -= learning_rate * grad_c\n   d -= learning_rate * grad_d\n\nplt.subplot(3, 1, 1)\nplt.title(\"y true\")\nplt.plot(x, y)\n\nplt.subplot(3, 1, 2)\nplt.title(\"y pred\")\nplt.plot(x, y_pred)\n\nplt.subplot(3, 1, 3)\nplt.plot(y_random)\nplt.title(\"y random\")\nplt.show()\n\n\n\n\n\n\n\n\nepoch1 loss:25594.9765625\nepoch101 loss:1265.33349609375\nepoch201 loss:1059.7664794921875\nepoch301 loss:892.087646484375\nepoch401 loss:751.0570678710938\nepoch501 loss:632.4374389648438\nepoch601 loss:532.6666870117188\nepoch701 loss:448.74884033203125\nepoch801 loss:378.1644287109375\nepoch901 loss:318.7945556640625\nepoch1001 loss:268.857177734375\nepoch1101 loss:226.853515625\nepoch1201 loss:191.5229949951172\nepoch1301 loss:161.80514526367188\nepoch1401 loss:136.8082275390625\nepoch1501 loss:115.7820816040039\nepoch1601 loss:98.09590911865234\nepoch1701 loss:83.21913146972656\nepoch1801 loss:70.70536041259766\nepoch1901 loss:60.17919921875",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Day3. 머신러닝과 딥러닝 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL04.html",
    "href": "DL04.html",
    "title": "5  Day4. CNN을 사용한 특징 기반 분류 v1.2 실습(Hands-On)",
    "section": "",
    "text": "5.0.1 M.L.P(Baseline Model with Multilayer Perceptrons)\nclass MLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Linear(784, 784)\n        self.act1 = nn.ReLU()\n        self.layer2 = nn.Linear(784, 10)\n        \n    def forward(self, x):\n        x = x.view(-1, 28 * 28)\n        x = self.act1(self.layer1(x))\n        x = self.layer2(x)\n        return x\nmodel = MLP()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n# optimizer = optim.Adam(model.parameters(), lr=0.01)\nloss_fn = nn.CrossEntropyLoss()\n\nn_epochs = 5\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in train_loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    model.eval()\n    acc = 0\n    count = 0\n    for X_batch, y_batch in test_loader:\n        y_pred = model(X_batch)\n        acc += (torch.argmax(y_pred, 1) == y_batch).float().sum()\n        count += len(y_batch)\n    acc = acc / count\n    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n\nEpoch 0: model accuracy 84.93%\nEpoch 1: model accuracy 88.31%\nEpoch 2: model accuracy 89.64%\nEpoch 3: model accuracy 90.02%\nEpoch 4: model accuracy 90.67%",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Day4. CNN을 사용한 특징 기반 분류 v1.2 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL04.html#lenet-5-구현",
    "href": "DL04.html#lenet-5-구현",
    "title": "5  Day4. CNN을 사용한 특징 기반 분류 v1.2 실습(Hands-On)",
    "section": "5.1 LeNet-5 구현",
    "text": "5.1 LeNet-5 구현\n\n5.1.1 LeNet-5 for MNIST\n\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n        self.act1 = nn.Tanh()\n        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)\n        self.act2 = nn.Tanh()\n        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n\n        self.conv3 = nn.Conv2d(16, 120, kernel_size=5, stride=1, padding=0)\n        self.act3 = nn.Tanh()\n\n        self.flat = nn.Flatten()\n        self.fc1 = nn.Linear(1*1*120, 84)\n        self.act4 = nn.Tanh()\n        self.fc2 = nn.Linear(84, 10)\n        \n    def forward(self, x):\n        x = self.act1(self.conv1(x))\n        x = self.pool1(x)\n        x = self.act2(self.conv2(x))\n        x = self.pool2(x)\n        x = self.act3(self.conv3(x))\n        x = self.act4(self.fc1(self.flat(x)))\n        x = self.fc2(x)\n        return x\n\n\nmodel = LeNet5()\noptimizer = optim.Adam(model.parameters())\nloss_fn = nn.CrossEntropyLoss()\n\nn_epochs = 5\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in train_loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # Validation\n    model.eval()\n    acc = 0\n    count = 0\n    for X_batch, y_batch in test_loader:\n        y_pred = model(X_batch)\n        acc += (torch.argmax(y_pred, 1) == y_batch).float().sum()\n        count += len(y_batch)\n    acc = acc / count\n    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n\nEpoch 0: model accuracy 95.43%\nEpoch 1: model accuracy 97.16%\nEpoch 2: model accuracy 97.77%\nEpoch 3: model accuracy 97.76%\nEpoch 4: model accuracy 98.44%\n\n\n\ntorch.save(model.state_dict(), \"LeNet5_20240129.pth\") # 모델 저장",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Day4. CNN을 사용한 특징 기반 분류 v1.2 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL04.html#cnn-모델-파라매터-확인-실습",
    "href": "DL04.html#cnn-모델-파라매터-확인-실습",
    "title": "5  Day4. CNN을 사용한 특징 기반 분류 v1.2 실습(Hands-On)",
    "section": "5.2 CNN 모델 파라매터 확인 실습",
    "text": "5.2 CNN 모델 파라매터 확인 실습\n\n# 임의의 텐서를 강제로 생성\ninputs = torch.Tensor(1, 1, 28, 28)\nprint('텐서의 크기 : {}'.format(inputs.shape))\n\n텐서의 크기 : torch.Size([1, 1, 28, 28])\n\n\n\nconv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\nprint(conv1)\n\nConv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n\n\n\nconv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\nprint(conv2)\n\nConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\n\n\npool = nn.MaxPool2d(2)\nprint(pool)\n\nMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\n\n\nout = conv1(inputs)\nprint(out.shape)\n\ntorch.Size([1, 32, 28, 28])\n\n\n\nout = pool(out)\nprint(out.shape)\n\ntorch.Size([1, 32, 14, 14])\n\n\n\nout = conv2(out)\nprint(out.shape)\n\ntorch.Size([1, 64, 14, 14])\n\n\n\nout = pool(out)\nprint(out.shape)\n\ntorch.Size([1, 64, 7, 7])\n\n\n\nprint(out.size(0), out.size(1), out.size(2), out.size(3))\n\n1 64 7 7\n\n\n\n# 첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼쳐라\nout = out.view(out.size(0), -1) \nprint(out.shape)\n\ntorch.Size([1, 3136])\n\n\n\nfc = nn.Linear(3136, 10) # input_dim = 3,136, output_dim = 10\nout = fc(out)\nprint(out.shape)\n\ntorch.Size([1, 10])\n\n\n\n5.2.1 View와 Reshape\n\nimport torch\nx = torch.arange(12)\nprint(x) # tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n\ntensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n\n\n\nprint(x.reshape(2, 6))\nprint(x.view(2, 6))\n\ntensor([[ 0,  1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10, 11]])\ntensor([[ 0,  1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10, 11]])\n\n\n\nprint(x.reshape(2, 3, -1)) # (2, 3, 2) 차원으로 자동 지정\nprint(x.view(2, 2, -1)) # (2, 2, 3) 차원으로 자동 지정\n\ntensor([[[ 0,  1],\n         [ 2,  3],\n         [ 4,  5]],\n\n        [[ 6,  7],\n         [ 8,  9],\n         [10, 11]]])\ntensor([[[ 0,  1,  2],\n         [ 3,  4,  5]],\n\n        [[ 6,  7,  8],\n         [ 9, 10, 11]]])\n\n\ntorch.view와 torch.reshape의 가장 큰 차이는 contiguous 속성을 만족하지 않는 텐서에 적용이 가능하느냐 여부입니다.\n\na = torch.randn(3, 4)\na.transpose_(0, 1)\nb = torch.randn(4, 3)\nprint(a)\nprint(b)\n\ntensor([[ 0.2699,  0.2880,  0.0943],\n        [ 0.2418,  1.3825,  0.3678],\n        [ 0.2878,  0.4216, -0.3238],\n        [ 0.8696,  0.7349, -0.2613]])\ntensor([[-0.0263, -2.1660, -0.6443],\n        [-0.5453, -1.3778, -1.1625],\n        [-0.9622, -0.5388,  0.1624],\n        [-0.0874, -0.0213,  0.4618]])\n\n\n\n# a 텐서 메모리 주소 예시\nfor i in range(4):\n    for j in range(3):\n        print(\"a :\", a[i][j].data_ptr())\n# b 텐서 메모리 주소 예시\nfor i in range(4):\n    for j in range(3):\n        print(\"b :\", b[i][j].data_ptr())\n\na : 3044972495872\na : 3044972495888\na : 3044972495904\na : 3044972495876\na : 3044972495892\na : 3044972495908\na : 3044972495880\na : 3044972495896\na : 3044972495912\na : 3044972495884\na : 3044972495900\na : 3044972495916\nb : 3044972496000\nb : 3044972496004\nb : 3044972496008\nb : 3044972496012\nb : 3044972496016\nb : 3044972496020\nb : 3044972496024\nb : 3044972496028\nb : 3044972496032\nb : 3044972496036\nb : 3044972496040\nb : 3044972496044\n\n\nb는 axis = 0인 오른쪽 방향으로 자료가 순서대로 저장됨에 비해, a는 transpose 연산을 거치며 axis = 1인 아래 방향으로 자료가 저장되고 있었습니다. 여기서, b처럼 axis 순서대로 자료가 저장된 상태를 contiguous = True 상태라고 부르며, a같이 자료 저장 순서가 원래 방향과 어긋난 경우를 contiguous = False 상태라고 합니다.\n텐서의 shape을 조작하는 과정에서 메모리 저장 상태가 변경되는 경우가 있습니다. 주로 narrow(), view(), expand(), transpose() 등 메소드를 사용하는 경우에 이 상태가 깨지는 것으로 알려져 있습니다.\n\ny = torch.ones(3, 4)\ny.transpose_(0, 1)\ny.is_contiguous() # False\n\nFalse\n\n\n\nprint(y.reshape(3, 2, 2)) # 실행 가능\n# print(y.view(3, 2, 2)) # 실행 불가\n\ntensor([[[1., 1.],\n         [1., 1.]],\n\n        [[1., 1.],\n         [1., 1.]],\n\n        [[1., 1.],\n         [1., 1.]]])\n\n\nRuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n따라서, 차원 변환을 적용하려는 텐서의 상태에 대하여 정확하게 파악하기가 모호한 경우에는 view 대신 reshape를 사용하시는 것을 권장드립니다.\n\n#!pip install torchinfo\n\n\nfrom torchinfo import summary\nsummary(model, input_size=(1, 1, 28, 28))\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLP                                      [1, 10]                   --\n├─Linear: 1-1                            [1, 784]                  615,440\n├─ReLU: 1-2                              [1, 784]                  --\n├─Linear: 1-3                            [1, 10]                   7,850\n==========================================================================================\nTotal params: 623,290\nTrainable params: 623,290\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 0.62\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.01\nParams size (MB): 2.49\nEstimated Total Size (MB): 2.50\n==========================================================================================\n\n\n\nimport torch.nn.functional as F\n\ndef findConv2dOutShape(H_in, W_in, conv, pool=2):\n    kernel_size = conv.kernel_size\n    stride = conv.stride\n    padding = conv.padding\n    dilation = conv.dilation\n\n    H_out = np.floor((H_in + 2*padding[0] - dilation[0]*(kernel_size[0]-1)-1) / stride[0] + 1)\n    W_out = np.floor((W_in + 2*padding[1] - dilation[1]*(kernel_size[1]-1)-1) / stride[1] + 1)\n\n    if pool:\n        H_out /= pool\n        W_out /= pool\n    \n    return int(H_out), int(W_out)\n\nclass Net(nn.Module):\n    def __init__(self, params):\n        super(Net, self).__init__()\n        C_in, H_in, W_in = params['input_shape']\n        init_f = params['initial_filters']\n        num_fc1 = params['num_fc1']\n        num_classes = params['num_classes']\n        self.dropout_rate = params['dropout_rate']\n\n        self.conv1 = nn.Conv2d(C_in, init_f, kernel_size=3)\n        h,w = findConv2dOutShape(H_in, W_in, self.conv1)\n        self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n        h,w = findConv2dOutShape(h, w, self.conv2)\n        self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n        h,w = findConv2dOutShape(h, w, self.conv3)\n        self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n        h,w = findConv2dOutShape(h, w, self.conv4)\n\n        self.num_flatten = h*w*8*init_f\n        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n        self.fc2 = nn.Linear(num_fc1, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv4(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, self.num_flatten)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, self.dropout_rate, training = self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Day4. CNN을 사용한 특징 기반 분류 v1.2 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL05.html",
    "href": "DL05.html",
    "title": "6  Day5. VGG와 ResNet 학습하기 실습(Hands-On)",
    "section": "",
    "text": "6.1 ResNet\nclass BasicBlock(nn.Module):\n   def __init__(self, in_channels, out_channels, kernel_size=3):\n       super(BasicBlock, self).__init__()\n       self.c1 = nn.Conv2d(in_channels, out_channels,kernel_size=kernel_size, padding=1)\n       self.c2 = nn.Conv2d(out_channels, out_channels,kernel_size=kernel_size, padding=1)\n       self.downsample = nn.Conv2d(in_channels, out_channels,kernel_size=1)\n       self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n       self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n       self.relu = nn.ReLU()\n   def forward(self, x):\n       x_ = x\n       x = self.c1(x)\n       x = self.bn1(x)\n       x = self.relu(x)\n       x = self.c2(x)\n       x = self.bn2(x)\n       x_ = self.downsample(x_)\n       x += x_\n       x = self.relu(x)\n       return x\nclass ResNet(nn.Module):\n   def __init__(self, num_classes=10):\n       super(ResNet, self).__init__()\n       self.b1 = BasicBlock(in_channels=3, out_channels=64)\n       self.b2 = BasicBlock(in_channels=64, out_channels=128)\n       self.b3 = BasicBlock(in_channels=128, out_channels=256)\n       self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n       self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n       self.fc2 = nn.Linear(in_features=2048, out_features=512)\n       self.fc3 = nn.Linear(in_features=512, out_features=num_classes)\n\n       self.relu = nn.ReLU()\n   def forward(self, x):\n       x = self.b1(x)\n       x = self.pool(x)\n       x = self.b2(x)\n       x = self.pool(x)\n       x = self.b3(x)\n       x = self.pool(x)\n       x = torch.flatten(x, start_dim=1)\n       x = self.fc1(x)\n       x = self.relu(x)\n       x = self.fc2(x)\n       x = self.relu(x)\n       x = self.fc3(x)\n       return x\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = ResNet(num_classes=10)\nmodel.to(device)\n\nResNet(\n  (b1): BasicBlock(\n    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (downsample): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (b2): BasicBlock(\n    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (b3): BasicBlock(\n    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n  (fc3): Linear(in_features=512, out_features=10, bias=True)\n  (relu): ReLU()\n)\nlr = 1e-4\noptim = Adam(model.parameters(), lr=lr)\n\nfor epoch in range(1):\n   iterator = tqdm.tqdm(train_loader)\n   for data, label in iterator:\n       optim.zero_grad()\n       preds = model(data.to(device))\n       loss = nn.CrossEntropyLoss()(preds, label.to(device))\n       loss.backward()\n       optim.step()\n       iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n\ntorch.save(model.state_dict(), \"ResNet.pth\")\n\nepoch:1 loss:1.2963857650756836: 100%|██████████| 1563/1563 [02:35&lt;00:00, 10.08it/s]\nmodel.load_state_dict(torch.load(\"ResNet.pth\", map_location=device))\nnum_corr = 0\nwith torch.no_grad():\n   for data, label in test_loader:\n       output = model(data.to(device))\n       preds = output.data.max(1)[1]\n       corr = preds.eq(label.to(device).data).sum().item()\n       num_corr += corr\n   print(f\"Accuracy:{(num_corr/len(test)) * 100.0}\")\n\nAccuracy:62.23",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Day5. VGG와 ResNet 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL05.html#vgg-전이학습",
    "href": "DL05.html#vgg-전이학습",
    "title": "6  Day5. VGG와 ResNet 학습하기 실습(Hands-On)",
    "section": "6.2 VGG 전이학습",
    "text": "6.2 VGG 전이학습\n\nimport torch\nimport torch.nn as nn\nfrom torchvision.models.vgg import vgg16, VGG16_Weights\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = vgg16(weights=VGG16_Weights.DEFAULT) # vgg 16 모델을 불러옴\n\nfc = nn.Sequential(                     # 분류층을 정의\n       nn.Linear(512 * 7 * 7, 4096),\n       nn.ReLU(),\n       nn.Dropout(), # 드롭아웃을 추가\n       nn.Linear(4096, 4096),\n       nn.ReLU(),\n       nn.Dropout(),\n       nn.Linear(4096, 10),\n   )\n\nmodel.classifier = fc # 분류층을 모델에 붙임\nmodel.to(device)\n\nVGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=10, bias=True)\n  )\n)\n\n\n\nlr = 1e-4\noptim = Adam(model.parameters(), lr=lr)\n\nfor epoch in range(1):\n   iterator = tqdm.tqdm(train_loader) # 학습 로그 출력\n   for data, label in iterator:\n       optim.zero_grad()\n       preds = model(data.to(device)) # 모델의 예측값 출력\n       loss = nn.CrossEntropyLoss()(preds, label.to(device))\n       loss.backward()\n       optim.step()\n       iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\ntorch.save(model.state_dict(), \"CIFAR_pretrained.pth\") # 모델 저장\n\nepoch:1 loss:0.28979870676994324: 100%|██████████| 1563/1563 [14:09&lt;00:00,  1.84it/s]\n\n\n\nmodel.load_state_dict(torch.load(\"CIFAR_pretrained.pth\", map_location=device))\nnum_corr = 0\nwith torch.no_grad():\n   for data, label in test_loader:\n       output = model(data.to(device))\n       preds = output.data.max(1)[1]\n       corr = preds.eq(label.to(device).data).sum().item()\n       num_corr += corr\n   print(f\"Accuracy:{(num_corr/len(test))*100.0}\")\n\nAccuracy:81.58999999999999\n\n\n\n6.2.1 분류기의 파라메터 확인\n\ntransforms = Compose([\n   RandomCrop((32, 32), padding=4),\n   RandomHorizontalFlip(p=0.5),\n   ToTensor(),\n   Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n])\n\n\ntrain = CIFAR10(root=\"data\", train=True, download=True, transform=transforms)\ntest = CIFAR10(root=\"data\", train=False, download=True, transform=transforms)\ntrain_loader = DataLoader(train, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test, batch_size=32, shuffle=False)\n\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data\\cifar-10-python.tar.gz\nExtracting data\\cifar-10-python.tar.gz to data\nFiles already downloaded and verified\n\n\n100%|██████████| 170498071/170498071 [00:36&lt;00:00, 4632622.12it/s]\n\n\n\nprint(train.data.shape)\n\n(50000, 32, 32, 3)\n\n\n\nfrom torchinfo import summary\nsummary(model, input_size=(1, 3, 32, 32))\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nVGG                                      [1, 10]                   --\n├─Sequential: 1-1                        [1, 512, 1, 1]            --\n│    └─Conv2d: 2-1                       [1, 64, 32, 32]           1,792\n│    └─ReLU: 2-2                         [1, 64, 32, 32]           --\n│    └─Conv2d: 2-3                       [1, 64, 32, 32]           36,928\n│    └─ReLU: 2-4                         [1, 64, 32, 32]           --\n│    └─MaxPool2d: 2-5                    [1, 64, 16, 16]           --\n│    └─Conv2d: 2-6                       [1, 128, 16, 16]          73,856\n│    └─ReLU: 2-7                         [1, 128, 16, 16]          --\n│    └─Conv2d: 2-8                       [1, 128, 16, 16]          147,584\n│    └─ReLU: 2-9                         [1, 128, 16, 16]          --\n│    └─MaxPool2d: 2-10                   [1, 128, 8, 8]            --\n│    └─Conv2d: 2-11                      [1, 256, 8, 8]            295,168\n│    └─ReLU: 2-12                        [1, 256, 8, 8]            --\n│    └─Conv2d: 2-13                      [1, 256, 8, 8]            590,080\n│    └─ReLU: 2-14                        [1, 256, 8, 8]            --\n│    └─Conv2d: 2-15                      [1, 256, 8, 8]            590,080\n│    └─ReLU: 2-16                        [1, 256, 8, 8]            --\n│    └─MaxPool2d: 2-17                   [1, 256, 4, 4]            --\n│    └─Conv2d: 2-18                      [1, 512, 4, 4]            1,180,160\n│    └─ReLU: 2-19                        [1, 512, 4, 4]            --\n│    └─Conv2d: 2-20                      [1, 512, 4, 4]            2,359,808\n│    └─ReLU: 2-21                        [1, 512, 4, 4]            --\n│    └─Conv2d: 2-22                      [1, 512, 4, 4]            2,359,808\n│    └─ReLU: 2-23                        [1, 512, 4, 4]            --\n│    └─MaxPool2d: 2-24                   [1, 512, 2, 2]            --\n│    └─Conv2d: 2-25                      [1, 512, 2, 2]            2,359,808\n│    └─ReLU: 2-26                        [1, 512, 2, 2]            --\n│    └─Conv2d: 2-27                      [1, 512, 2, 2]            2,359,808\n│    └─ReLU: 2-28                        [1, 512, 2, 2]            --\n│    └─Conv2d: 2-29                      [1, 512, 2, 2]            2,359,808\n│    └─ReLU: 2-30                        [1, 512, 2, 2]            --\n│    └─MaxPool2d: 2-31                   [1, 512, 1, 1]            --\n├─AdaptiveAvgPool2d: 1-2                 [1, 512, 7, 7]            --\n├─Sequential: 1-3                        [1, 10]                   --\n│    └─Linear: 2-32                      [1, 4096]                 102,764,544\n│    └─ReLU: 2-33                        [1, 4096]                 --\n│    └─Dropout: 2-34                     [1, 4096]                 --\n│    └─Linear: 2-35                      [1, 4096]                 16,781,312\n│    └─ReLU: 2-36                        [1, 4096]                 --\n│    └─Dropout: 2-37                     [1, 4096]                 --\n│    └─Linear: 2-38                      [1, 10]                   40,970\n==========================================================================================\nTotal params: 134,301,514\nTrainable params: 134,301,514\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 433.06\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 2.28\nParams size (MB): 537.21\nEstimated Total Size (MB): 539.50\n==========================================================================================",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Day5. VGG와 ResNet 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html",
    "href": "DL06.html",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "",
    "text": "7.1 데이터 확인\nimport pandas as pd\ndata = pd.read_csv(\"./data/Netflix_2015-2019.csv\")  # 데이터 파일을 읽어옴\ndata.head()  # 5개의 데이터를 표시\n\n\n\n\n\n\n\n\nDate\nOpen\nHigh\nLow\nVolume\nClose\n\n\n\n\n0\n2015-12-16\n120\n123\n118\n13181000\n123\n\n\n1\n2015-12-17\n124\n126\n122\n17284900\n123\n\n\n2\n2015-12-18\n121\n122\n118\n17948100\n118\n\n\n3\n2015-12-21\n120\n120\n116\n11670000\n117\n\n\n4\n2015-12-22\n117\n117\n115\n9689000\n116",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#데이터셋-전체-확인",
    "href": "DL06.html#데이터셋-전체-확인",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.2 데이터셋 전체 확인",
    "text": "7.2 데이터셋 전체 확인\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 967 entries, 0 to 966\nData columns (total 6 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   Date    967 non-null    object\n 1   Open    967 non-null    int64 \n 2   High    967 non-null    int64 \n 3   Low     967 non-null    int64 \n 4   Volume  967 non-null    int64 \n 5   Close   967 non-null    int64 \ndtypes: int64(5), object(1)\nmemory usage: 45.5+ KB",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#데이터의-분포-확인",
    "href": "DL06.html#데이터의-분포-확인",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.3 데이터의 분포 확인",
    "text": "7.3 데이터의 분포 확인\n\nimport matplotlib.pyplot as plt\ndata_used = data.iloc[:, 1:4]  # 개장가, 최고가, 최저가 추가\ndata_used[\"Close\"] = data[\"Close\"]  # 종가 추가\nhist = data_used.hist()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#넷플릭스-데이터셋-정의",
    "href": "DL06.html#넷플릭스-데이터셋-정의",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.4 넷플릭스 데이터셋 정의",
    "text": "7.4 넷플릭스 데이터셋 정의\n\nimport numpy as np\nfrom torch.utils.data.dataset import Dataset\n\nclass Netflix(Dataset):\n    def __init__(self):\n        self.csv = pd.read_csv(\"./data/Netflix_2015-2019.csv\")\n\n        self.data = self.csv.iloc[:, 1:4].values\n        self.data = self.data / np.max(self.data)\n\n        self.label = data[\"Close\"].values\n        self.label = self.label / np.max(self.label)\n\n    def __len__(self):\n        return len(self.data) - 30\n\n    def __getitem__(self, i):\n        data = self.data[i:i+30]\n        label = self.label[i+30]\n        return data, label\n\n\nfrom torch.utils.data.dataloader import DataLoader\ndataset = Netflix()\nloader = DataLoader(dataset, batch_size=32)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#rnn-클래스-정의하기",
    "href": "DL06.html#rnn-클래스-정의하기",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.5 RNN 클래스 정의하기",
    "text": "7.5 RNN 클래스 정의하기\n\nimport torch\nimport torch.nn as nn\n\nclass RNN(nn.Module):\n   def __init__(self):\n       super(RNN, self).__init__()\n       self.rnn = nn.RNN(input_size=3, hidden_size=8, num_layers=5, batch_first=True)\n       # (30,3) or (3,30)\n       # batch_first =&gt; (32,30,3) / (30,3,32)\n       \n       # 주가를 예측하는 MLP층 정의\n       self.fc1 = nn.Linear(in_features=240, out_features=64)\n       self.fc2 = nn.Linear(in_features=64, out_features=1)\n       self.relu = nn.ReLU() # 활성화 함수 정의\n\n   def forward(self, x, h0):\n       x, hn = self.rnn(x, h0) # RNN층의 출력\n\n       # MLP층의 입력으로 사용될 수 있도록 모양 변경\n       x = torch.reshape(x, (x.shape[0], -1))\n\n       # MLP 층을 이용해 종가를 예측\n       x = self.fc1(x)\n       x = self.relu(x)\n       x = self.fc2(x)\n\n       # 예측한 종가를 1차원 벡터로 표현\n       x = torch.flatten(x)\n\n       return x",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#모델과-데이터셋-정의",
    "href": "DL06.html#모델과-데이터셋-정의",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.6 모델과 데이터셋 정의",
    "text": "7.6 모델과 데이터셋 정의\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = RNN().to(device)  # 모델의 정의",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#최적화-정의",
    "href": "DL06.html#최적화-정의",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.7 최적화 정의",
    "text": "7.7 최적화 정의\n\nfrom torch.optim.adam import Adam\noptim = Adam(params=model.parameters(), lr=0.0001) # 사용할 최적화를 설정",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#학습-루프-정의",
    "href": "DL06.html#학습-루프-정의",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.8 학습 루프 정의",
    "text": "7.8 학습 루프 정의\n\nimport tqdm\nfor epoch in range(200):\n   iterator = tqdm.tqdm(loader)\n   for data, label in iterator:\n       optim.zero_grad()\n\n       # 초기 은닉 상태\n       h0 = torch.zeros(5, data.shape[0], 8).to(device)\n\n       # 모델의 예측값\n       pred = model(data.type(torch.FloatTensor).to(device), h0)\n\n       # 손실의 계산\n       loss = nn.MSELoss()(pred, label.type(torch.FloatTensor).to(device))\n       \n       # 오차 역전파\n       loss.backward()  \n       \n       # 최적화 진행\n       optim.step() \n\n       iterator.set_description(f\"epoch{epoch} loss:{loss.item()}\")\n\ntorch.save(model.state_dict(), \"./rnn.pth\")  # 모델 저장\n\nepoch0 loss:0.1133282482624054: 100%|██████████| 30/30 [00:00&lt;00:00, 119.58it/s] \nepoch1 loss:0.030863119289278984: 100%|██████████| 30/30 [00:00&lt;00:00, 121.90it/s] \nepoch2 loss:0.012668101117014885: 100%|██████████| 30/30 [00:00&lt;00:00, 123.85it/s]\nepoch3 loss:0.00995593797415495: 100%|██████████| 30/30 [00:00&lt;00:00, 122.52it/s] \nepoch4 loss:0.009051559492945671: 100%|██████████| 30/30 [00:00&lt;00:00, 129.73it/s] \nepoch5 loss:0.0077210282906889915: 100%|██████████| 30/30 [00:00&lt;00:00, 123.01it/s]\nepoch6 loss:0.005778169259428978: 100%|██████████| 30/30 [00:00&lt;00:00, 121.98it/s]\nepoch7 loss:0.0030504465103149414: 100%|██████████| 30/30 [00:00&lt;00:00, 124.79it/s]\nepoch8 loss:0.00045336777111515403: 100%|██████████| 30/30 [00:00&lt;00:00, 126.42it/s]\nepoch9 loss:0.0036704300437122583: 100%|██████████| 30/30 [00:00&lt;00:00, 126.42it/s]\nepoch10 loss:0.0023120916448533535: 100%|██████████| 30/30 [00:00&lt;00:00, 119.69it/s]\nepoch11 loss:0.005660854279994965: 100%|██████████| 30/30 [00:00&lt;00:00, 130.78it/s] \nepoch12 loss:0.006029938813298941: 100%|██████████| 30/30 [00:00&lt;00:00, 136.85it/s] \nepoch13 loss:0.005122475326061249: 100%|██████████| 30/30 [00:00&lt;00:00, 122.28it/s] \nepoch14 loss:0.005853748880326748: 100%|██████████| 30/30 [00:00&lt;00:00, 119.62it/s] \nepoch15 loss:0.006356183905154467: 100%|██████████| 30/30 [00:00&lt;00:00, 122.83it/s] \nepoch16 loss:0.006075398065149784: 100%|██████████| 30/30 [00:00&lt;00:00, 133.14it/s] \nepoch17 loss:0.00603263545781374: 100%|██████████| 30/30 [00:00&lt;00:00, 123.29it/s]   \nepoch18 loss:0.006256675347685814: 100%|██████████| 30/30 [00:00&lt;00:00, 130.87it/s]  \nepoch19 loss:0.006165366154164076: 100%|██████████| 30/30 [00:00&lt;00:00, 125.39it/s] \nepoch20 loss:0.006183885503560305: 100%|██████████| 30/30 [00:00&lt;00:00, 135.64it/s]  \nepoch21 loss:0.006131547968834639: 100%|██████████| 30/30 [00:00&lt;00:00, 126.95it/s]  \nepoch22 loss:0.006229641381651163: 100%|██████████| 30/30 [00:00&lt;00:00, 121.69it/s]  \nepoch23 loss:0.0061165704391896725: 100%|██████████| 30/30 [00:00&lt;00:00, 134.40it/s] \nepoch24 loss:0.006140000652521849: 100%|██████████| 30/30 [00:00&lt;00:00, 123.59it/s] \nepoch25 loss:0.0061017959378659725: 100%|██████████| 30/30 [00:00&lt;00:00, 124.61it/s] \nepoch26 loss:0.006118049845099449: 100%|██████████| 30/30 [00:00&lt;00:00, 119.02it/s]  \nepoch27 loss:0.006087516900151968: 100%|██████████| 30/30 [00:00&lt;00:00, 130.29it/s]  \nepoch28 loss:0.006020728498697281: 100%|██████████| 30/30 [00:00&lt;00:00, 125.25it/s]  \nepoch29 loss:0.006041453219950199: 100%|██████████| 30/30 [00:00&lt;00:00, 132.88it/s] \nepoch30 loss:0.0060264477506279945: 100%|██████████| 30/30 [00:00&lt;00:00, 121.10it/s] \nepoch31 loss:0.005958861205726862: 100%|██████████| 30/30 [00:00&lt;00:00, 127.80it/s]  \nepoch32 loss:0.005957175046205521: 100%|██████████| 30/30 [00:00&lt;00:00, 118.89it/s]  \nepoch33 loss:0.005941562820225954: 100%|██████████| 30/30 [00:00&lt;00:00, 126.50it/s]  \nepoch34 loss:0.005897947121411562: 100%|██████████| 30/30 [00:00&lt;00:00, 126.41it/s]  \nepoch35 loss:0.005903737619519234: 100%|██████████| 30/30 [00:00&lt;00:00, 120.83it/s]  \nepoch36 loss:0.005882508587092161: 100%|██████████| 30/30 [00:00&lt;00:00, 136.39it/s]  \nepoch37 loss:0.005844305735081434: 100%|██████████| 30/30 [00:00&lt;00:00, 122.00it/s]  \nepoch38 loss:0.00581583334133029: 100%|██████████| 30/30 [00:00&lt;00:00, 134.36it/s]   \nepoch39 loss:0.005784646607935429: 100%|██████████| 30/30 [00:00&lt;00:00, 120.66it/s]  \nepoch40 loss:0.005783306900411844: 100%|██████████| 30/30 [00:00&lt;00:00, 132.82it/s] \nepoch41 loss:0.005727968644350767: 100%|██████████| 30/30 [00:00&lt;00:00, 114.25it/s]  \nepoch42 loss:0.005704001989215612: 100%|██████████| 30/30 [00:00&lt;00:00, 118.70it/s] \nepoch43 loss:0.005667759105563164: 100%|██████████| 30/30 [00:00&lt;00:00, 117.99it/s]  \nepoch44 loss:0.005675178486853838: 100%|██████████| 30/30 [00:00&lt;00:00, 124.57it/s]  \nepoch45 loss:0.005601053591817617: 100%|██████████| 30/30 [00:00&lt;00:00, 125.41it/s]  \nepoch46 loss:0.005596708972007036: 100%|██████████| 30/30 [00:00&lt;00:00, 125.38it/s]  \nepoch47 loss:0.005540730431675911: 100%|██████████| 30/30 [00:00&lt;00:00, 129.25it/s]  \nepoch48 loss:0.005552222486585379: 100%|██████████| 30/30 [00:00&lt;00:00, 124.38it/s]  \nepoch49 loss:0.0054680658504366875: 100%|██████████| 30/30 [00:00&lt;00:00, 128.92it/s] \nepoch50 loss:0.005474218633025885: 100%|██████████| 30/30 [00:00&lt;00:00, 125.39it/s]  \nepoch51 loss:0.005416974890977144: 100%|██████████| 30/30 [00:00&lt;00:00, 134.03it/s]  \nepoch52 loss:0.005408560857176781: 100%|██████████| 30/30 [00:00&lt;00:00, 123.57it/s] \nepoch53 loss:0.005350365769118071: 100%|██████████| 30/30 [00:00&lt;00:00, 129.45it/s]  \nepoch54 loss:0.005339012015610933: 100%|██████████| 30/30 [00:00&lt;00:00, 118.51it/s]  \nepoch55 loss:0.005309702828526497: 100%|██████████| 30/30 [00:00&lt;00:00, 124.97it/s]  \nepoch56 loss:0.005278876982629299: 100%|██████████| 30/30 [00:00&lt;00:00, 122.95it/s] \nepoch57 loss:0.005240301601588726: 100%|██████████| 30/30 [00:00&lt;00:00, 129.30it/s] \nepoch58 loss:0.0052159191109240055: 100%|██████████| 30/30 [00:00&lt;00:00, 121.82it/s] \nepoch59 loss:0.00516312662512064: 100%|██████████| 30/30 [00:00&lt;00:00, 127.80it/s]   \nepoch60 loss:0.005157516337931156: 100%|██████████| 30/30 [00:00&lt;00:00, 132.02it/s] \nepoch61 loss:0.005105071235448122: 100%|██████████| 30/30 [00:00&lt;00:00, 126.66it/s] \nepoch62 loss:0.005099133588373661: 100%|██████████| 30/30 [00:00&lt;00:00, 133.47it/s]  \nepoch63 loss:0.005014801397919655: 100%|██████████| 30/30 [00:00&lt;00:00, 126.49it/s]  \nepoch64 loss:0.004990304354578257: 100%|██████████| 30/30 [00:00&lt;00:00, 136.48it/s] \nepoch65 loss:0.004957042634487152: 100%|██████████| 30/30 [00:00&lt;00:00, 115.51it/s]  \nepoch66 loss:0.004911202006042004: 100%|██████████| 30/30 [00:00&lt;00:00, 129.49it/s]  \nepoch67 loss:0.0048713963478803635: 100%|██████████| 30/30 [00:00&lt;00:00, 126.50it/s] \nepoch68 loss:0.004812187515199184: 100%|██████████| 30/30 [00:00&lt;00:00, 128.64it/s]  \nepoch69 loss:0.004762388300150633: 100%|██████████| 30/30 [00:00&lt;00:00, 117.37it/s]  \nepoch70 loss:0.004720356781035662: 100%|██████████| 30/30 [00:00&lt;00:00, 110.17it/s]  \nepoch71 loss:0.0046601807698607445: 100%|██████████| 30/30 [00:00&lt;00:00, 110.69it/s] \nepoch72 loss:0.004588132258504629: 100%|██████████| 30/30 [00:00&lt;00:00, 110.40it/s]  \nepoch73 loss:0.004531672690063715: 100%|██████████| 30/30 [00:00&lt;00:00, 110.26it/s]  \nepoch74 loss:0.004467759281396866: 100%|██████████| 30/30 [00:00&lt;00:00, 97.47it/s]   \nepoch75 loss:0.004409820772707462: 100%|██████████| 30/30 [00:00&lt;00:00, 91.22it/s] \nepoch76 loss:0.004338240250945091: 100%|██████████| 30/30 [00:00&lt;00:00, 95.92it/s] \nepoch77 loss:0.0042843446135520935: 100%|██████████| 30/30 [00:00&lt;00:00, 96.10it/s]\nepoch78 loss:0.004217283800244331: 100%|██████████| 30/30 [00:00&lt;00:00, 113.11it/s]  \nepoch79 loss:0.0041459971107542515: 100%|██████████| 30/30 [00:00&lt;00:00, 111.51it/s] \nepoch80 loss:0.004060149192810059: 100%|██████████| 30/30 [00:00&lt;00:00, 97.70it/s]   \nepoch81 loss:0.0040906621143221855: 100%|██████████| 30/30 [00:00&lt;00:00, 71.76it/s]\nepoch82 loss:0.0038173487409949303: 100%|██████████| 30/30 [00:00&lt;00:00, 113.22it/s] \nepoch83 loss:0.003970103804022074: 100%|██████████| 30/30 [00:00&lt;00:00, 114.97it/s]  \nepoch84 loss:0.003781592706218362: 100%|██████████| 30/30 [00:00&lt;00:00, 123.48it/s]  \nepoch85 loss:0.003906263969838619: 100%|██████████| 30/30 [00:00&lt;00:00, 117.57it/s]  \nepoch86 loss:0.0037786427419632673: 100%|██████████| 30/30 [00:00&lt;00:00, 116.23it/s] \nepoch87 loss:0.0037665064446628094: 100%|██████████| 30/30 [00:00&lt;00:00, 120.12it/s] \nepoch88 loss:0.003673359751701355: 100%|██████████| 30/30 [00:00&lt;00:00, 119.77it/s] \nepoch89 loss:0.0036173653788864613: 100%|██████████| 30/30 [00:00&lt;00:00, 113.94it/s] \nepoch90 loss:0.0035650485660880804: 100%|██████████| 30/30 [00:00&lt;00:00, 115.48it/s] \nepoch91 loss:0.0035149981267750263: 100%|██████████| 30/30 [00:00&lt;00:00, 126.76it/s] \nepoch92 loss:0.0034552705474197865: 100%|██████████| 30/30 [00:00&lt;00:00, 112.03it/s]\nepoch93 loss:0.0034008114598691463: 100%|██████████| 30/30 [00:00&lt;00:00, 123.59it/s] \nepoch94 loss:0.003343059681355953: 100%|██████████| 30/30 [00:00&lt;00:00, 121.64it/s] \nepoch95 loss:0.0032971641048789024: 100%|██████████| 30/30 [00:00&lt;00:00, 116.74it/s] \nepoch96 loss:0.003225145861506462: 100%|██████████| 30/30 [00:00&lt;00:00, 115.83it/s]  \nepoch97 loss:0.0031819292344152927: 100%|██████████| 30/30 [00:00&lt;00:00, 128.48it/s]\nepoch98 loss:0.0031142625957727432: 100%|██████████| 30/30 [00:00&lt;00:00, 116.01it/s] \nepoch99 loss:0.0030629942193627357: 100%|██████████| 30/30 [00:00&lt;00:00, 124.85it/s] \nepoch100 loss:0.002995492424815893: 100%|██████████| 30/30 [00:00&lt;00:00, 112.66it/s]  \nepoch101 loss:0.0029346959199756384: 100%|██████████| 30/30 [00:00&lt;00:00, 119.34it/s] \nepoch102 loss:0.0028710351325571537: 100%|██████████| 30/30 [00:00&lt;00:00, 118.52it/s] \nepoch103 loss:0.0028376334812492132: 100%|██████████| 30/30 [00:00&lt;00:00, 121.42it/s] \nepoch104 loss:0.0027558174915611744: 100%|██████████| 30/30 [00:00&lt;00:00, 117.53it/s] \nepoch105 loss:0.002681717276573181: 100%|██████████| 30/30 [00:00&lt;00:00, 112.55it/s]  \nepoch106 loss:0.0026482255198061466: 100%|██████████| 30/30 [00:00&lt;00:00, 118.73it/s] \nepoch107 loss:0.002609373303130269: 100%|██████████| 30/30 [00:00&lt;00:00, 128.86it/s]  \nepoch108 loss:0.002561823930591345: 100%|██████████| 30/30 [00:00&lt;00:00, 123.00it/s]  \nepoch109 loss:0.0025207102298736572: 100%|██████████| 30/30 [00:00&lt;00:00, 114.42it/s] \nepoch110 loss:0.002469426952302456: 100%|██████████| 30/30 [00:00&lt;00:00, 121.54it/s] \nepoch111 loss:0.0024231309071183205: 100%|██████████| 30/30 [00:00&lt;00:00, 113.24it/s]\nepoch112 loss:0.002365459455177188: 100%|██████████| 30/30 [00:00&lt;00:00, 117.43it/s]  \nepoch113 loss:0.0023124138824641705: 100%|██████████| 30/30 [00:00&lt;00:00, 112.73it/s] \nepoch114 loss:0.002249119570478797: 100%|██████████| 30/30 [00:00&lt;00:00, 116.26it/s] \nepoch115 loss:0.0021924935281276703: 100%|██████████| 30/30 [00:00&lt;00:00, 116.57it/s]\nepoch116 loss:0.002154420129954815: 100%|██████████| 30/30 [00:00&lt;00:00, 112.19it/s]  \nepoch117 loss:0.002107753185555339: 100%|██████████| 30/30 [00:00&lt;00:00, 120.34it/s] \nepoch118 loss:0.0020624306052923203: 100%|██████████| 30/30 [00:00&lt;00:00, 116.33it/s] \nepoch119 loss:0.00202119629830122: 100%|██████████| 30/30 [00:00&lt;00:00, 125.36it/s]   \nepoch120 loss:0.001973542384803295: 100%|██████████| 30/30 [00:00&lt;00:00, 116.95it/s]  \nepoch121 loss:0.001920867944136262: 100%|██████████| 30/30 [00:00&lt;00:00, 122.57it/s]  \nepoch122 loss:0.0018701364751905203: 100%|██████████| 30/30 [00:00&lt;00:00, 112.01it/s] \nepoch123 loss:0.0018160560866817832: 100%|██████████| 30/30 [00:00&lt;00:00, 114.94it/s]\nepoch124 loss:0.001759301288984716: 100%|██████████| 30/30 [00:00&lt;00:00, 122.99it/s]  \nepoch125 loss:0.0016985404072329402: 100%|██████████| 30/30 [00:00&lt;00:00, 111.75it/s] \nepoch126 loss:0.001650456222705543: 100%|██████████| 30/30 [00:00&lt;00:00, 123.63it/s]  \nepoch127 loss:0.0015937809366732836: 100%|██████████| 30/30 [00:00&lt;00:00, 104.58it/s]\nepoch128 loss:0.0015555077698081732: 100%|██████████| 30/30 [00:00&lt;00:00, 111.63it/s]\nepoch129 loss:0.0015194652369245887: 100%|██████████| 30/30 [00:00&lt;00:00, 121.32it/s] \nepoch130 loss:0.001473985961638391: 100%|██████████| 30/30 [00:00&lt;00:00, 118.15it/s]  \nepoch131 loss:0.0014418229693546891: 100%|██████████| 30/30 [00:00&lt;00:00, 123.16it/s] \nepoch132 loss:0.0013955087633803487: 100%|██████████| 30/30 [00:00&lt;00:00, 111.74it/s]\nepoch133 loss:0.0013522175140678883: 100%|██████████| 30/30 [00:00&lt;00:00, 117.16it/s] \nepoch134 loss:0.001302353455685079: 100%|██████████| 30/30 [00:00&lt;00:00, 119.08it/s] \nepoch135 loss:0.0012536747381091118: 100%|██████████| 30/30 [00:00&lt;00:00, 118.57it/s] \nepoch136 loss:0.0012033925158903003: 100%|██████████| 30/30 [00:00&lt;00:00, 128.07it/s]\nepoch137 loss:0.0011487404117360711: 100%|██████████| 30/30 [00:00&lt;00:00, 118.63it/s]\nepoch138 loss:0.0011151385260745883: 100%|██████████| 30/30 [00:00&lt;00:00, 116.61it/s]\nepoch139 loss:0.0010848306119441986: 100%|██████████| 30/30 [00:00&lt;00:00, 121.17it/s]\nepoch140 loss:0.0010581339010968804: 100%|██████████| 30/30 [00:00&lt;00:00, 112.66it/s] \nepoch141 loss:0.0010224267607554793: 100%|██████████| 30/30 [00:00&lt;00:00, 123.86it/s]\nepoch142 loss:0.0009922855533659458: 100%|██████████| 30/30 [00:00&lt;00:00, 113.65it/s]\nepoch143 loss:0.0009605060913600028: 100%|██████████| 30/30 [00:00&lt;00:00, 126.86it/s] \nepoch144 loss:0.000924227642826736: 100%|██████████| 30/30 [00:00&lt;00:00, 118.28it/s]  \nepoch145 loss:0.0008843218092806637: 100%|██████████| 30/30 [00:00&lt;00:00, 120.95it/s]\nepoch146 loss:0.0008454030612483621: 100%|██████████| 30/30 [00:00&lt;00:00, 119.41it/s] \nepoch147 loss:0.0008045530994422734: 100%|██████████| 30/30 [00:00&lt;00:00, 115.48it/s] \nepoch148 loss:0.000767334655392915: 100%|██████████| 30/30 [00:00&lt;00:00, 126.78it/s]  \nepoch149 loss:0.0007330970256589353: 100%|██████████| 30/30 [00:00&lt;00:00, 120.77it/s] \nepoch150 loss:0.0006993492715992033: 100%|██████████| 30/30 [00:00&lt;00:00, 116.16it/s] \nepoch151 loss:0.0006747493171133101: 100%|██████████| 30/30 [00:00&lt;00:00, 110.30it/s] \nepoch152 loss:0.0006520745810121298: 100%|██████████| 30/30 [00:00&lt;00:00, 121.44it/s] \nepoch153 loss:0.0006302078254520893: 100%|██████████| 30/30 [00:00&lt;00:00, 118.10it/s] \nepoch154 loss:0.0006130611873231828: 100%|██████████| 30/30 [00:00&lt;00:00, 111.79it/s]\nepoch155 loss:0.0005927855963818729: 100%|██████████| 30/30 [00:00&lt;00:00, 112.85it/s] \nepoch156 loss:0.0005751944263465703: 100%|██████████| 30/30 [00:00&lt;00:00, 111.45it/s] \nepoch157 loss:0.0005558125558309257: 100%|██████████| 30/30 [00:00&lt;00:00, 112.56it/s]\nepoch158 loss:0.0005329706473276019: 100%|██████████| 30/30 [00:00&lt;00:00, 120.48it/s] \nepoch159 loss:0.0005123721202835441: 100%|██████████| 30/30 [00:00&lt;00:00, 116.03it/s] \nepoch160 loss:0.0004912657896056771: 100%|██████████| 30/30 [00:00&lt;00:00, 114.78it/s] \nepoch161 loss:0.000469820894068107: 100%|██████████| 30/30 [00:00&lt;00:00, 115.93it/s]  \nepoch162 loss:0.00045026993029750884: 100%|██████████| 30/30 [00:00&lt;00:00, 118.67it/s]\nepoch163 loss:0.00043349116458557546: 100%|██████████| 30/30 [00:00&lt;00:00, 118.30it/s]\nepoch164 loss:0.00041893270099535584: 100%|██████████| 30/30 [00:00&lt;00:00, 115.44it/s]\nepoch165 loss:0.0004081387014593929: 100%|██████████| 30/30 [00:00&lt;00:00, 116.95it/s] \nepoch166 loss:0.0003977203741669655: 100%|██████████| 30/30 [00:00&lt;00:00, 119.47it/s] \nepoch167 loss:0.000391818699426949: 100%|██████████| 30/30 [00:00&lt;00:00, 111.75it/s]  \nepoch168 loss:0.00038579796091653407: 100%|██████████| 30/30 [00:00&lt;00:00, 119.55it/s]\nepoch169 loss:0.00038047824637033045: 100%|██████████| 30/30 [00:00&lt;00:00, 113.89it/s]\nepoch170 loss:0.00037801385042257607: 100%|██████████| 30/30 [00:00&lt;00:00, 110.56it/s]\nepoch171 loss:0.0003740711836144328: 100%|██████████| 30/30 [00:00&lt;00:00, 118.63it/s]\nepoch172 loss:0.00036944469320587814: 100%|██████████| 30/30 [00:00&lt;00:00, 99.85it/s]\nepoch173 loss:0.00036325736436992884: 100%|██████████| 30/30 [00:00&lt;00:00, 122.54it/s]\nepoch174 loss:0.0003559450851753354: 100%|██████████| 30/30 [00:00&lt;00:00, 117.81it/s] \nepoch175 loss:0.00034700174001045525: 100%|██████████| 30/30 [00:00&lt;00:00, 123.13it/s]\nepoch176 loss:0.00033846087171696126: 100%|██████████| 30/30 [00:00&lt;00:00, 119.09it/s]\nepoch177 loss:0.0003305237914901227: 100%|██████████| 30/30 [00:00&lt;00:00, 112.44it/s] \nepoch178 loss:0.00032653583912178874: 100%|██████████| 30/30 [00:00&lt;00:00, 124.61it/s]\nepoch179 loss:0.00031720136757940054: 100%|██████████| 30/30 [00:00&lt;00:00, 111.00it/s]\nepoch180 loss:0.0003151640121359378: 100%|██████████| 30/30 [00:00&lt;00:00, 110.58it/s] \nepoch181 loss:0.0003129615215584636: 100%|██████████| 30/30 [00:00&lt;00:00, 121.27it/s]\nepoch182 loss:0.00031068839598447084: 100%|██████████| 30/30 [00:00&lt;00:00, 119.12it/s]\nepoch183 loss:0.00030987217905931175: 100%|██████████| 30/30 [00:00&lt;00:00, 119.89it/s]\nepoch184 loss:0.0003096576256211847: 100%|██████████| 30/30 [00:00&lt;00:00, 113.49it/s] \nepoch185 loss:0.00030973891261965036: 100%|██████████| 30/30 [00:00&lt;00:00, 116.75it/s]\nepoch186 loss:0.0003112372651230544: 100%|██████████| 30/30 [00:00&lt;00:00, 125.94it/s] \nepoch187 loss:0.0003143460489809513: 100%|██████████| 30/30 [00:00&lt;00:00, 118.02it/s]\nepoch188 loss:0.00031802227022126317: 100%|██████████| 30/30 [00:00&lt;00:00, 129.65it/s]\nepoch189 loss:0.0003228485875297338: 100%|██████████| 30/30 [00:00&lt;00:00, 115.67it/s] \nepoch190 loss:0.00032656837720423937: 100%|██████████| 30/30 [00:00&lt;00:00, 121.05it/s]\nepoch191 loss:0.0003281572717241943: 100%|██████████| 30/30 [00:00&lt;00:00, 124.44it/s] \nepoch192 loss:0.0003267954452894628: 100%|██████████| 30/30 [00:00&lt;00:00, 112.61it/s] \nepoch193 loss:0.0003205299726687372: 100%|██████████| 30/30 [00:00&lt;00:00, 115.31it/s] \nepoch194 loss:0.0003109335375484079: 100%|██████████| 30/30 [00:00&lt;00:00, 125.52it/s] \nepoch195 loss:0.00030183859053067863: 100%|██████████| 30/30 [00:00&lt;00:00, 120.50it/s]\nepoch196 loss:0.0002976426621899009: 100%|██████████| 30/30 [00:00&lt;00:00, 115.44it/s] \nepoch197 loss:0.00030353126931004226: 100%|██████████| 30/30 [00:00&lt;00:00, 116.80it/s]\nepoch198 loss:0.00032168166944757104: 100%|██████████| 30/30 [00:00&lt;00:00, 114.43it/s]\nepoch199 loss:0.00035044897231273353: 100%|██████████| 30/30 [00:00&lt;00:00, 114.56it/s]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#모델-성능-평가하기",
    "href": "DL06.html#모델-성능-평가하기",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.9 모델 성능 평가하기",
    "text": "7.9 모델 성능 평가하기\n\nimport matplotlib.pyplot as plt\n\n# 예측값을 위한 데이터 로더\nloader = DataLoader(dataset, batch_size=1)  \n\n# 예측값들을 저장하는 리스트\npreds = []  \ntotal_loss = 0\n\nwith torch.no_grad():\n   # 모델의 가중치 불러오기\n   model.load_state_dict(torch.load(\"rnn.pth\", map_location=device))\n\n   for data, label in loader:\n       h0 = torch.zeros(5, data.shape[0], 8).to(device)  # 초기 은닉상태 정의\n\n       # 모델의 예측값 출력\n       pred = model(data.type(torch.FloatTensor).to(device), h0)\n       preds.append(pred.item())  # 예측값을 리스트에 추가\n       loss = nn.MSELoss()(pred,\n                           label.type(torch.FloatTensor).to(device))  # 손실계산\n       total_loss += loss/len(loader)  # 손실의 평균치 계산\n\ntotal_loss.item()\n\n0.0012640039203688502",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#그림으로-확인하기",
    "href": "DL06.html#그림으로-확인하기",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.10 그림으로 확인하기",
    "text": "7.10 그림으로 확인하기\n\nplt.plot(preds, label=\"prediction\")\nplt.plot(dataset.label[30:], label=\"actual\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#캘리포니아-집-값-예측",
    "href": "DL06.html#캘리포니아-집-값-예측",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.11 캘리포니아 집 값 예측",
    "text": "7.11 캘리포니아 집 값 예측\n\n7.11.1 Loading the data, EDA and data preparation\n\nimport pandas as pd\nfrom sklearn.datasets import fetch_california_housing\n_data = fetch_california_housing()\ndf = pd.DataFrame(_data.data, columns=_data.feature_names)\ndf['target'] = _data.target\n\n\nimport torch\nfrom torch.utils.data import Dataset\nclass MyDataset(Dataset):\n    def __init__(self, df=df):\n        self.x = df.iloc[:, :-1].values\n        self.y = df.iloc[:, -1:].values\n\n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, index):\n        x = self.x[index]\n        y = self.y[index]\n        return torch.tensor(x, dtype=torch.float), torch.tensor(y, dtype=torch.float)\n\n\nds = MyDataset(df)\nsample = next(iter(ds))\nprint(sample[0].shape, sample[1].shape)\n\ntorch.Size([8]) torch.Size([1])\n\n\n\nfrom torch.utils.data import DataLoader\ndef prepare_loaders(df = df, index = 15640, batch_size = 512):\n    # 1) Train Valids Split\n    train = df[:index].reset_index(drop = True)\n    valid = df[index:].reset_index(drop = True)\n    \n    # 2) train, valid -&gt; MyDataset(Dataset) --&gt; train_ds, valid_ds\n    train_ds = MyDataset(train)\n    valid_ds = MyDataset(valid)\n    \n    # 3) train_ds, valid_ds -&gt; DataLoader -&gt; train_loader, valid_loader\n    train_loader = DataLoader(train_ds, shuffle = True, batch_size = batch_size)\n    valid_loader = DataLoader(valid_ds, shuffle = False, batch_size = batch_size)\n    print('DataLoader Completed')\n    return train_loader, valid_loader\n\ntrain_loader, valid_loader = prepare_loaders(df = df, index = 15640, batch_size = 512)\n\nDataLoader Completed\n\n\n\nsample = next(iter(train_loader))\nprint(sample[0].shape, sample[1].shape)\n\ntorch.Size([512, 8]) torch.Size([512, 1])",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL06.html#rnn-매개변수",
    "href": "DL06.html#rnn-매개변수",
    "title": "7  Day6. RNN 학습하기 실습(Hands-On)",
    "section": "7.12 RNN 매개변수",
    "text": "7.12 RNN 매개변수\n\ninput_size = 5 # 입력의 크기\nhidden_size = 8 # 은닉 상태의 크기\n\n\nimport torch\nimport torch.nn as nn\n# (batch_size, time_steps, input_size)\n# 배치 크기는 1, 10번의 시점동안 5차원의 입력 벡터가 들어가도록 텐서를 정의\ninputs = torch.Tensor(1, 10, 5)\n\n\ncell = nn.RNN(input_size, hidden_size, batch_first=True)\n\n\noutputs, _status = cell(inputs)\n\n\n# 10번의 시점동안 8차원의 은닉상태가 출력\nprint(outputs.shape) # 모든 time-step의 hidden_state\n\ntorch.Size([1, 10, 8])\n\n\n\n# 다시 말해 마지막 시점의 은닉 상태의 크기를 확인해보겠습니다.\nprint(_status.shape) # 최종 time-step의 hidden_state\n\ntorch.Size([1, 1, 8])\n\n\n\n# 이 2개인 깊은 순환 신경망의 경우, 앞서 실습했던 임의의 입력에 대해서 출력\ncell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True)\n\n\noutputs, _status = cell(inputs)\n\n\nprint(outputs.shape) # 모든 time-step의 hidden_state\n\ntorch.Size([1, 10, 8])\n\n\n\nprint(_status.shape) # (층의 개수, 배치 크기, 은닉 상태의 크기)\n\ntorch.Size([2, 1, 8])",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Day6. RNN 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL07.html",
    "href": "DL07.html",
    "title": "8  Day7. LSTM 학습하기 실습(Hands-On)",
    "section": "",
    "text": "8.1 데이터 살펴보기\nimport pandas as pd\ndf = pd.read_csv(\"./data/LSTM/ArticlesApril2017.csv\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Day7. LSTM 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL07.html#학습용-데이터셋-정의",
    "href": "DL07.html#학습용-데이터셋-정의",
    "title": "8  Day7. LSTM 학습하기 실습(Hands-On)",
    "section": "8.2 학습용 데이터셋 정의",
    "text": "8.2 학습용 데이터셋 정의\n\nimport numpy as np\nimport glob\nimport string\n\nfrom torch.utils.data.dataset import Dataset\n\nclass TextGeneration(Dataset):\n    def __init__(self):\n        all_headlines = []\n        # 모든 헤드라인의 텍스트를 불러옴\n        for filename in glob.glob(\"./data/LSTM/*.csv\"):\n            if 'Articles' in filename:\n                article_df = pd.read_csv(filename)\n                all_headlines.extend(list(article_df.headline.values))\n                break\n\n        # headline 중 unknown 값은 제거\n        all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n\n        # 구두점 제거 및 전처리가 된 문장들을 리스트로 반환\n        self.corpus = [self.clean_text(x) for x in all_headlines]\n        self.BOW = {}\n\n        # 모든 문장의 단어를 추출해 고유번호 지정\n        for line in self.corpus:\n            for word in line.split():\n                if word not in self.BOW.keys():\n                    self.BOW[word] = len(self.BOW.keys())\n\n        # 모델의 입력으로 사용할 데이터\n        self.data = self.generate_sequence(self.corpus)\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, i):\n        data = np.array(self.data[i][0]) # 입력 데이터\n        label = np.array(self.data[i][1]).astype(np.float32) # 출력 데이터\n        return data, label\n\n    def clean_text(self, txt):\n        # 모든 단어를 소문자로 바꾸고 특수문자를 제거\n        txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n        return txt\n\n    def generate_sequence(self, txt):\n        seq = []\n\n        for line in txt:\n            line = line.split()\n            line_bow = [self.BOW[word] for word in line]\n\n            # 단어 2개를 입력으로, 그다음 단어를 정답으로\n            data = [([line_bow[i], line_bow[i+1]], line_bow[i+2])\n            for i in range(len(line_bow)-2)]\n\n            seq.extend(data)\n\n        return seq",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Day7. LSTM 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL07.html#lstm모델-정의",
    "href": "DL07.html#lstm모델-정의",
    "title": "8  Day7. LSTM 학습하기 실습(Hands-On)",
    "section": "8.3 LSTM모델 정의",
    "text": "8.3 LSTM모델 정의\n\nimport torch\nimport torch.nn as nn\n\n\nclass LSTM(nn.Module):\n   def __init__(self, num_embeddings):\n       super(LSTM, self).__init__()\n\n       # 밀집표현을 위한 임베딩층\n       self.embed = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=16)\n\n       # LSTM을 5개층을 쌓음\n       self.lstm = nn.LSTM(\n           input_size=16,\n           hidden_size=64,\n           num_layers=5,\n           batch_first=True)\n\n       # 분류를 위한 MLP층\n       self.fc1 = nn.Linear(128, num_embeddings)\n       self.fc2 = nn.Linear(num_embeddings,num_embeddings)\n\n       # 활성화 함수\n       self.relu = nn.ReLU()\n\n   def forward(self, x):\n       x = self.embed(x)\n\n       # LSTM 모델의 예측값\n       x, _ = self.lstm(x)\n       x = torch.reshape(x, (x.shape[0], -1))\n       x = self.fc1(x)\n       x = self.relu(x)\n       x = self.fc2(x)\n\n       return x",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Day7. LSTM 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL07.html#모델-학습하기",
    "href": "DL07.html#모델-학습하기",
    "title": "8  Day7. LSTM 학습하기 실습(Hands-On)",
    "section": "8.4 모델 학습하기",
    "text": "8.4 모델 학습하기\n\nimport tqdm\n\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.optim.adam import Adam\n\n# 학습을 진행할 프로세서 정의\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndataset = TextGeneration()  # 데이터셋 정의\nmodel = LSTM(num_embeddings=len(dataset.BOW)).to(device)  # 모델 정의\nloader = DataLoader(dataset, batch_size=64)\noptim = Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(200):\n   iterator = tqdm.tqdm(loader)\n   for data, label in iterator:\n       # 기울기 초기화\n       optim.zero_grad()\n\n       # 모델의 예측값\n       pred = model(torch.tensor(data, dtype=torch.long).to(device))\n\n       # 정답 레이블은 long 텐서로 반환해야 함\n       loss = nn.CrossEntropyLoss()(\n           pred, torch.tensor(label, dtype=torch.long).to(device))\n\n       # 오차 역전파\n       loss.backward()\n       optim.step()\n\n       iterator.set_description(f\"epoch{epoch} loss:{loss.item()}\")\n\ntorch.save(model.state_dict(), \"lstm.pth\")\n\n  0%|          | 0/63 [00:00&lt;?, ?it/s]C:\\Users\\sigma\\AppData\\Local\\Temp\\ipykernel_14424\\954448527.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  pred = model(torch.tensor(data, dtype=torch.long).to(device))\nC:\\Users\\sigma\\AppData\\Local\\Temp\\ipykernel_14424\\954448527.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  pred, torch.tensor(label, dtype=torch.long).to(device))\nepoch0 loss:7.372651100158691: 100%|██████████| 63/63 [00:02&lt;00:00, 29.96it/s] \nepoch1 loss:7.012795448303223: 100%|██████████| 63/63 [00:02&lt;00:00, 30.09it/s] \nepoch2 loss:6.751251220703125: 100%|██████████| 63/63 [00:02&lt;00:00, 30.34it/s] \nepoch3 loss:6.5387091636657715: 100%|██████████| 63/63 [00:02&lt;00:00, 30.41it/s]\nepoch4 loss:6.4103546142578125: 100%|██████████| 63/63 [00:02&lt;00:00, 30.51it/s]\nepoch5 loss:6.107255935668945: 100%|██████████| 63/63 [00:02&lt;00:00, 30.87it/s] \nepoch6 loss:5.7916669845581055: 100%|██████████| 63/63 [00:02&lt;00:00, 30.93it/s]\nepoch7 loss:5.595593452453613: 100%|██████████| 63/63 [00:02&lt;00:00, 31.11it/s] \nepoch8 loss:5.431673049926758: 100%|██████████| 63/63 [00:01&lt;00:00, 31.54it/s] \nepoch9 loss:5.613152980804443: 100%|██████████| 63/63 [00:02&lt;00:00, 31.12it/s] \nepoch10 loss:5.555459022521973: 100%|██████████| 63/63 [00:02&lt;00:00, 31.03it/s] \nepoch11 loss:5.417506217956543: 100%|██████████| 63/63 [00:02&lt;00:00, 30.25it/s] \nepoch12 loss:5.819920063018799: 100%|██████████| 63/63 [00:02&lt;00:00, 30.95it/s] \nepoch13 loss:5.562602996826172: 100%|██████████| 63/63 [00:02&lt;00:00, 30.69it/s] \nepoch14 loss:5.339858055114746: 100%|██████████| 63/63 [00:02&lt;00:00, 31.18it/s] \nepoch15 loss:5.221261501312256: 100%|██████████| 63/63 [00:02&lt;00:00, 31.21it/s] \nepoch16 loss:5.118991851806641: 100%|██████████| 63/63 [00:02&lt;00:00, 30.98it/s] \nepoch17 loss:4.925679683685303: 100%|██████████| 63/63 [00:02&lt;00:00, 31.03it/s] \nepoch18 loss:4.803688049316406: 100%|██████████| 63/63 [00:02&lt;00:00, 30.64it/s] \nepoch19 loss:4.697256088256836: 100%|██████████| 63/63 [00:02&lt;00:00, 30.57it/s] \nepoch20 loss:4.366311073303223: 100%|██████████| 63/63 [00:02&lt;00:00, 30.25it/s] \nepoch21 loss:4.232382774353027: 100%|██████████| 63/63 [00:02&lt;00:00, 30.47it/s] \nepoch22 loss:4.235006332397461: 100%|██████████| 63/63 [00:02&lt;00:00, 30.69it/s] \nepoch23 loss:4.18096399307251: 100%|██████████| 63/63 [00:02&lt;00:00, 30.41it/s]  \nepoch24 loss:4.231608867645264: 100%|██████████| 63/63 [00:02&lt;00:00, 30.50it/s] \nepoch25 loss:4.260599613189697: 100%|██████████| 63/63 [00:02&lt;00:00, 30.30it/s] \nepoch26 loss:4.290002822875977: 100%|██████████| 63/63 [00:02&lt;00:00, 30.28it/s] \nepoch27 loss:4.587839603424072: 100%|██████████| 63/63 [00:02&lt;00:00, 30.50it/s] \nepoch28 loss:4.5711822509765625: 100%|██████████| 63/63 [00:02&lt;00:00, 30.52it/s]\nepoch29 loss:4.351805686950684: 100%|██████████| 63/63 [00:02&lt;00:00, 30.46it/s] \nepoch30 loss:4.152091979980469: 100%|██████████| 63/63 [00:02&lt;00:00, 30.27it/s] \nepoch31 loss:3.99059796333313: 100%|██████████| 63/63 [00:02&lt;00:00, 30.00it/s]  \nepoch32 loss:3.88297963142395: 100%|██████████| 63/63 [00:02&lt;00:00, 30.40it/s]  \nepoch33 loss:3.866213321685791: 100%|██████████| 63/63 [00:02&lt;00:00, 30.43it/s] \nepoch34 loss:3.689802885055542: 100%|██████████| 63/63 [00:02&lt;00:00, 30.59it/s] \nepoch35 loss:3.6054000854492188: 100%|██████████| 63/63 [00:02&lt;00:00, 30.76it/s]\nepoch36 loss:3.6056625843048096: 100%|██████████| 63/63 [00:02&lt;00:00, 30.59it/s]\nepoch37 loss:3.5783417224884033: 100%|██████████| 63/63 [00:02&lt;00:00, 30.81it/s]\nepoch38 loss:3.487673282623291: 100%|██████████| 63/63 [00:02&lt;00:00, 30.68it/s] \nepoch39 loss:3.4938406944274902: 100%|██████████| 63/63 [00:02&lt;00:00, 30.92it/s]\nepoch40 loss:3.420072555541992: 100%|██████████| 63/63 [00:02&lt;00:00, 30.37it/s] \nepoch41 loss:3.252845048904419: 100%|██████████| 63/63 [00:02&lt;00:00, 30.46it/s] \nepoch42 loss:3.2274937629699707: 100%|██████████| 63/63 [00:02&lt;00:00, 30.38it/s]\nepoch43 loss:3.2877650260925293: 100%|██████████| 63/63 [00:02&lt;00:00, 30.76it/s]\nepoch44 loss:3.256868362426758: 100%|██████████| 63/63 [00:02&lt;00:00, 30.70it/s] \nepoch45 loss:3.279987335205078: 100%|██████████| 63/63 [00:02&lt;00:00, 30.61it/s] \nepoch46 loss:3.1522459983825684: 100%|██████████| 63/63 [00:02&lt;00:00, 30.49it/s]\nepoch47 loss:3.078834056854248: 100%|██████████| 63/63 [00:02&lt;00:00, 29.68it/s] \nepoch48 loss:3.0076518058776855: 100%|██████████| 63/63 [00:02&lt;00:00, 30.35it/s]\nepoch49 loss:3.0695154666900635: 100%|██████████| 63/63 [00:02&lt;00:00, 30.25it/s]\nepoch50 loss:3.0221283435821533: 100%|██████████| 63/63 [00:02&lt;00:00, 30.30it/s]\nepoch51 loss:3.1195931434631348: 100%|██████████| 63/63 [00:02&lt;00:00, 28.72it/s]\nepoch52 loss:3.0998075008392334: 100%|██████████| 63/63 [00:02&lt;00:00, 30.08it/s]\nepoch53 loss:3.062981367111206: 100%|██████████| 63/63 [00:02&lt;00:00, 29.97it/s] \nepoch54 loss:3.137132167816162: 100%|██████████| 63/63 [00:02&lt;00:00, 30.58it/s] \nepoch55 loss:3.2123146057128906: 100%|██████████| 63/63 [00:02&lt;00:00, 30.41it/s]\nepoch56 loss:3.0057947635650635: 100%|██████████| 63/63 [00:02&lt;00:00, 29.94it/s]\nepoch57 loss:2.5904428958892822: 100%|██████████| 63/63 [00:02&lt;00:00, 29.25it/s]\nepoch58 loss:2.33766770362854: 100%|██████████| 63/63 [00:02&lt;00:00, 29.82it/s]  \nepoch59 loss:2.209383010864258: 100%|██████████| 63/63 [00:02&lt;00:00, 29.93it/s] \nepoch60 loss:2.1444334983825684: 100%|██████████| 63/63 [00:02&lt;00:00, 30.01it/s]\nepoch61 loss:2.1039631366729736: 100%|██████████| 63/63 [00:02&lt;00:00, 30.02it/s]\nepoch62 loss:2.2292325496673584: 100%|██████████| 63/63 [00:02&lt;00:00, 29.69it/s]\nepoch63 loss:2.423673152923584: 100%|██████████| 63/63 [00:02&lt;00:00, 29.88it/s] \nepoch64 loss:2.3762269020080566: 100%|██████████| 63/63 [00:02&lt;00:00, 29.70it/s]\nepoch65 loss:2.256706476211548: 100%|██████████| 63/63 [00:02&lt;00:00, 29.23it/s] \nepoch66 loss:2.3110923767089844: 100%|██████████| 63/63 [00:02&lt;00:00, 29.09it/s]\nepoch67 loss:2.196319580078125: 100%|██████████| 63/63 [00:02&lt;00:00, 29.65it/s] \nepoch68 loss:1.9813998937606812: 100%|██████████| 63/63 [00:02&lt;00:00, 29.74it/s]\nepoch69 loss:1.7943894863128662: 100%|██████████| 63/63 [00:02&lt;00:00, 29.72it/s]\nepoch70 loss:1.5957521200180054: 100%|██████████| 63/63 [00:02&lt;00:00, 29.39it/s]\nepoch71 loss:1.5631855726242065: 100%|██████████| 63/63 [00:02&lt;00:00, 29.32it/s]\nepoch72 loss:1.4813250303268433: 100%|██████████| 63/63 [00:02&lt;00:00, 29.99it/s]\nepoch73 loss:1.4767897129058838: 100%|██████████| 63/63 [00:02&lt;00:00, 29.92it/s]\nepoch74 loss:1.815490484237671: 100%|██████████| 63/63 [00:02&lt;00:00, 29.78it/s] \nepoch75 loss:1.7830092906951904: 100%|██████████| 63/63 [00:02&lt;00:00, 29.06it/s]\nepoch76 loss:1.8959804773330688: 100%|██████████| 63/63 [00:02&lt;00:00, 29.32it/s]\nepoch77 loss:1.5385154485702515: 100%|██████████| 63/63 [00:02&lt;00:00, 30.23it/s]\nepoch78 loss:1.5313900709152222: 100%|██████████| 63/63 [00:02&lt;00:00, 29.57it/s]\nepoch79 loss:2.7489333152770996: 100%|██████████| 63/63 [00:02&lt;00:00, 29.86it/s]\nepoch80 loss:1.4279186725616455: 100%|██████████| 63/63 [00:02&lt;00:00, 29.64it/s]\nepoch81 loss:1.2948559522628784: 100%|██████████| 63/63 [00:02&lt;00:00, 29.60it/s]\nepoch82 loss:1.1474590301513672: 100%|██████████| 63/63 [00:02&lt;00:00, 29.71it/s]\nepoch83 loss:1.130650281906128: 100%|██████████| 63/63 [00:02&lt;00:00, 29.80it/s] \nepoch84 loss:1.0365859270095825: 100%|██████████| 63/63 [00:02&lt;00:00, 29.07it/s]\nepoch85 loss:1.150331735610962: 100%|██████████| 63/63 [00:02&lt;00:00, 29.89it/s] \nepoch86 loss:0.9882837533950806: 100%|██████████| 63/63 [00:02&lt;00:00, 29.60it/s]\nepoch87 loss:1.1159240007400513: 100%|██████████| 63/63 [00:02&lt;00:00, 29.68it/s]\nepoch88 loss:0.7778836488723755: 100%|██████████| 63/63 [00:02&lt;00:00, 29.50it/s]\nepoch89 loss:0.8133600950241089: 100%|██████████| 63/63 [00:02&lt;00:00, 29.56it/s]\nepoch90 loss:0.8302339315414429: 100%|██████████| 63/63 [00:02&lt;00:00, 29.79it/s]\nepoch91 loss:0.8861123323440552: 100%|██████████| 63/63 [00:02&lt;00:00, 28.76it/s]\nepoch92 loss:0.8457903861999512: 100%|██████████| 63/63 [00:02&lt;00:00, 29.90it/s]\nepoch93 loss:0.795343816280365: 100%|██████████| 63/63 [00:02&lt;00:00, 28.97it/s] \nepoch94 loss:0.8793076276779175: 100%|██████████| 63/63 [00:02&lt;00:00, 28.90it/s]\nepoch95 loss:0.9502432942390442: 100%|██████████| 63/63 [00:02&lt;00:00, 29.64it/s]\nepoch96 loss:1.0178048610687256: 100%|██████████| 63/63 [00:02&lt;00:00, 28.79it/s]\nepoch97 loss:0.9928147196769714: 100%|██████████| 63/63 [00:02&lt;00:00, 29.41it/s]\nepoch98 loss:0.9010856747627258: 100%|██████████| 63/63 [00:02&lt;00:00, 28.45it/s]\nepoch99 loss:0.692245364189148: 100%|██████████| 63/63 [00:02&lt;00:00, 29.58it/s] \nepoch100 loss:0.6776093244552612: 100%|██████████| 63/63 [00:02&lt;00:00, 29.61it/s]\nepoch101 loss:0.6116495132446289: 100%|██████████| 63/63 [00:02&lt;00:00, 29.68it/s]\nepoch102 loss:0.6006203293800354: 100%|██████████| 63/63 [00:02&lt;00:00, 29.55it/s]\nepoch103 loss:0.7315515279769897: 100%|██████████| 63/63 [00:02&lt;00:00, 29.77it/s]\nepoch104 loss:0.6399082541465759: 100%|██████████| 63/63 [00:02&lt;00:00, 29.57it/s]\nepoch105 loss:0.6313225626945496: 100%|██████████| 63/63 [00:02&lt;00:00, 29.78it/s]\nepoch106 loss:0.5401725172996521: 100%|██████████| 63/63 [00:02&lt;00:00, 29.48it/s]\nepoch107 loss:0.6542189717292786: 100%|██████████| 63/63 [00:02&lt;00:00, 29.56it/s]\nepoch108 loss:1.0974290370941162: 100%|██████████| 63/63 [00:02&lt;00:00, 29.60it/s]\nepoch109 loss:0.5562237501144409: 100%|██████████| 63/63 [00:02&lt;00:00, 29.08it/s]\nepoch110 loss:0.7701835632324219: 100%|██████████| 63/63 [00:02&lt;00:00, 29.05it/s]\nepoch111 loss:0.7525618076324463: 100%|██████████| 63/63 [00:02&lt;00:00, 29.39it/s]\nepoch112 loss:0.5408453345298767: 100%|██████████| 63/63 [00:02&lt;00:00, 29.75it/s]\nepoch113 loss:0.5820992588996887: 100%|██████████| 63/63 [00:02&lt;00:00, 28.39it/s]\nepoch114 loss:0.43132632970809937: 100%|██████████| 63/63 [00:02&lt;00:00, 28.90it/s]\nepoch115 loss:0.4582231938838959: 100%|██████████| 63/63 [00:02&lt;00:00, 29.07it/s]\nepoch116 loss:0.46172642707824707: 100%|██████████| 63/63 [00:02&lt;00:00, 28.57it/s]\nepoch117 loss:0.4117851257324219: 100%|██████████| 63/63 [00:02&lt;00:00, 28.44it/s]\nepoch118 loss:0.4054495692253113: 100%|██████████| 63/63 [00:02&lt;00:00, 28.75it/s]\nepoch119 loss:0.4143424928188324: 100%|██████████| 63/63 [00:02&lt;00:00, 28.26it/s]\nepoch120 loss:0.399949312210083: 100%|██████████| 63/63 [00:02&lt;00:00, 28.13it/s] \nepoch121 loss:0.2994658350944519: 100%|██████████| 63/63 [00:02&lt;00:00, 28.44it/s]\nepoch122 loss:0.31716188788414: 100%|██████████| 63/63 [00:02&lt;00:00, 27.85it/s]  \nepoch123 loss:0.2917465269565582: 100%|██████████| 63/63 [00:02&lt;00:00, 27.43it/s]\nepoch124 loss:0.30665263533592224: 100%|██████████| 63/63 [00:02&lt;00:00, 27.29it/s]\nepoch125 loss:0.30644601583480835: 100%|██████████| 63/63 [00:02&lt;00:00, 26.71it/s]\nepoch126 loss:0.3023678660392761: 100%|██████████| 63/63 [00:02&lt;00:00, 28.01it/s]\nepoch127 loss:0.3063408136367798: 100%|██████████| 63/63 [00:02&lt;00:00, 27.55it/s]\nepoch128 loss:0.36595290899276733: 100%|██████████| 63/63 [00:02&lt;00:00, 27.07it/s]\nepoch129 loss:0.23219983279705048: 100%|██████████| 63/63 [00:02&lt;00:00, 26.70it/s]\nepoch130 loss:0.8885325193405151: 100%|██████████| 63/63 [00:02&lt;00:00, 26.96it/s]\nepoch131 loss:0.8072288632392883: 100%|██████████| 63/63 [00:02&lt;00:00, 28.26it/s]\nepoch132 loss:0.7318798303604126: 100%|██████████| 63/63 [00:02&lt;00:00, 28.36it/s]\nepoch133 loss:0.2506997883319855: 100%|██████████| 63/63 [00:02&lt;00:00, 28.57it/s]\nepoch134 loss:0.9059635400772095: 100%|██████████| 63/63 [00:02&lt;00:00, 28.60it/s]\nepoch135 loss:0.5220997929573059: 100%|██████████| 63/63 [00:02&lt;00:00, 28.99it/s]\nepoch136 loss:0.3638765513896942: 100%|██████████| 63/63 [00:02&lt;00:00, 28.91it/s]\nepoch137 loss:0.28650176525115967: 100%|██████████| 63/63 [00:02&lt;00:00, 29.15it/s]\nepoch138 loss:0.23368768393993378: 100%|██████████| 63/63 [00:02&lt;00:00, 28.99it/s]\nepoch139 loss:0.3135228753089905: 100%|██████████| 63/63 [00:02&lt;00:00, 28.62it/s]\nepoch140 loss:0.29951217770576477: 100%|██████████| 63/63 [00:02&lt;00:00, 28.51it/s]\nepoch141 loss:0.313153475522995: 100%|██████████| 63/63 [00:02&lt;00:00, 28.38it/s] \nepoch142 loss:0.22673535346984863: 100%|██████████| 63/63 [00:02&lt;00:00, 28.48it/s]\nepoch143 loss:0.3167438507080078: 100%|██████████| 63/63 [00:02&lt;00:00, 28.56it/s]\nepoch144 loss:0.23271474242210388: 100%|██████████| 63/63 [00:02&lt;00:00, 27.62it/s]\nepoch145 loss:0.2790517210960388: 100%|██████████| 63/63 [00:02&lt;00:00, 28.10it/s]\nepoch146 loss:0.15404677391052246: 100%|██████████| 63/63 [00:02&lt;00:00, 28.23it/s]\nepoch147 loss:0.19027599692344666: 100%|██████████| 63/63 [00:02&lt;00:00, 26.29it/s]\nepoch148 loss:0.19010695815086365: 100%|██████████| 63/63 [00:02&lt;00:00, 28.20it/s]\nepoch149 loss:0.20009469985961914: 100%|██████████| 63/63 [00:02&lt;00:00, 27.51it/s]\nepoch150 loss:0.3250100314617157: 100%|██████████| 63/63 [00:02&lt;00:00, 27.48it/s]\nepoch151 loss:0.2491767853498459: 100%|██████████| 63/63 [00:02&lt;00:00, 26.99it/s] \nepoch152 loss:0.36567503213882446: 100%|██████████| 63/63 [00:02&lt;00:00, 27.58it/s]\nepoch153 loss:0.19784851372241974: 100%|██████████| 63/63 [00:02&lt;00:00, 27.47it/s]\nepoch154 loss:0.2207948863506317: 100%|██████████| 63/63 [00:02&lt;00:00, 27.28it/s]\nepoch155 loss:0.20343296229839325: 100%|██████████| 63/63 [00:02&lt;00:00, 27.01it/s]\nepoch156 loss:0.14597663283348083: 100%|██████████| 63/63 [00:02&lt;00:00, 27.80it/s]\nepoch157 loss:0.15305744111537933: 100%|██████████| 63/63 [00:02&lt;00:00, 27.74it/s]\nepoch158 loss:0.192966490983963: 100%|██████████| 63/63 [00:02&lt;00:00, 27.63it/s]  \nepoch159 loss:0.20738768577575684: 100%|██████████| 63/63 [00:02&lt;00:00, 27.26it/s]\nepoch160 loss:0.17042401432991028: 100%|██████████| 63/63 [00:02&lt;00:00, 26.77it/s]\nepoch161 loss:0.14671185612678528: 100%|██████████| 63/63 [00:02&lt;00:00, 27.14it/s]\nepoch162 loss:0.2155202180147171: 100%|██████████| 63/63 [00:02&lt;00:00, 27.28it/s] \nepoch163 loss:0.19189725816249847: 100%|██████████| 63/63 [00:02&lt;00:00, 26.13it/s]\nepoch164 loss:0.21228453516960144: 100%|██████████| 63/63 [00:02&lt;00:00, 26.85it/s]\nepoch165 loss:0.21198499202728271: 100%|██████████| 63/63 [00:02&lt;00:00, 27.14it/s]\nepoch166 loss:0.1336313784122467: 100%|██████████| 63/63 [00:02&lt;00:00, 27.05it/s] \nepoch167 loss:0.10597109794616699: 100%|██████████| 63/63 [00:02&lt;00:00, 26.92it/s]\nepoch168 loss:0.31624317169189453: 100%|██████████| 63/63 [00:02&lt;00:00, 27.22it/s]\nepoch169 loss:0.1102648377418518: 100%|██████████| 63/63 [00:02&lt;00:00, 27.46it/s]\nepoch170 loss:0.1352931559085846: 100%|██████████| 63/63 [00:02&lt;00:00, 27.52it/s] \nepoch171 loss:0.2176336944103241: 100%|██████████| 63/63 [00:02&lt;00:00, 27.30it/s] \nepoch172 loss:0.17053921520709991: 100%|██████████| 63/63 [00:02&lt;00:00, 27.28it/s]\nepoch173 loss:0.12344326823949814: 100%|██████████| 63/63 [00:02&lt;00:00, 27.85it/s]\nepoch174 loss:0.2963258624076843: 100%|██████████| 63/63 [00:02&lt;00:00, 28.16it/s]\nepoch175 loss:0.2578527331352234: 100%|██████████| 63/63 [00:02&lt;00:00, 27.97it/s] \nepoch176 loss:0.17342731356620789: 100%|██████████| 63/63 [00:02&lt;00:00, 27.88it/s]\nepoch177 loss:0.18770797550678253: 100%|██████████| 63/63 [00:02&lt;00:00, 25.92it/s]\nepoch178 loss:0.2669675052165985: 100%|██████████| 63/63 [00:02&lt;00:00, 28.11it/s] \nepoch179 loss:0.23345589637756348: 100%|██████████| 63/63 [00:02&lt;00:00, 27.99it/s]\nepoch180 loss:0.18830612301826477: 100%|██████████| 63/63 [00:02&lt;00:00, 27.36it/s]\nepoch181 loss:0.1043897271156311: 100%|██████████| 63/63 [00:02&lt;00:00, 27.13it/s] \nepoch182 loss:0.09840714931488037: 100%|██████████| 63/63 [00:02&lt;00:00, 27.77it/s]\nepoch183 loss:0.08853331953287125: 100%|██████████| 63/63 [00:02&lt;00:00, 27.73it/s]\nepoch184 loss:0.13405174016952515: 100%|██████████| 63/63 [00:02&lt;00:00, 27.43it/s]\nepoch185 loss:0.15336914360523224: 100%|██████████| 63/63 [00:02&lt;00:00, 27.55it/s]\nepoch186 loss:0.09544318169355392: 100%|██████████| 63/63 [00:02&lt;00:00, 27.75it/s]\nepoch187 loss:0.14581386744976044: 100%|██████████| 63/63 [00:02&lt;00:00, 27.17it/s]\nepoch188 loss:0.16919568181037903: 100%|██████████| 63/63 [00:02&lt;00:00, 27.42it/s]\nepoch189 loss:0.11675361543893814: 100%|██████████| 63/63 [00:02&lt;00:00, 27.53it/s]\nepoch190 loss:0.21376530826091766: 100%|██████████| 63/63 [00:02&lt;00:00, 27.66it/s]\nepoch191 loss:0.19200748205184937: 100%|██████████| 63/63 [00:02&lt;00:00, 27.68it/s]\nepoch192 loss:0.1597258746623993: 100%|██████████| 63/63 [00:02&lt;00:00, 27.99it/s] \nepoch193 loss:0.17169798910617828: 100%|██████████| 63/63 [00:02&lt;00:00, 27.55it/s]\nepoch194 loss:0.37269127368927: 100%|██████████| 63/63 [00:02&lt;00:00, 26.88it/s]   \nepoch195 loss:0.1793302744626999: 100%|██████████| 63/63 [00:02&lt;00:00, 27.01it/s] \nepoch196 loss:0.22224219143390656: 100%|██████████| 63/63 [00:02&lt;00:00, 27.37it/s]\nepoch197 loss:0.15241554379463196: 100%|██████████| 63/63 [00:02&lt;00:00, 27.42it/s]\nepoch198 loss:0.14123687148094177: 100%|██████████| 63/63 [00:02&lt;00:00, 27.67it/s]\nepoch199 loss:0.30991119146347046: 100%|██████████| 63/63 [00:02&lt;00:00, 28.17it/s]\n\n\n\ndef generate(model, BOW, string=\"finding an \", strlen=10):\n   device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n   print(f\"input word: {string}\")\n\n   with torch.no_grad():\n       for p in range(strlen):\n           # 입력 문장을 텐서로 변경\n           words = torch.tensor([BOW[w] for w in string.split()], dtype=torch.long).to(device)           \n           input_tensor = torch.unsqueeze(words[-2:], dim=0)\n           output = model(input_tensor)  # 모델을 이용해 예측\n           output_word = (torch.argmax(output).cpu().numpy())\n           string += list(BOW.keys())[output_word]  # 문장에 예측된 단어를 추가\n           string += \" \"\n\n   print(f\"predicted sentence: {string}\")\n\nmodel.load_state_dict(torch.load(\"lstm.pth\", map_location=device))\npred = generate(model, dataset.BOW)\n\ninput word: finding an \npredicted sentence: finding an expansive view and dims it today today sister sharp in",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Day7. LSTM 학습하기 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html",
    "href": "DL08.html",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "",
    "text": "9.1 데이터 확인\nimport string\n\nl = []\n\n# 한글 텍스트 파일을 읽기 위해 utf-8 인코딩으로 읽어옴\nwith open(\n    \"./data/Attention.txt\",\n    'r', encoding=\"utf-8\") as f:\n   lines = f.read().split(\"\\n\")\n   for line in lines:\n       # 특수 문자를 지우고 모든 글자를 소문자로 변경\n       txt = \"\".join(v for v in line if v not in string.punctuation).lower()\n       l.append(txt)\n\nprint(l[:5])\n\n['go\\t가', 'hi\\t안녕', 'run\\t뛰어', 'run\\t뛰어', 'who\\t누구']",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#bow를-만드는-함수-정의",
    "href": "DL08.html#bow를-만드는-함수-정의",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.2 BOW를 만드는 함수 정의",
    "text": "9.2 BOW를 만드는 함수 정의\n\nimport numpy as np\nimport torch\n\nfrom torch.utils.data.dataset import Dataset\n\ndef get_BOW(corpus):  # 문장들로부터 BOW를 만드는 함수\n   BOW = {\"&lt;SOS&gt;\":0, \"&lt;EOS&gt;\":1}  # &lt;SOS&gt; 토큰과 &lt;EOS&gt; 토큰을 추가\n\n   # 문장 내 단어들을 이용해 BOW를 생성\n   for line in corpus:\n       for word in line.split():\n           if word not in BOW.keys():\n               BOW[word] = len(BOW.keys())\n\n   return BOW",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#학습에-사용할-데이터셋-정의",
    "href": "DL08.html#학습에-사용할-데이터셋-정의",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.3 학습에 사용할 데이터셋 정의",
    "text": "9.3 학습에 사용할 데이터셋 정의\n\nclass Eng2Kor(Dataset):  # 학습에 이용할 데이터셋\n   def __init__(\n       self,\n       pth2txt=\\\n       \"./data/Attention.txt\"):\n       self.eng_corpus = []  # 영어 문장이 들어가는 변수\n       self.kor_corpus = []  # 한글 문장이 들어가는 변수\n\n       # 텍스트 파일을 읽어서 영어 문장과 한글 문장을 저장\n       with open(pth2txt, 'r', encoding=\"utf-8\") as f:\n           lines = f.read().split(\"\\n\")\n           for line in lines:\n               # 특수 문자와 대문자 제거\n               txt = \"\".join(\n                   v for v in line if v not in string.punctuation\n                   ).lower()\n               engtxt = txt.split(\"\\t\")[0]\n               kortxt = txt.split(\"\\t\")[1]\n\n               # 길이가 10 이하인 문장만을 사용\n               if len(engtxt.split()) &lt;= 10 and len(kortxt.split()) &lt;= 10:\n                   self.eng_corpus.append(engtxt)\n                   self.kor_corpus.append(kortxt)\n\n       self.engBOW = get_BOW(self.eng_corpus)  # 영어 BOW\n       self.korBOW = get_BOW(self.kor_corpus)  # 한글 BOW\n   \n   # 문장을 단어별로 분리하고 마지막에 &lt;EOS&gt;를 추가\n   def gen_seq(self, line):\n       seq = line.split()\n       seq.append(\"&lt;EOS&gt;\")\n       return seq\n   \n   def __len__(self):\n       return len(self.eng_corpus)\n\n   def __getitem__(self, i):\n       # 문자열로 되어 있는 문장을 숫자 표현으로 변경\n       data = np.array([self.engBOW[txt] for txt in self.gen_seq(self.eng_corpus[i])])\n       label = np.array([self.korBOW[txt] for txt in self.gen_seq(self.kor_corpus[i])])\n       return data, label",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#학습에-사용할-데이터-로더-정의",
    "href": "DL08.html#학습에-사용할-데이터-로더-정의",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.4 학습에 사용할 데이터 로더 정의",
    "text": "9.4 학습에 사용할 데이터 로더 정의\n\ndef loader(dataset):  # 데이터셋의 문장을 한문장씩 불러오기 위한 함수\n   for i in range(len(dataset)):\n       data, label = dataset[i]\n       # 데이터와 정답을 반환\n       yield torch.tensor(data), torch.tensor(label)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#인코더-정의",
    "href": "DL08.html#인코더-정의",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.5 인코더 정의",
    "text": "9.5 인코더 정의\n\nimport torch.nn as nn\n\nclass Encoder(nn.Module):\n   def __init__(self, input_size, hidden_size):\n       super(Encoder, self).__init__()\n       self.embedding = nn.Embedding(input_size, hidden_size)\n       self.gru = nn.GRU(hidden_size, hidden_size)\n\n   def forward(self, x, h):\n       # 배치차원과 시계열 차원 추가\n       x = self.embedding(x).view(1, 1, -1)\n       output, hidden = self.gru(x, h)\n       return output, hidden",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#디코더-정의",
    "href": "DL08.html#디코더-정의",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.6 디코더 정의",
    "text": "9.6 디코더 정의\n\nclass Decoder(nn.Module):\n   def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=11):\n       super(Decoder, self).__init__()\n\n       # 임베딩층 정의\n       self.embedding = nn.Embedding(output_size, hidden_size)\n\n       # 어텐션 가중치를 계산하기 위한 MLP층\n       self.attention = nn.Linear(hidden_size * 2, max_length)\n\n       #특징 추출을 위한 MLP층\n       self.context = nn.Linear(hidden_size * 2, hidden_size)\n\n       # 과적합을 피하기 위한 드롭아웃 층\n       self.dropout = nn.Dropout(dropout_p)\n\n       # GRU층\n       self.gru = nn.GRU(hidden_size, hidden_size)\n\n       # 단어 분류를 위한 MLP층\n       self.out = nn.Linear(hidden_size, output_size)\n\n       # 활성화 함수\n       self.relu = nn.ReLU()\n       self.softmax = nn.LogSoftmax(dim=1)\n\n   def forward(self, x, h, encoder_outputs):\n       # 입력을 밀집 표현으로\n       x = self.embedding(x).view(1, 1, -1)\n       x = self.dropout(x)\n\n       # 어텐션 가중치 계산\n       attn_weights = self.softmax(self.attention(torch.cat((x[0], h[0]), -1)))\n\n       # 어텐션 가중치와 인코더의 출력을 내적\n       attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n                                encoder_outputs.unsqueeze(0))\n\n       # 인코더 각 시점의 중요도와 민집표현을 합쳐\n       # MLP층으로 특징 추출\n       output = torch.cat((x[0], attn_applied[0]), 1)\n       output = self.context(output).unsqueeze(0)\n       output = self.relu(output)\n\n       # GRU층으로 입력\n       output, hidden = self.gru(output, h)\n\n       # 예측된 단어 출력\n       output = self.out(output[0])\n\n       return output",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#학습에-필요한-요소-정의",
    "href": "DL08.html#학습에-필요한-요소-정의",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.7 학습에 필요한 요소 정의",
    "text": "9.7 학습에 필요한 요소 정의\n\nimport random\nimport tqdm\n\nfrom torch.optim.adam import Adam\n\n# 학습에 사용할 프로세서 정의\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# 학습에 사용할 데이터셋 정의\ndataset = Eng2Kor()\n\n# 인코더 디코더 정의\nencoder = Encoder(input_size=len(dataset.engBOW), hidden_size=64).to(device)\ndecoder = Decoder(64, len(dataset.korBOW), dropout_p=0.1).to(device)\n# 인코더 디코더 학습을 위한 최적화 정의\nencoder_optimizer = Adam(encoder.parameters(), lr=0.0001)\ndecoder_optimizer = Adam(decoder.parameters(), lr=0.0001)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#학습-루프-정의",
    "href": "DL08.html#학습-루프-정의",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.8 학습 루프 정의",
    "text": "9.8 학습 루프 정의\n\nfor epoch in range(5):\n# for epoch in range(200):\n   iterator = tqdm.tqdm(loader(dataset), total=len(dataset))\n   total_loss = 0\n\n   for data, label in iterator:\n       data = torch.tensor(data, dtype=torch.long).to(device)\n       label = torch.tensor(label, dtype=torch.long).to(device)\n\n       # 인코더의 초기 은닉 상태\n       encoder_hidden = torch.zeros(1, 1, 64).to(device)\n       # 인코더의 모든 시점의 출력을 저장하는 변수\n       encoder_outputs = torch.zeros(11, 64).to(device)\n\n       encoder_optimizer.zero_grad()\n       decoder_optimizer.zero_grad()\n\n       loss = 0\n       for ei in range(len(data)):\n           # 한 단어씩 인코더에 넣어줌\n           encoder_output, encoder_hidden = encoder(data[ei], encoder_hidden)\n           # 인코더의 은닉 상태를 저장\n           encoder_outputs[ei] = encoder_output[0, 0]\n\n       decoder_input = torch.tensor([[0]]).to(device)\n\n       # 인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로 저장\n       decoder_hidden = encoder_hidden\n       use_teacher_forcing = True if random.random() &lt; 0.5 else False\n\n       if use_teacher_forcing:\n           for di in range(len(label)):\n               decoder_output = decoder(\n                   decoder_input, decoder_hidden, encoder_outputs)\n\n               # 직접적으로 정답을 다음 시점의 입력으로 넣어줌\n               target = torch.tensor(label[di], dtype=torch.long).to(device)\n               target = torch.unsqueeze(target, dim=0).to(device)\n               loss += nn.CrossEntropyLoss()(decoder_output, target)\n               decoder_input = target\n       else:\n           for di in range(len(label)):\n               decoder_output = decoder(\n                   decoder_input, decoder_hidden, encoder_outputs)\n\n               # 가장 높은 확률을 갖는 단어의 인덱스가 topi\n               topv, topi = decoder_output.topk(1)\n               decoder_input = topi.squeeze().detach()\n\n               # 디코더의 예측값을 다음 시점의 입력으로 넣어줌\n               target = torch.tensor(label[di], dtype=torch.long).to(device)\n               target = torch.unsqueeze(target, dim=0).to(device)\n               loss += nn.CrossEntropyLoss()(decoder_output, target)\n\n               if decoder_input.item() == 1:  # &lt;EOS&gt; 토큰을 만나면 중지\n                   break\n       \n       # 전체 손실 계산\n       total_loss += loss.item()/len(dataset)\n       iterator.set_description(f\"epoch:{epoch+1} loss:{total_loss}\")\n       loss.backward()\n\n       encoder_optimizer.step()\n       decoder_optimizer.step()\n\ntorch.save(encoder.state_dict(), \"attn_enc.pth\")\ntorch.save(decoder.state_dict(), \"attn_dec.pth\")\n\n  0%|          | 0/3592 [00:00&lt;?, ?it/s]C:\\Users\\sigma\\AppData\\Local\\Temp\\ipykernel_19864\\3089506258.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  data = torch.tensor(data, dtype=torch.long).to(device)\nC:\\Users\\sigma\\AppData\\Local\\Temp\\ipykernel_19864\\3089506258.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  label = torch.tensor(label, dtype=torch.long).to(device)\nC:\\Users\\sigma\\AppData\\Local\\Temp\\ipykernel_19864\\3089506258.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  target = torch.tensor(label[di], dtype=torch.long).to(device)\nepoch:1 loss:0.0029976564420092612:   0%|          | 0/3592 [00:00&lt;?, ?it/s]C:\\Users\\sigma\\AppData\\Local\\Temp\\ipykernel_19864\\3089506258.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  target = torch.tensor(label[di], dtype=torch.long).to(device)\nepoch:1 loss:21.41402745512387: 100%|██████████| 3592/3592 [00:28&lt;00:00, 126.35it/s] \nepoch:2 loss:21.257755387134733: 100%|██████████| 3592/3592 [00:28&lt;00:00, 126.99it/s]\nepoch:3 loss:20.951004168769582: 100%|██████████| 3592/3592 [00:28&lt;00:00, 127.23it/s]\nepoch:4 loss:20.644393546942304: 100%|██████████| 3592/3592 [00:28&lt;00:00, 126.48it/s]\nepoch:5 loss:20.666789276363556: 100%|██████████| 3592/3592 [00:28&lt;00:00, 125.34it/s]",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#모델-성능-평가에-필요한-요소-정의",
    "href": "DL08.html#모델-성능-평가에-필요한-요소-정의",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.9 모델 성능 평가에 필요한 요소 정의",
    "text": "9.9 모델 성능 평가에 필요한 요소 정의\n\n# 인코더 가중치 불러오기\nencoder.load_state_dict(torch.load(\"attn_enc.pth\", map_location=device))\n# 디코더 가중치 불러오기\ndecoder.load_state_dict(torch.load(\"attn_dec.pth\", map_location=device))\n\n# 불러올 영어 문장을 랜덤하게 지정\nidx = random.randint(0, len(dataset))\n# 테스트에 사용할 문장\ninput_sentence = dataset.eng_corpus[idx]\n# 신경망이 번역한 문장\npred_sentence = \"\"\n\ndata, label = dataset[idx]\ndata = torch.tensor(data, dtype=torch.long).to(device)\nlabel = torch.tensor(label, dtype=torch.long).to(device)\n\n# 인코더의 초기 은닉 상태 정의\nencoder_hidden = torch.zeros(1, 1, 64).to(device)\n# 인코더 출력을 담기위한 변수\nencoder_outputs = torch.zeros(11, 64).to(device)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#인코더-동작",
    "href": "DL08.html#인코더-동작",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.10 인코더 동작",
    "text": "9.10 인코더 동작\n\nfor ei in range(len(data)):\n   # 한 단어씩 인코더에 넣어줌\n   encoder_output, encoder_hidden = encoder(data[ei], encoder_hidden)\n   # 인코더의 출력을 저장\n   encoder_outputs[ei] = encoder_output[0, 0]\n\n# 디코더의 초기 입력\n# 0은 &lt;SOS&gt;토큰\ndecoder_input = torch.tensor([[0]]).to(device)\n\n# 인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로\ndecoder_hidden = encoder_hidden",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL08.html#디코더-동작",
    "href": "DL08.html#디코더-동작",
    "title": "9  Day8. 어텐션! 실습(Hands-On)",
    "section": "9.11 디코더 동작",
    "text": "9.11 디코더 동작\n\nfor di in range(11):\n    # 가장 높은 확률을 갖는 단어의 요소를 구함\n   decoder_output = decoder(decoder_input, decoder_hidden, encoder_outputs)\n   topv, topi = decoder_output.topk(1)\n   decoder_input = topi.squeeze().detach()\n\n   # &lt;EOS&gt; 토큰을 만나면 중지\n   if decoder_input.item() == 1:\n       break\n\n   # 가장 높은 단어를 문자열에 추가\n   pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"\n\nprint(input_sentence)  # 영어 문장\nprint(pred_sentence)  # 한글 문장\n\nis this your dictionary\n내",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Day8. 어텐션! 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL09.html",
    "href": "DL09.html",
    "title": "10  Day9. GAN 실습(Hands-On)",
    "section": "",
    "text": "10.1 데이터 불러오기\n!unzip \"./img_align_celeba.zip\" -d \"./GAN/\"",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Day9. GAN 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL09.html#이미지-전처리-정의",
    "href": "DL09.html#이미지-전처리-정의",
    "title": "10  Day9. GAN 실습(Hands-On)",
    "section": "11.1 이미지 전처리 정의",
    "text": "11.1 이미지 전처리 정의\n\nimport torch\nimport torchvision.transforms as tf\n\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data.dataloader import DataLoader\n\n# 이미지의 전처리 과정\ntransforms = tf.Compose([\n   tf.Resize(64),\n   tf.CenterCrop(64),\n   tf.ToTensor(),\n   tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n\n# ImageFolder()를 이용해 데이터셋을 작성\n# root는 최상위 경로를, transform은 전처리를 의미합니다.\ndataset = ImageFolder(\n   root=\"./GAN\",\n   transform=transforms\n)\nloader = DataLoader(dataset, batch_size=128, shuffle=True)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Day9. GAN 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL09.html#생성자-정의",
    "href": "DL09.html#생성자-정의",
    "title": "10  Day9. GAN 실습(Hands-On)",
    "section": "11.2 생성자 정의",
    "text": "11.2 생성자 정의\n\nimport torch.nn as nn\n\nclass Generator(nn.Module):\n   def __init__(self):\n       super(Generator, self).__init__()\n\n       # 생성자를 구성하는 층 정의\n       self.gen = nn.Sequential(\n           nn.ConvTranspose2d(100, 512, kernel_size=4, bias=False),\n           nn.BatchNorm2d(512),\n           nn.ReLU(),\n\n           nn.ConvTranspose2d(512, 256, kernel_size=4,\n                              stride=2, padding=1, bias=False),\n           nn.BatchNorm2d(256),\n           nn.ReLU(),\n\n           nn.ConvTranspose2d(256, 128, kernel_size=4,\n                              stride=2, padding=1, bias=False),\n           nn.BatchNorm2d(128),\n           nn.ReLU(),\n\n           nn.ConvTranspose2d(128, 64, kernel_size=4,\n                              stride=2, padding=1, bias=False),\n           nn.BatchNorm2d(64),\n           nn.ReLU(),\n\n           nn.ConvTranspose2d(64, 3, kernel_size=4,\n                              stride=2, padding=1, bias=False),\n           nn.Tanh()\n       )\n\n   def forward(self, x):\n       return self.gen(x)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Day9. GAN 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL09.html#감별자-정의",
    "href": "DL09.html#감별자-정의",
    "title": "10  Day9. GAN 실습(Hands-On)",
    "section": "11.3 감별자 정의",
    "text": "11.3 감별자 정의\n\nclass Discriminator(nn.Module):\n   def __init__(self):\n       super(Discriminator, self).__init__()\n\n       # 감별자를 구성하는 층의 정의\n       self.disc = nn.Sequential(\n           nn.Conv2d(3, 64, kernel_size=4,\n                     stride=2, padding=1, bias=False),\n           nn.BatchNorm2d(64),\n           nn.LeakyReLU(0.2),\n\n           nn.Conv2d(64, 128, kernel_size=4,\n                     stride=2, padding=1, bias=False),\n           nn.BatchNorm2d(128),\n           nn.LeakyReLU(0.2),\n\n           nn.Conv2d(128, 256, kernel_size=4,\n                     stride=2, padding=1, bias=False),\n           nn.BatchNorm2d(256),\n           nn.LeakyReLU(0.2),\n\n           nn.Conv2d(256, 512, kernel_size=4,\n                     stride=2, padding=1, bias=False),\n           nn.BatchNorm2d(512),\n           nn.LeakyReLU(0.2),\n\n           nn.Conv2d(512, 1, kernel_size=4),\n           nn.Sigmoid()\n       )\n\n   def forward(self, x):\n       return self.disc(x)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Day9. GAN 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL09.html#gan의-가중치-초기화-함수",
    "href": "DL09.html#gan의-가중치-초기화-함수",
    "title": "10  Day9. GAN 실습(Hands-On)",
    "section": "11.4 GAN의 가중치 초기화 함수",
    "text": "11.4 GAN의 가중치 초기화 함수\n\ndef weights_init(m):\n   # 층의 종류 추출\n   classname = m.__class__.__name__\n   if classname.find('Conv') != -1:\n       # 합성곱층 초기화\n       nn.init.normal_(m.weight.data, 0.0, 0.02)\n   elif classname.find('BatchNorm') != -1:\n       # 배치정규화층 초기화\n       nn.init.normal_(m.weight.data, 1.0, 0.02)\n       nn.init.constant_(m.bias.data, 0)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Day9. GAN 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL09.html#학습에-필요한-요소-정의",
    "href": "DL09.html#학습에-필요한-요소-정의",
    "title": "10  Day9. GAN 실습(Hands-On)",
    "section": "11.5 학습에 필요한 요소 정의",
    "text": "11.5 학습에 필요한 요소 정의\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# 생성자 정의\nG = Generator().to(device)\n# 생성자 가중치 초기화\nG.apply(weights_init)\n\n# 감별자 정의\nD = Discriminator().to(device)\n# 감별자 가중치 초기화\nD.apply(weights_init)\n\nimport tqdm\n\nfrom torch.optim.adam import Adam\n\nG_optim = Adam(G.parameters(), lr=0.0001, betas=(0.5, 0.999))\nD_optim = Adam(D.parameters(), lr=0.0001, betas=(0.5, 0.999))",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Day9. GAN 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL09.html#학습-루프-정의",
    "href": "DL09.html#학습-루프-정의",
    "title": "10  Day9. GAN 실습(Hands-On)",
    "section": "11.6 학습 루프 정의",
    "text": "11.6 학습 루프 정의\n\nfor epochs in range(5):\n# for epochs in range(50):\n   iterator = tqdm.tqdm(enumerate(loader, 0), total=len(loader))\n\n   for i, data in iterator:\n       D_optim.zero_grad()\n\n       # 실제 이미지에는 1, 생성된 이미지는 0으로 정답을 설정\n       label = torch.ones_like(\n           data[1], dtype=torch.float32).to(device)\n       label_fake = torch.zeros_like(\n           data[1], dtype=torch.float32).to(device)\n\n       # 실제 이미지를 감별자에 입력\n       real = D(data[0].to(device))\n\n       # 실제 이미지에 대한 감별자의 오차를 계산\n       Dloss_real = nn.BCELoss()(torch.squeeze(real), label)\n       Dloss_real.backward()\n       # 가짜 이미지 생성\n       noise = torch.randn(label.shape[0], 100, 1, 1, device=device)\n       fake = G(noise)\n\n       # 가짜 이미지를 감별자에 입력\n       output = D(fake.detach())\n\n       # 가짜 이미지에 대한 감별자의 오차를 계산\n       Dloss_fake = nn.BCELoss()(torch.squeeze(output), label_fake)\n       Dloss_fake.backward()\n\n       # 감별자의 전체 오차를 학습\n       Dloss = Dloss_real + Dloss_fake\n       D_optim.step()\n       \n       # 생성자의 학습\n       G_optim.zero_grad()\n       output = D(fake)\n       Gloss = nn.BCELoss()(torch.squeeze(output), label)\n       Gloss.backward()\n\n       G_optim.step()\n\n       iterator.set_description(f\"epoch:{epochs} iteration:{i} D_loss:{Dloss} G_loss:{Gloss}\")\n\ntorch.save(G.state_dict(), \"Generator.pth\")\ntorch.save(D.state_dict(), \"Discriminator.pth\")\n\n\nwith torch.no_grad():\n   G.load_state_dict(\n       torch.load(\"./Generator.pth\", map_location=device))\n\n   # 특징 공간 상의 랜덤한 하나의 점을 지정\n   feature_vector = torch.randn(1, 100, 1, 1).to(device)\n   # 이미지 생성\n   pred = G(feature_vector).squeeze()\n   pred = pred.permute(1, 2, 0).cpu().numpy()\n\n   plt.imshow(pred)\n   plt.title(\"predicted image\")\n   plt.show()",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Day9. GAN 실습(Hands-On)</span>"
    ]
  },
  {
    "objectID": "DL10.html",
    "href": "DL10.html",
    "title": "11  streamlit",
    "section": "",
    "text": "11.1 Tutorial\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\n\nst.title('Uber pickups in NYC')\n\nDATE_COLUMN = 'date/time'\nDATA_URL = ('https://s3-us-west-2.amazonaws.com/'\n            'streamlit-demo-data/uber-raw-data-sep14.csv.gz')\n\n@st.cache_data\ndef load_data(nrows):\n    data = pd.read_csv(DATA_URL, nrows=nrows)\n    lowercase = lambda x: str(x).lower()\n    data.rename(lowercase, axis='columns', inplace=True)\n    data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])\n    return data\n\ndata_load_state = st.text('Loading data...')\ndata = load_data(10000)\ndata_load_state.text(\"Done! (using st.cache_data)\")\n\nif st.checkbox('Show raw data'):\n    st.subheader('Raw data')\n    st.write(data)\n\nst.subheader('Number of pickups by hour')\nhist_values = np.histogram(data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]\nst.bar_chart(hist_values)\n\n# Some number in the range 0-23\nhour_to_filter = st.slider('hour', 0, 23, 17)\nfiltered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]\n\nst.subheader('Map of all pickups at %s:00' % hour_to_filter)\nst.map(filtered_data)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>streamlit</span>"
    ]
  },
  {
    "objectID": "DL10.html#ok-lets-lenet-5",
    "href": "DL10.html#ok-lets-lenet-5",
    "title": "11  streamlit",
    "section": "11.2 Ok, Let’s LeNet-5",
    "text": "11.2 Ok, Let’s LeNet-5\n\n#!pip install streamlit streamlit-drawable-canvas opencv-python\n\n\nfrom streamlit_drawable_canvas import st_canvas\nimport streamlit as st\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\n\nfrom PIL import Image\n\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n        self.act1 = nn.Tanh()\n        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)\n        self.act2 = nn.Tanh()\n        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n\n        self.conv3 = nn.Conv2d(16, 120, kernel_size=5, stride=1, padding=0)\n        self.act3 = nn.Tanh()\n\n        self.flat = nn.Flatten()\n        self.fc1 = nn.Linear(1*1*120, 84)\n        self.act4 = nn.Tanh()\n        self.fc2 = nn.Linear(84, 10)\n        \n    def forward(self, x):\n        x = self.act1(self.conv1(x))\n        x = self.pool1(x)\n        x = self.act2(self.conv2(x))\n        x = self.pool2(x)\n        x = self.act3(self.conv3(x))\n        x = self.act4(self.fc1(self.flat(x)))\n        x = self.fc2(x)\n        return x\n\ndef import_and_predict(img, model):\n  img_transform = transforms.Compose([transforms.Grayscale(), transforms.RandomInvert(p=1)])\n  img_new = img_transform(img)\n  composed = transforms.Compose([transforms.Resize(28), transforms.ToTensor()])\n  img_t = composed(img_new)\n  img_t = img_t.type(torch.float32)\n  x = img_t.expand(1, 1, 28, 28)\n  z = model(x)\n  z = nn.Softmax(dim=1)(z)\n  p_max, yhat = torch.max(z.data, 1)\n  p = float(format(p_max.numpy()[0], '.4f'))*100\n  yhat = int(float(yhat.numpy()[0]))\n  st.success(f\"작성하신 숫자는 {p:.2f} %로 {yhat}로 예측됩니다.\")\n\ndef load_model():\n  model = LeNet5()\n  model.load_state_dict(torch.load('./LeNet5_20240129.pth'))\n  return model\n\nmodel = load_model()\nst.write(\"\"\"\n         # MNIST를 사용한 숫자 인식 예측 앱\n        \"\"\")\nst.markdown(\"\"\"\n            ## 숫자를 그려보세요!\n            \"\"\")\nst.write(\"Note: 숫자가 캔버스의 대부분을 차지하고 캔버스 중앙에 위치하도록 이미지를 그립니다.\")\nst.sidebar.header(\"사용자 입력\")\n\n# Specify brush parameters and drawing mode\nb_width = st.sidebar.slider(\"브러시 너비 선택: \", 1, 100, 10)\nb_color = st.sidebar.color_picker(\"브러시 색상 16진수 입력: \")\nbg_color = st.sidebar.color_picker(\"배경색 16진수 입력: \", \"#FFFFFF\")\n\n# Create a canvas component\ncanvas = st_canvas(\n    stroke_width=b_width,\n    stroke_color=b_color,\n    background_color=bg_color,\n    update_streamlit=True,\n    height=300,\n    width=300,\n    drawing_mode='freedraw',\n    key=\"canvas\",\n)\n\nif canvas.image_data is not None:\n    image = Image.fromarray(canvas.image_data)\n    w, h = image.size\n    st.image(image, width=500, caption=\"숫자 이미지\")\n    import_and_predict(image, model)\n\nFileNotFoundError: [Errno 2] No such file or directory: './LeNet5_20240129.pth'",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>streamlit</span>"
    ]
  },
  {
    "objectID": "DL11.html",
    "href": "DL11.html",
    "title": "12  Gradio",
    "section": "",
    "text": "12.1 필수적인 패키지 설치",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Gradio</span>"
    ]
  },
  {
    "objectID": "DL11.html#필수적인-패키지-설치",
    "href": "DL11.html#필수적인-패키지-설치",
    "title": "12  Gradio",
    "section": "",
    "text": "gradio, 머신 러닝 모델, API 또는 Python 데모 또는 웹 애플리케이션을 빠르게 구축할 수 있는 오픈 소스 Python 패키지\nfasttext, 단어 임베딩 및 텍스트 분류 학습을 위한 라이브러리\ntransformers, 트랜스포머 모델을 사용하기 위한 라이브러리\n\n\n12.1.1 transformers 라이브러리가 필요한 이유\nTransformer 모델은 일반적으로 규모가 큽니다. 수백만에서 수천억 개의 매개변수가 포함된 모델을 학습하고 배포하는 일은 복잡한 작업입니다. 게다가 새로운 모델이 거의 매일 출시되고 각각 고유한 구현 방식이 있기 때문에, 이 모든 모델들을 시험해 보는 것 또한 쉬운 일이 아닙니다.\nTransformers 라이브러리는 이러한 문제를 해결하기 위해 만들어졌습니다. 이 라이브러리의 목표는 모든 Transformer 모델들을 적재하고, 학습하고, 저장할 수 있는 단일 API를 제공하는 것입니다. Transformers 라이브러리의 특징은 다음과 같습니다.\n\n사용 용이성(Ease of use): 최신 NLP 모델을 기반으로 추론 작업을 수행하기 위해서, 해당 모델을 다운로드, 적재 및 사용하는데 단 두 줄의 코드만 작성하면 됩니다.\n유연성(Flexibility): 기본적으로 모든 모델은 PyTorch의 nn.Module 또는 TensorFlow의 tf.keras.Model 클래스로 표현되며 각 기계 학습(ML) 프레임워크(framework, e.g., PyTorch, Tensorflow) 내에서의 다른 모델들과 동일하게 취급됩니다.\n단순성(Simplicity): 라이브러리 전체에서 추상화(abstraction)가 거의 이루어지지 않습니다. “All in one file”은 🤗Transformers 라이브러리의 핵심 개념입니다. 다시 말해서, 모델의 순전파(forward pass)가 단일 파일에 완전히 정의되어 해당 코드 자체를 쉽게 이해하고 해킹할 수 있습니다.\n\n\nimport gradio as gr\nimport fasttext\n\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import AutoTokenizer\n\nimport numpy as np\nimport pandas as pd\nimport torch",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Gradio</span>"
    ]
  },
  {
    "objectID": "DL11.html#사용자-입력-및-출력",
    "href": "DL11.html#사용자-입력-및-출력",
    "title": "12  Gradio",
    "section": "12.2 사용자 입력 및 출력",
    "text": "12.2 사용자 입력 및 출력\nwith gr.Blocks() as app:\n    gr.Markdown(\n    \"\"\"\n    &lt;h1 align=\"center\"&gt;\n    영화 리뷰 점수 판별기\n    &lt;/h1&gt;\n    \"\"\")\n\n    gr.Markdown(\n    \"\"\"\n    - 영화 리뷰를 입력하면, 리뷰가 긍정인지 부정인지 판별해주는 모델\n        - 영어와 한글을 지원하며, 언어를 직접 선택할수도, 혹은 모델이 언어감지를 직접 하도록 할 수 있음\n    - 사용자가 리뷰를 입력하면, (1) 감지된 언어, (2) 긍정일 확률과 부정일 확률, (3) 입력된 리뷰의 어떤 단어가 긍정/부정 결정에 영향을 주었는지 확인\n        - 긍정일 경우 빨강색, 부정일 경우 파란색으로 표시\n    \"\"\")\n\n    with gr.Accordion(label=\"모델에 대한 설명 ( 여기를 클릭 하시오. )\", open=False):\n        gr.Markdown(\n        \"\"\"\n        - 언어감지는 `fasttext`의 `language detector`을 사용\n        - 영어는 `bert-base-uncased` 기반으로, 영어 영화 리뷰 분석 데이터셋인 `SST-2`로 학습 및 평가(92.8%의 정확도)\n        - 한국어는 `klue/roberta-base` 기반이으로, 네이버 영화의 리뷰를 크롤링해서 영화 리뷰 분석 데이터셋을 제작하고, 이를 이용하여 모델을 학습 및 평가(94%의 정확도)\n        - 단어별 영향력은, 단어 각각을 모델에 넣었을 때 결과가 긍정으로 나오는지 부정으로 나오는지를 바탕으로 측정하였다.\n        \"\"\")\n\n    with gr.Row():\n        with gr.Column():\n            inputs_1 = gr.Dropdown(choices=['언어감지 기능 사용', 'Eng', 'Kor'], value='언어감지 기능 사용', label='Lang')\n            inputs_2 = gr.Textbox(placeholder=\"리뷰를 입력하시오.\", label='Text')\n            with gr.Row():\n                btn = gr.Button(\"제출하기\")\n        with gr.Column():\n            output_1 = gr.Label(num_top_classes=3, label='Lang')\n            output_2 = gr.Label(num_top_classes=2, label='Result')\n            output_3 = gr.HighlightedText(label=\"Analysis\", combine_adjacent=False).style(color_map={\"+++\": \"#CF0000\", \"++\": \"#FF3232\", \"+\": \"#FFD4D4\", \"---\": \"#0004FE\", \"--\": \"#4C47FF\", \"-\": \"#BEBDFF\"})\n    \n    btn.click(fn=builder, inputs=[inputs_1, inputs_2], outputs=[output_1, output_2, output_3])\n\nif __name__ == \"__main__\":\n    app.launch()",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Gradio</span>"
    ]
  },
  {
    "objectID": "DL11.html#모델-실행",
    "href": "DL11.html#모델-실행",
    "title": "12  Gradio",
    "section": "12.3 모델 실행",
    "text": "12.3 모델 실행\nid2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\nlabel2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n\nclass LanguageIdentification:\n    def __init__(self):\n        pretrained_lang_model = \"./lid.176.ftz\"\n        self.model = fasttext.load_model(pretrained_lang_model)\n\n    def predict_lang(self, text):\n        predictions = self.model.predict(text, k=200) # returns top 200 matching languages\n        return predictions\n\nLANGUAGE = LanguageIdentification()\n\ndef tokenized_data(tokenizer, inputs):\n    return tokenizer.batch_encode_plus(\n        [inputs],\n        return_tensors=\"pt\",\n        padding=\"max_length\",\n        max_length=64,\n        truncation=True)\n\neng_model_name = \"roberta-base\"\neng_step = 1900\neng_tokenizer = AutoTokenizer.from_pretrained(eng_model_name)\neng_file_name = \"{}-{}.pt\".format(eng_model_name, eng_step)\neng_state_dict = torch.load(eng_file_name)\neng_model = AutoModelForSequenceClassification.from_pretrained(\n    eng_model_name, num_labels=2, id2label=id2label, label2id=label2id,\n    state_dict=eng_state_dict\n)\n\nkor_model_name = \"klue/roberta-small\"\nkor_step = 2400\nkor_tokenizer = AutoTokenizer.from_pretrained(kor_model_name)\nkor_file_name = \"{}-{}.pt\".format(kor_model_name.replace('/', '_'), kor_step)\nkor_state_dict = torch.load(kor_file_name)\nkor_model = AutoModelForSequenceClassification.from_pretrained(\n    kor_model_name, num_labels=2, id2label=id2label, label2id=label2id,\n    state_dict=kor_state_dict\n)\ndef builder(Lang, Text):\n    percent_kor, percent_eng = 0, 0\n    text_list = Text.split(' ')\n\n    # [ output_1 ]\n    if Lang == '언어감지 기능 사용':\n        pred = LANGUAGE.predict_lang(Text)\n        if '__label__en' in pred[0]:\n            Lang = 'Eng'\n            idx = pred[0].index('__label__en')\n            p_eng = pred[1][idx]\n        if '__label__ko' in pred[0]:\n            Lang = 'Kor'\n            idx = pred[0].index('__label__ko')\n            p_kor = pred[1][idx]\n        percent_kor = p_kor / (p_kor+p_eng)\n        percent_eng = p_eng / (p_kor+p_eng)\n\n    if Lang == 'Eng':\n        model = eng_model\n        tokenizer = eng_tokenizer\n        if percent_eng==0: percent_eng=1\n\n    if Lang == 'Kor':\n        model = kor_model\n        tokenizer = kor_tokenizer\n        if percent_kor==0: percent_kor=1\n\n    # [ output_2 ]\n    inputs = tokenized_data(tokenizer, Text)\n    model.eval()\n    with torch.no_grad():\n        logits = model(input_ids=inputs['input_ids'], \n            attention_mask=inputs['attention_mask']).logits    \n    m = torch.nn.Softmax(dim=1)\n    output = m(logits)\n\n    # [ output_3 ]\n    output_analysis = []\n    for word in text_list:\n        tokenized_word = tokenized_data(tokenizer, word)\n        with torch.no_grad():\n            logit = model(input_ids=tokenized_word['input_ids'], \n                attention_mask=tokenized_word['attention_mask']).logits\n        word_output = m(logit)\n        if word_output[0][1] &gt; 0.99:\n            output_analysis.append( (word, '+++') )\n        elif word_output[0][1] &gt; 0.9:\n            output_analysis.append( (word, '++') )\n        elif word_output[0][1] &gt; 0.8:\n            output_analysis.append( (word, '+') )\n        elif word_output[0][1] &lt; 0.01:\n            output_analysis.append( (word, '---') )\n        elif word_output[0][1] &lt; 0.1:\n            output_analysis.append( (word, '--') )\n        elif word_output[0][1] &lt; 0.2:\n            output_analysis.append( (word, '-') )\n        else:\n            output_analysis.append( (word, None) )\n\n    return [ {'Kor': percent_kor, 'Eng': percent_eng}, \n            {id2label[1]: output[0][1].item(), id2label[0]: output[0][0].item()}, \n            output_analysis ]",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Gradio</span>"
    ]
  },
  {
    "objectID": "DL00_Python.html",
    "href": "DL00_Python.html",
    "title": "13  함수와 클래스",
    "section": "",
    "text": "arr = [5,3,2,1,3,2,1] # 변수\nprint(arr) # 함수\nfor i in range(len(arr) - 1, 0, -1): # 반복\n  for j in range(i): # 반복\n    if arr[j] &gt; arr[j + 1]: # 제어\n        arr[j], arr[j + 1] = arr[j + 1], arr[j] # 할당\nprint(arr) # 함수\n\n[5, 3, 2, 1, 3, 2, 1]\n[1, 1, 2, 2, 3, 3, 5]\n\n\n\narr = [5,3,2,1,3,2,1] # 변수\nprint(arr) # 함수\nfor i in range(len(arr) - 1, 0, -1):\n  swapped = False\n  for j in range(i):\n    if arr[j] &gt; arr[j + 1]:\n      arr[j], arr[j + 1] = arr[j + 1], arr[j]\n      swapped = True\n  if not swapped:\n    break\nprint(arr) # 함수\n\n[5, 3, 2, 1, 3, 2, 1]\n[1, 1, 2, 2, 3, 3, 5]\n\n\n\narr = [5,3,2,1,3,2,1] # 변수\nprint(arr) # 함수\nend = len(arr) - 1\nwhile end &gt; 0:\n  last_swap = 0\n  for i in range(end):\n    if arr[i] &gt; arr[i + 1]:\n      arr[i], arr[i + 1] = arr[i + 1], arr[i]\n      last_swap = i\n  end = last_swap\nprint(arr) # 함수\n\n[5, 3, 2, 1, 3, 2, 1]\n[1, 1, 2, 2, 3, 3, 5]\n\n\n\narr = [5,3,2,1,3,2,1] # 변수\nprint(arr) # 함수\ndef bubble_sort(x):\n  arr = x.copy()\n  end = len(arr) - 1\n  while end &gt; 0:\n    last_swap = 0\n    for i in range(end):\n      if arr[i] &gt; arr[i + 1]:\n        arr[i], arr[i + 1] = arr[i + 1], arr[i]\n        last_swap = i\n    end = last_swap\n  return arr\nprint(bubble_sort(arr)) # 함수\n\n[5, 3, 2, 1, 3, 2, 1]\n[1, 1, 2, 2, 3, 3, 5]\n\n\n\nclass BubbleSort():\n  def __init__(self, x):\n    self.arr = x.copy()\n\n  def sort(self):\n    end = len(self.arr) - 1\n    while end &gt; 0:\n      last_swap = 0\n      for i in range(end):\n        if self.arr[i] &gt; self.arr[i + 1]:\n          self.arr[i], self.arr[i + 1] = self.arr[i + 1], self.arr[i]\n          last_swap = i\n      end = last_swap\n    return self.arr\n\n\nbubble_sort = BubbleSort([5,3,2,1,3,2,1])\nsort_result = bubble_sort.sort()\nprint(sort_result)\n\n[1, 1, 2, 2, 3, 3, 5]\n\n\n\nbubble_sort &lt;- function(x) {\n  n &lt;- length(x)\n  for (i in 1:(n-1)) {\n    for (j in 1:(n-i)) {\n      if (x[j] &gt; x[j+1]) {\n        temp &lt;- x[j]\n        x[j] &lt;- x[j+1]\n        x[j+1] &lt;- temp\n      }\n    }\n  }\n  return(x)\n}\n\n\nx &lt;- sample(1:10)\ncat(\"Input: \", x, \"\\n\")\ncat(\"Output: \", bubble_sort(x), \"\\n\")\n\nInput:  4 5 9 10 3 6 1 2 7 8 \nOutput:  1 2 3 4 5 6 7 8 9 10 \n\n\n\nbubble_sort &lt;- function(x) {\n  swapped &lt;- TRUE\n  while (swapped) {\n    swapped &lt;- FALSE\n    for (i in 1:(length(x) - 1)) {\n      if (x[i] &gt; x[i + 1]) {\n        tmp &lt;- x[i]\n        x[i] &lt;- x[i + 1]\n        x[i + 1] &lt;- tmp\n        swapped &lt;- TRUE\n      }\n    }\n  }\n  return(x)\n}\n\n\nx &lt;- sample(1:10)\ncat(\"Input: \", x, \"\\n\")\ncat(\"Output: \", bubble_sort(x), \"\\n\")\n\nInput:  1 2 3 4 9 6 10 7 8 5 \nOutput:  1 2 3 4 5 6 7 8 9 10",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>함수와 클래스</span>"
    ]
  },
  {
    "objectID": "DL00_Torch.html",
    "href": "DL00_Torch.html",
    "title": "14  벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)",
    "section": "",
    "text": "14.1 파이토치 텐서 선언하기(PyTorch Tensor Allocation)\n파이토치는 Numpy와 매우 유사합니다. 하지만 더 낫습니다(better). 우선 torch를 임포트합니다.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)</span>"
    ]
  },
  {
    "objectID": "DL00_Torch.html#파이토치-텐서-선언하기pytorch-tensor-allocation",
    "href": "DL00_Torch.html#파이토치-텐서-선언하기pytorch-tensor-allocation",
    "title": "14  벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)",
    "section": "",
    "text": "import torch\n\n14.1.1 1D with PyTorch\nt = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\nprint(t)\ndim()을 사용하면 현재 텐서의 차원을 보여줍니다. shape나 size()를 사용하면 크기를 확인할 수 있습니다.\nprint(t.dim())  # rank. 즉, 차원\nprint(t.shape)  # shape\nprint(t.size()) # shape\n\n1\ntorch.Size([7])\ntorch.Size([7])\n현재 1차원 텐서이며, 원소는 7개입니다. 인덱스로 접근하는 것과 슬라이싱을 해봅시다. 방법은 Numpy 실습과 같습니다.\nprint(t[0], t[1], t[-1])  # 인덱스로 접근\nprint(t[2:5], t[4:-1])    # 슬라이싱\nprint(t[:2], t[3:])       # 슬라이싱\n\ntensor(0.) tensor(1.) tensor(6.)\ntensor([2., 3., 4.]) tensor([4., 5.])\ntensor([0., 1.]) tensor([3., 4., 5., 6.])\n\n\n14.1.2 2D with PyTorch\n파이토치로 2차원 텐서인 행렬을 만들어봅시다.\n\nimport torch\n\n\nt = torch.FloatTensor([[1., 2., 3.],\n                       [4., 5., 6.],\n                       [7., 8., 9.],\n                       [10., 11., 12.]\n                      ])\nprint(t)\n\ntensor([[ 1.,  2.,  3.],\n        [ 4.,  5.,  6.],\n        [ 7.,  8.,  9.],\n        [10., 11., 12.]])\n\n\ndim()을 사용하면 현재 텐서의 차원을 보여줍니다. size()를 사용하면 크기를 확인할 수 있습니다.\n\nprint(t.dim())  # rank. 즉, 차원\nprint(t.size()) # shape\n\n2\ntorch.Size([4, 3])\n\n\n\nprint(t[:, 1]) # 첫번째 차원을 전체 선택한 상황에서 두번째 차원의 첫번째 것만 가져온다.\nprint(t[:, 1].size()) # ↑ 위의 경우의 크기\n\ntensor([ 2.,  5.,  8., 11.])\ntorch.Size([4])\n\n\n\n\n14.1.3 브로드캐스팅(Broadcasting)\n원래 m1의 크기는 (1, 2)이며 m2의 크기는 (1,)입니다. 그런데 파이토치는 m2의 크기를 (1, 2)로 변경하여 연산을 수행합니다. 이번에는 벡터 간 연산에서 브로드캐스팅이 적용되는 경우를 보겠습니다.\n\nm1 = torch.FloatTensor([[3, 3]])\nm2 = torch.FloatTensor([[2, 2]])\nprint(m1 + m2)\n\ntensor([[5., 5.]])\n\n\n\n# Vector + scalar\nm1 = torch.FloatTensor([[1, 2]])\nm2 = torch.FloatTensor([3]) # [3] -&gt; [3, 3]\nprint(m1 + m2)\n\ntensor([[4., 5.]])\n\n\nm1의 크기는 (1, 2) m2의 크기는 (2, 1)였습니다. 이 두 벡터는 원래 수학적으로는 덧셈을 수행할 수 없습니다. 그러나 파이토치는 두 벡터의 크기를 (2, 2)로 변경하여 덧셈을 수행합니다.\n\n# 2 x 1 Vector + 1 x 2 Vector\nm1 = torch.FloatTensor([[1, 2]])\nm2 = torch.FloatTensor([[3], [4]])\nprint(m1 + m2)\n\ntensor([[4., 5.],\n        [5., 6.]])\n\n\n브로드캐스팅 과정에서 실제로 두 텐서가 어떻게 변경되는지 보겠습니다.\n[1, 2]\n==&gt; [[1, 2],\n     [1, 2]]\n[3]\n[4]\n==&gt; [[3, 3],\n     [4, 4]]\n브로드캐스팅은 편리하지만, 자동으로 실행되는 기능이므로 사용자 입장에서 굉장히 주의해서 사용해야 합니다. 예를 들어 A 텐서와 B 텐서가 있을 때, 사용자는 이 두 텐서의 크기가 같다고 착각하고 덧셈 연산을 수행했다고 가정해보겠습니다. 하지만 실제로 이 두 텐서의 크기는 달랐고 브로드캐스팅이 수행되어 덧셈 연산이 수행되었습니다. 만약, 두 텐서의 크기가 다르다고 에러를 발생시킨다면 사용자는 이 연산이 잘못되었음을 바로 알 수 있지만 브로드캐스팅은 자동으로 수행되므로 사용자는 나중에 원하는 결과가 나오지 않았더라도 어디서 문제가 발생했는지 찾기가 굉장히 어려울 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)</span>"
    ]
  },
  {
    "objectID": "DL00_Torch.html#행렬-곱셈과-곱셈의-차이matrix-multiplication-vs.-multiplication",
    "href": "DL00_Torch.html#행렬-곱셈과-곱셈의-차이matrix-multiplication-vs.-multiplication",
    "title": "14  벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)",
    "section": "14.2 행렬 곱셈과 곱셈의 차이(Matrix Multiplication Vs. Multiplication)",
    "text": "14.2 행렬 곱셈과 곱셈의 차이(Matrix Multiplication Vs. Multiplication)\n행렬로 곱셈을 하는 방법은 크게 두 가지가 있습니다. 바로 행렬 곱셈(.matmul)과 원소 별 곱셈(.mul)입니다. 파이토치 텐서의 행렬 곱셈을 보겠습니다. 이는 matmul()을 통해 수행합니다.\n\nm1 = torch.FloatTensor([[1, 2], [3, 4]])\nm2 = torch.FloatTensor([[1], [2]])\nprint('Shape of Matrix 1: ', m1.shape) # 2 x 2\nprint('Shape of Matrix 2: ', m2.shape) # 2 x 1\nprint(m1.matmul(m2)) # 2 x 1\n\nShape of Matrix 1:  torch.Size([2, 2])\nShape of Matrix 2:  torch.Size([2, 1])\ntensor([[ 5.],\n        [11.]])\n\n\n위의 결과는 2 x 2 행렬과 2 x 1 행렬(벡터)의 행렬 곱셈의 결과를 보여줍니다.\n행렬 곱셈이 아니라 element-wise 곱셈이라는 것이 존재합니다. 이는 동일한 크기의 행렬이 동일한 위치에 있는 원소끼리 곱하는 것을 말합니다. 아래는 서로 다른 크기의 행렬이 브로드캐스팅이 된 후에 element-wise 곱셈이 수행되는 것을 보여줍니다. 이는 * 또는 mul()을 통해 수행합니다.\n\nm1 = torch.FloatTensor([[1, 2], [3, 4]])\nm2 = torch.FloatTensor([[1], [2]])\nprint('Shape of Matrix 1: ', m1.shape) # 2 x 2\nprint('Shape of Matrix 2: ', m2.shape) # 2 x 1\nprint(m1 * m2) # 2 x 2\nprint(m1.mul(m2))\n\nShape of Matrix 1:  torch.Size([2, 2])\nShape of Matrix 2:  torch.Size([2, 1])\ntensor([[1., 2.],\n        [6., 8.]])\ntensor([[1., 2.],\n        [6., 8.]])\n\n\nm1 행렬의 크기는 (2, 2)이었습니다. m2 행렬의 크기는 (2, 1)였습니다. 이때 element-wise 곱셈을 수행하면, 두 행렬의 크기는 브로드캐스팅이 된 후에 곱셈이 수행됩니다. 더 정확히는 여기서 m2의 크기가 변환됩니다.\n브로드캐스팅 과정에서 m2 텐서가 어떻게 변경되는지 보겠습니다.\n[1]\n[2]\n==&gt; [[1, 1],\n     [2, 2]]",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)</span>"
    ]
  },
  {
    "objectID": "DL00_Torch.html#평균",
    "href": "DL00_Torch.html#평균",
    "title": "14  벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)",
    "section": "14.3 평균",
    "text": "14.3 평균\n평균을 구하는 방법도 제공하고 있습니다. 이는 Numpy에서의 사용법과 매우 유사합니다. 우선 1차원인 벡터를 선언하여 .mean()을 사용하여 원소의 평균을 구합니다.\n\nt = torch.FloatTensor([1, 2])\nprint(t.mean())\n\ntensor(1.5000)\n\n\n1과 2의 평균인 1.5가 나옵니다. 이번에는 2차원인 행렬을 선언하여 .mean()을 사용해봅시다. 우선 2차원 행렬을 선언합니다.\n\nt = torch.FloatTensor([[1, 2], [3, 4]])\nprint(t)\n\ntensor([[1., 2.],\n        [3., 4.]])\n\n\n\nprint(t.mean())\n\ntensor(2.5000)\n\n\n4개의 원소의 평균인 2.5가 나왔습니다. 이번에는 dim. 즉, 차원(dimension)을 인자로 주는 경우를 보겠습니다.\n\nprint(t.mean(dim=0))\n\ntensor([2., 3.])\n\n\ndim=0이라는 것은 첫번째 차원을 의미합니다. 행렬에서 첫번째 차원은 ’행’을 의미합니다. 그리고 인자로 dim을 준다면 해당 차원을 제거한다는 의미가 됩니다. 다시 말해 행렬에서 ’열’만을 남기겠다는 의미가 됩니다. 기존 행렬의 크기는 (2, 2)였지만 이를 수행하면 열의 차원만 보존되면서 (1, 2)가 됩니다. 이는 (2,)와 같으며 벡터입니다. 열의 차원을 보존하면서 평균을 구하면 아래와 같이 연산합니다.\n# 실제 연산 과정\nt.mean(dim=0)은 입력에서 첫번째 차원을 제거한다.\n\n[[1., 2.],\n [3., 4.]]\n\n1과 3의 평균을 구하고, 2와 4의 평균을 구한다.\n결과 ==&gt; [2., 3.]\n이번에는 인자로 dim=1을 주겠습니다. 이번에는 두번째 차원을 제거합니다. 즉, 열이 제거된 텐서가 되어야 합니다. 열의 차원이 제거되어야 하므로 (2, 2)의 크기에서 (2, 1)의 크기가 됩니다. 이번에는 1과 2의 평균을 구하고 3과 4의 평균을 구하게 됩니다. 그렇다면 결과는 아래와 같습니다.\n\nprint(t.mean(dim=1))\n\ntensor([1.5000, 3.5000])",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)</span>"
    ]
  },
  {
    "objectID": "DL00_Torch.html#덧셈",
    "href": "DL00_Torch.html#덧셈",
    "title": "14  벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)",
    "section": "14.4 덧셈",
    "text": "14.4 덧셈\n덧셈(Sum)은 평균(Mean)과 연산 방법이나 인자가 의미하는 바는 정확히 동일합니다. 다만, 평균이 아니라 덧셈을 할 뿐입니다.\n\nt = torch.FloatTensor([[1, 2], [3, 4]])\nprint(t)\n\ntensor([[1., 2.],\n        [3., 4.]])\n\n\n\nprint(t.sum()) # 단순히 원소 전체의 덧셈을 수행\nprint(t.sum(dim=0)) # 행을 제거\nprint(t.sum(dim=1)) # 열을 제거\nprint(t.sum(dim=-1)) # 열을 제거\n\ntensor(10.)\ntensor([4., 6.])\ntensor([3., 7.])\ntensor([3., 7.])",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)</span>"
    ]
  },
  {
    "objectID": "DL00_Torch.html#최대max와-아그맥스argmax",
    "href": "DL00_Torch.html#최대max와-아그맥스argmax",
    "title": "14  벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)",
    "section": "14.5 최대(Max)와 아그맥스(ArgMax)",
    "text": "14.5 최대(Max)와 아그맥스(ArgMax)\n최대(Max)는 원소의 최대값을 리턴하고, 아그맥스(ArgMax)는 최대값을 가진 인덱스를 리턴합니다. (2, 2) 크기의 행렬을 선언하고 Max를 사용해봅시다.\n\nt = torch.FloatTensor([[1, 2], [3, 4]])\nprint(t)\n\ntensor([[1., 2.],\n        [3., 4.]])\n\n\n우선 (2, 2) 행렬을 선언하였습니다. 이제 .max()를 사용합니다. 원소 중 최대값인 4를 리턴합니다. 이번에는 인자로 dim=0을 주겠습니다. 첫번째 차원을 제거한다는 의미입니다.\n\nprint(t.max()) # Returns one value: max\n\ntensor(4.)\n\n\n행의 차원을 제거한다는 의미이므로 (1, 2) 텐서를 만듭니다. 결과는 [3, 4]입니다. 그런데 [1, 1]이라는 값도 함께 리턴되었습니다. max에 dim 인자를 주면 argmax도 함께 리턴하는 특징 때문입니다. 첫번째 열에서 3의 인덱스는 1이었습니다. 두번째 열에서 4의 인덱스는 1이었습니다. 그러므로 [1, 1]이 리턴됩니다. 어떤 의미인지는 아래 설명해봤습니다.\n# [1, 1]가 무슨 의미인지 봅시다. 기존 행렬을 다시 상기해봅시다.\n[[1, 2],\n [3, 4]]\n첫번째 열에서 0번 인덱스는 1, 1번 인덱스는 3입니다.\n두번째 열에서 0번 인덱스는 2, 1번 인덱스는 4입니다.\n다시 말해 3과 4의 인덱스는 [1, 1]입니다.\n만약 두 개를 함께 리턴받는 것이 아니라 max 또는 argmax만 리턴받고 싶다면 다음과 같이 리턴값에도 인덱스를 부여하면 됩니다. 0번 인덱스를 사용하면 max 값만 받아올 수 있고, 1번 인덱스를 사용하면 argmax 값만 받아올 수 있습니다.\n\nprint('Max: ', t.max(dim=0)[0])\nprint('Argmax: ', t.max(dim=0)[1])\n\nMax:  tensor([3., 4.])\nArgmax:  tensor([1, 1])\n\n\n이번에는 dim=1로 인자를 주었을 때와 dim=-1로 인자를 주었을 때를 보겠습니다.\n\nprint(t.max(dim=1))\nprint(t.max(dim=-1))\n\ntorch.return_types.max(\nvalues=tensor([2., 4.]),\nindices=tensor([1, 1]))\ntorch.return_types.max(\nvalues=tensor([2., 4.]),\nindices=tensor([1, 1]))",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)</span>"
    ]
  }
]