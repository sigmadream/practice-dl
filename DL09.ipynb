{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Day9. GAN 실습(Hands-On)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUZ0VNPFUKh4"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTvgVBOPPymR"
      },
      "outputs": [],
      "source": [
        "!unzip \"./img_align_celeba.zip\" -d \"./GAN/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aETYNzDGFUZ8"
      },
      "source": [
        "# 데이터 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "S6FvglW4E-ja",
        "outputId": "a39a397f-2d2a-42d6-eb39-529f762fa6fb"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# 이미지까지의 경로\n",
        "pth_to_imgs = \"./GAN/img_align_celeba\"\n",
        "imgs = glob.glob(os.path.join(pth_to_imgs, \"*\"))\n",
        "\n",
        "# 9개의 이미지를 보여줌\n",
        "for i in range(9):\n",
        "   plt.subplot(3, 3, i+1)\n",
        "   img = Image.open(imgs[i])\n",
        "   plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO_rsmCnIh5L"
      },
      "source": [
        "## 이미지 전처리 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apntXi_MIZ5r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as tf\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "# 이미지의 전처리 과정\n",
        "transforms = tf.Compose([\n",
        "   tf.Resize(64),\n",
        "   tf.CenterCrop(64),\n",
        "   tf.ToTensor(),\n",
        "   tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "# ImageFolder()를 이용해 데이터셋을 작성\n",
        "# root는 최상위 경로를, transform은 전처리를 의미합니다.\n",
        "dataset = ImageFolder(\n",
        "   root=\"./GAN\",\n",
        "   transform=transforms\n",
        ")\n",
        "loader = DataLoader(dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH-IJ4SCRiTJ"
      },
      "source": [
        "## 생성자 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqV6hFPvQfYC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Generator, self).__init__()\n",
        "\n",
        "       # 생성자를 구성하는 층 정의\n",
        "       self.gen = nn.Sequential(\n",
        "           nn.ConvTranspose2d(100, 512, kernel_size=4, bias=False),\n",
        "           nn.BatchNorm2d(512),\n",
        "           nn.ReLU(),\n",
        "\n",
        "           nn.ConvTranspose2d(512, 256, kernel_size=4,\n",
        "                              stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(256),\n",
        "           nn.ReLU(),\n",
        "\n",
        "           nn.ConvTranspose2d(256, 128, kernel_size=4,\n",
        "                              stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(128),\n",
        "           nn.ReLU(),\n",
        "\n",
        "           nn.ConvTranspose2d(128, 64, kernel_size=4,\n",
        "                              stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(64),\n",
        "           nn.ReLU(),\n",
        "\n",
        "           nn.ConvTranspose2d(64, 3, kernel_size=4,\n",
        "                              stride=2, padding=1, bias=False),\n",
        "           nn.Tanh()\n",
        "       )\n",
        "\n",
        "   def forward(self, x):\n",
        "       return self.gen(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy6UolSBRntO"
      },
      "source": [
        "## 감별자 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b56JhqcTRkmi"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Discriminator, self).__init__()\n",
        "\n",
        "       # 감별자를 구성하는 층의 정의\n",
        "       self.disc = nn.Sequential(\n",
        "           nn.Conv2d(3, 64, kernel_size=4,\n",
        "                     stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(64),\n",
        "           nn.LeakyReLU(0.2),\n",
        "\n",
        "           nn.Conv2d(64, 128, kernel_size=4,\n",
        "                     stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(128),\n",
        "           nn.LeakyReLU(0.2),\n",
        "\n",
        "           nn.Conv2d(128, 256, kernel_size=4,\n",
        "                     stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(256),\n",
        "           nn.LeakyReLU(0.2),\n",
        "\n",
        "           nn.Conv2d(256, 512, kernel_size=4,\n",
        "                     stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(512),\n",
        "           nn.LeakyReLU(0.2),\n",
        "\n",
        "           nn.Conv2d(512, 1, kernel_size=4),\n",
        "           nn.Sigmoid()\n",
        "       )\n",
        "\n",
        "   def forward(self, x):\n",
        "       return self.disc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4dqHVUbRuSw"
      },
      "source": [
        "## GAN의 가중치 초기화 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF8j6kH0Rpo2"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "   # 층의 종류 추출\n",
        "   classname = m.__class__.__name__\n",
        "   if classname.find('Conv') != -1:\n",
        "       # 합성곱층 초기화\n",
        "       nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "   elif classname.find('BatchNorm') != -1:\n",
        "       # 배치정규화층 초기화\n",
        "       nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "       nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlaienghR0mX"
      },
      "source": [
        "## 학습에 필요한 요소 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6f8RIi9RwIJ"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 생성자 정의\n",
        "G = Generator().to(device)\n",
        "# 생성자 가중치 초기화\n",
        "G.apply(weights_init)\n",
        "\n",
        "# 감별자 정의\n",
        "D = Discriminator().to(device)\n",
        "# 감별자 가중치 초기화\n",
        "D.apply(weights_init)\n",
        "\n",
        "import tqdm\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "G_optim = Adam(G.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "D_optim = Adam(D.parameters(), lr=0.0001, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRs1hpuXR6by"
      },
      "source": [
        "## 학습 루프 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwI4m0J1R25s"
      },
      "outputs": [],
      "source": [
        "for epochs in range(5):\n",
        "# for epochs in range(50):\n",
        "   iterator = tqdm.tqdm(enumerate(loader, 0), total=len(loader))\n",
        "\n",
        "   for i, data in iterator:\n",
        "       D_optim.zero_grad()\n",
        "\n",
        "       # 실제 이미지에는 1, 생성된 이미지는 0으로 정답을 설정\n",
        "       label = torch.ones_like(\n",
        "           data[1], dtype=torch.float32).to(device)\n",
        "       label_fake = torch.zeros_like(\n",
        "           data[1], dtype=torch.float32).to(device)\n",
        "\n",
        "       # 실제 이미지를 감별자에 입력\n",
        "       real = D(data[0].to(device))\n",
        "\n",
        "       # 실제 이미지에 대한 감별자의 오차를 계산\n",
        "       Dloss_real = nn.BCELoss()(torch.squeeze(real), label)\n",
        "       Dloss_real.backward()\n",
        "       # 가짜 이미지 생성\n",
        "       noise = torch.randn(label.shape[0], 100, 1, 1, device=device)\n",
        "       fake = G(noise)\n",
        "\n",
        "       # 가짜 이미지를 감별자에 입력\n",
        "       output = D(fake.detach())\n",
        "\n",
        "       # 가짜 이미지에 대한 감별자의 오차를 계산\n",
        "       Dloss_fake = nn.BCELoss()(torch.squeeze(output), label_fake)\n",
        "       Dloss_fake.backward()\n",
        "\n",
        "       # 감별자의 전체 오차를 학습\n",
        "       Dloss = Dloss_real + Dloss_fake\n",
        "       D_optim.step()\n",
        "       \n",
        "       # 생성자의 학습\n",
        "       G_optim.zero_grad()\n",
        "       output = D(fake)\n",
        "       Gloss = nn.BCELoss()(torch.squeeze(output), label)\n",
        "       Gloss.backward()\n",
        "\n",
        "       G_optim.step()\n",
        "\n",
        "       iterator.set_description(f\"epoch:{epochs} iteration:{i} D_loss:{Dloss} G_loss:{Gloss}\")\n",
        "\n",
        "torch.save(G.state_dict(), \"Generator.pth\")\n",
        "torch.save(D.state_dict(), \"Discriminator.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "QLVPPLsBSA15",
        "outputId": "668d9377-4816-478e-c4d5-10609c09455b"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "   G.load_state_dict(\n",
        "       torch.load(\"./Generator.pth\", map_location=device))\n",
        "\n",
        "   # 특징 공간 상의 랜덤한 하나의 점을 지정\n",
        "   feature_vector = torch.randn(1, 100, 1, 1).to(device)\n",
        "   # 이미지 생성\n",
        "   pred = G(feature_vector).squeeze()\n",
        "   pred = pred.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "   plt.imshow(pred)\n",
        "   plt.title(\"predicted image\")\n",
        "   plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
